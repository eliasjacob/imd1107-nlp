{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic Behavior and Tool Calling with Large Language Models (LLMs)\n",
    "## IMD1107 - Natural Language Processing\n",
    "### [Dr. Elias Jacob de Menezes Neto](htttps://docente.ufrn.br/elias.jacob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Keypoints\n",
    "\n",
    "\n",
    "- Agentic behavior refers to the ability of language models to perform goal-directed actions autonomously based on inputs and context.\n",
    "\n",
    "- Tool/function calling enables LLMs to interact with external tools and resources, extending their capabilities beyond text generation.\n",
    "\n",
    "- LangChain facilitates the creation of agents that use LLMs as reasoning engines to determine necessary actions and their inputs.\n",
    "\n",
    "- Different agent architectures like ReAct, BabyAGI, and MRKL provide structured methods for building agents to handle various tasks.\n",
    "\n",
    "- The general flow for tool calling involves generating tool calls, invoking appropriate tools, formatting results, and passing messages back to the model.\n",
    "\n",
    "- Agents and AgentExecutors can be created to replicate tool interactions and achieve agentic behavior in LLMs.\n",
    "\n",
    "- Structured output constrains the LLM's output to a specific format or structure, which is useful for data storage and information extraction.\n",
    "\n",
    "\n",
    "### Takeaways\n",
    "\n",
    "- LLMs with agentic behavior can make decisions and take actions without direct human intervention, enhancing their functionality and autonomy.\n",
    "\n",
    "- Integrating LLMs with external tools significantly expands their capabilities, allowing them to perform a wider range of tasks.\n",
    "\n",
    "- Tool calling enables LLMs to break down complex queries, retrieve information from multiple sources, and provide structured outputs.\n",
    "\n",
    "- Different agent architectures offer various approaches to building AI systems that can reason, plan, and execute tasks autonomously.\n",
    "\n",
    "- Practical implementations of agentic behavior and tool calling can be achieved using frameworks like LangChain, with support for both cloud-based and local LLMs.\n",
    "\n",
    "- Structured output techniques like JSON mode and tool calling help in extracting specific information from unstructured text and ensuring consistent data formats.\n",
    "\n",
    "- When working with DataFrame agents or other powerful tools, it's crucial to consider security repercussions and use proper sandboxing techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Agentic Behavior in Language Models\n",
    "\n",
    "Before diving into the technical aspects, let's understand what agentic behavior means in the context of Language Models (LLMs). Agentic behavior refers to the ability of LLMs to perform goal-directed actions autonomously based on inputs and context. This capability allows LLMs to make decisions and take actions without direct human intervention.\n",
    "\n",
    "\n",
    "This notebook explores the concepts of agentic behavior and tool calling in Large Language Models (LLMs). We'll cover:\n",
    "\n",
    "1. What agentic behavior means for LLMs\n",
    "2. How tool calling extends LLM capabilities\n",
    "3. Practical implementations using LangChain\n",
    "4. Creating agents that interact with external tools\n",
    "5. Generating structured output from LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Agentic Behavior\n",
    "\n",
    "Agentic behavior is a key concept in the development of autonomous systems using language models (LLMs). It refers to the ability of LLMs to perform goal-directed actions autonomously based on inputs and context. This capability allows LLMs to make decisions and take actions without direct human intervention, enhancing their functionality and autonomy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents in the Context of Language Models\n",
    "\n",
    "Agentic behavior refers to the ability of language models (LLMs) to perform goal-directed actions autonomously based on inputs and context. This means that LLMs can make decisions and take actions without direct human intervention. In the context of LLMs, agents are systems that utilize LLMs as reasoning engines to determine necessary actions and their inputs. These agents can be used in various applications, such as chatbots, AI systems, and autonomous decision-making scenarios.\n",
    "\n",
    "LLMs possess the capability to assess the context and inputs provided to them and make autonomous decisions regarding the actions to undertake. This feature is particularly valuable in scenarios that require real-time decision-making. Some common examples of autonomous decision-making in LLMs include:\n",
    "\n",
    "- **Chatbots:** LLMs can be used to manage customer support by understanding queries and providing appropriate responses autonomously.\n",
    "- **AI Systems:** LLMs can create content such as articles or summaries based on given topics without human intervention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts: Agentic Behavior and Tool Calling\n",
    "\n",
    "Before diving into the implementation details, let's clarify two key concepts:\n",
    "\n",
    "1. **Agentic Behavior**: The ability of LLMs to autonomously make decisions and take actions based on inputs and context. This allows LLMs to operate more independently.\n",
    "\n",
    "2. **Tool Calling**: The capability of LLMs to interact with external tools and resources, expanding their functionality beyond text generation. This enables LLMs to perform a wider range of tasks.\n",
    "\n",
    "These concepts form the foundation for creating more versatile and powerful AI systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Role of LangChain in Agent Creation\n",
    "\n",
    "While language models can generate text, they cannot directly take actions on their own. LangChain is a powerful framework that bridges this gap by assisting the creation of agents. These agents use LLMs as reasoning engines to determine the necessary actions and their inputs, enabling more complex and autonomous decision-making processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Agents with LangChain\n",
    "\n",
    "While language models can generate text, they cannot directly take actions on their own. This is where **LangChain** comes into play. LangChain facilitates the creation of agents, which are systems that utilize an LLM as a reasoning engine to determine necessary actions and their inputs. The process involves feeding the results of those actions back into the agent, allowing it to decide whether additional actions are needed or if the task is complete.\n",
    "\n",
    "#### LangGraph: A More Flexible Approach to Agent Creation\n",
    "\n",
    "**LangGraph** is an extension of LangChain that offers greater flexibility and customization options for building agents compared to previous concepts. It is recommended for modern agent development due to its enhanced controllability. For more detailed information on agent concepts, refer to the [LangGraph documentation](https://langchain-ai.github.io/langgraph/).\n",
    "\n",
    "> **Note:** LangChain's earlier concept, **AgentExecutor**, served as a runtime for agents but lacked the flexibility required for more complex and customized agents. LangGraph addresses these limitations, providing a more flexible and controllable runtime. However, LangGraph is more complex than AgentExecutor and requires a deeper understanding of the basic concepts. LangGraph is outside our scope for this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Agent Architectures\n",
    "\n",
    "Different tasks and applications require different approaches to agent design. Agent architectures provide structured methods for building agents that can handle various types of tasks. Let's explore some popular agent architectures and understand how they can be used effectively with LLMs.\n",
    "\n",
    "### Agent Architectures\n",
    "\n",
    "There are several agent architectures that can be used to build agents with LLMs. Here are a few popular examples:\n",
    "\n",
    "#### 1. ReAct Agents\n",
    "\n",
    "**ReAct** is a popular architecture that combines reasoning and acting in an iterative process. The general flow of ReAct agents includes:\n",
    "\n",
    "1. **Reasoning:** The model \"thinks\" about the next step based on the input and previous observations.\n",
    "2. **Action Selection:** The model chooses an action from the available tools or decides to respond to the user.\n",
    "3. **Argument Generation:** The model generates arguments for the selected tool.\n",
    "4. **Execution:** The agent runtime (executor) parses the chosen tool and calls it with the generated arguments.\n",
    "5. **Observation:** The executor returns the results of the tool call back to the model as an observation.\n",
    "6. **Iteration:** This process repeats until the agent decides to respond to the user.\n",
    "\n",
    "#### 2. BabyAGI Agents\n",
    "\n",
    "**BabyAGI** is an agent architecture that focuses on task decomposition and iterative task execution. The main steps in the BabyAGI process are:\n",
    "\n",
    "1. **Task Creation:** The model creates a list of tasks based on the objective.\n",
    "2. **Task Prioritization:** The model prioritizes the tasks based on their importance and dependencies.\n",
    "3. **Task Execution:** The model selects the highest-priority task and executes it using the available tools.\n",
    "4. **Task Monitoring:** The model monitors the progress of the task execution and updates the task list accordingly.\n",
    "5. **Iteration:** The process repeats until the objective is achieved or no more tasks can be executed.\n",
    "\n",
    "#### 3. MRKL Agents\n",
    "\n",
    "**MRKL** (Modal Reasoning, Knowledge, and Language) is an agent architecture that combines multiple modalities, such as vision and language, to perform tasks. The key components of MRKL agents are:\n",
    "\n",
    "1. **Perception:** The agent perceives the environment through various modalities (e.g., vision, language).\n",
    "2. **Reasoning:** The agent reasons about the perceived information using its knowledge and language understanding.\n",
    "3. **Action:** The agent takes actions based on its reasoning, which can involve interacting with the environment or communicating with users.\n",
    "4. **Learning:** The agent learns from its experiences and updates its knowledge and reasoning capabilities.\n",
    "\n",
    "These are just a few examples of agent architectures that can be used with LLMs. The choice of architecture depends on the specific requirements of the task and the available resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Tool/Function Calling\n",
    "\n",
    "Tool calling, also known as function calling, is a crucial aspect of agentic behavior in LLMs. It enables LLMs to interact with external tools and resources, thereby extending their capabilities beyond text generation. Let's explore how tool calling works and its significance in enhancing LLM functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool/Function Calling as the Essence of Agentic Behavior\n",
    "\n",
    "Tool calling, also known as function calling, refers to the ability of Language Models (LLMs) to interact with external tools and resources. This capability enables LLMs to generate output that matches a user-defined schema, allowing them to perform actions or retrieve information from various sources.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"images/tool_call.png\" alt=\"\" style=\"width: 50%; height: 50%\"/>\n",
    "</p>\n",
    "\n",
    "> **Note:** Despite the term \"tool calling,\" the model itself does not execute the action or call the tool directly. Instead, it generates the necessary arguments for the tool, and the user decides whether to execute the tool.\n",
    "\n",
    "#### Integrating LLMs with External Tools\n",
    "LLMs can be integrated with a variety of external tools, such as:\n",
    " \n",
    "- **APIs:** LLMs can interact with APIs to retrieve data or perform actions. For example, an LLM could generate the necessary arguments to call a weather API and retrieve current weather information for a specific location.\n",
    "- **Databases:** LLMs can generate queries or commands to interact with databases, allowing them to retrieve, insert, or manipulate data based on the user's input.\n",
    "- **Other External Resources:** LLMs can be integrated with tools like search engines, knowledge bases, or domain-specific applications to enhance their capabilities and provide more accurate or relevant responses.\n",
    "\n",
    "#### Benefits of Tool Calling\n",
    "Tool calling offers several benefits when working with LLMs:\n",
    "\n",
    "1. **Enhanced Functionality:** By integrating with external tools, LLMs can perform a wider range of tasks and provide more thorough answers to user queries.\n",
    "2. **Handling Complex Queries:** Tool calling enables LLMs to break down complex queries into smaller, manageable steps. The model can generate the necessary tool calls to retrieve information from multiple sources and combine the results to provide a final answer.\n",
    "3. **Structured Output:** Tool calling allows LLMs to generate output that adheres to a specific format or structure, making it easier to process and use the generated data in downstream applications.\n",
    "\n",
    "\n",
    "#### Key Points of Tool Assimilation\n",
    "\n",
    "- Enhances LLM functionality by leveraging external tools\n",
    "- Enables handling of complex queries through structured tool interactions\n",
    "- Provides structured output for easier processing in downstream applications\n",
    "\n",
    "#### Real-World Examples\n",
    "Here are a few examples of how tool calling can be used in real-world scenarios:\n",
    "\n",
    "- **Search Engines:** An LLM can generate search queries based on a user's input and call a search engine API to retrieve relevant information. The model can then process the search results and provide a summarized answer to the user's question.\n",
    "- **Weather API:** An LLM can be integrated with a weather API to provide current weather information or forecasts for a specific location. The model can generate the necessary API calls based on the user's input and present the weather data in a user-friendly format.\n",
    "- **Database Queries:** LLMs can be used to generate SQL queries or database commands based on natural language input. For example, a user could ask, \"What are the top 5 best-selling products in the last month?\" The LLM would generate the appropriate database query, execute it, and return the results to the user.\n",
    "\n",
    "> **Note:** LangChain provides a standardized interface for tool calling that is consistent across different models, making it easier to work with various LLMs and integrate them with external tools.\n",
    "\n",
    "#### Tool Usage Flow\n",
    "The general flow for using tool calling with LLMs is as follows:\n",
    "\n",
    "1. Generate tool calls with a chat model in response to a query.\n",
    "2. Invoke the appropriate tools using the generated tool call as arguments.\n",
    "3. Format the result of the tool invocations as ToolMessages.\n",
    "4. Pass the entire list of messages back to the model so that it can generate a final answer (or call more tools).\n",
    "\n",
    "This flow allows LLMs to perform tasks and answer queries by leveraging external tools and resources, providing a more powerful and flexible approach to natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Practical Example: Tool Calling with LLMs\n",
    "\n",
    "Now that we have covered the theoretical aspects, let's see tool calling in action. We will use LangChain to integrate LLMs with external tools and demonstrate how they can perform tasks autonomously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-zYm0VXQ\n"
     ]
    }
   ],
   "source": [
    "# Import the load_dotenv function to load environment variables from a .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import ChatOpenAI class from langchain_openai module\n",
    "from langchain_openai import ChatOpenAI\n",
    "# Import ChatOllama class from langchain_ollama module\n",
    "from langchain_ollama import ChatOllama\n",
    "# Import StructuredTool class from langchain_core.tools module\n",
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "# Import the os module to interact with the operating system\n",
    "import os\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv() # You are expected to have a .env file with the OpenAI API KEY `OPENAI_API_KEY`\n",
    "\n",
    "# Retrieve the OpenAI API key from the environment variables and print the first 10 characters\n",
    "print(os.getenv('OPENAI_API_KEY')[:10]) # Here are the first 10 characters of my API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ChatOpenAI model with specific parameters\n",
    "model_openai = ChatOpenAI(\n",
    "    model='gpt-4o-mini',  # Specify the model to use\n",
    "    temperature=0.0       # Set the temperature for response variability\n",
    ") # This model costs around 0.15 USD per million tokens (input) and half of that (output). \n",
    "  # To learn more about models and pricing, go to https://openai.com/api/pricing/\n",
    "\n",
    "# Initialize the ChatOllama model with specific parameters\n",
    "model_llama = ChatOllama(\n",
    "    model='llama3.1',                # Specify the model to use\n",
    "    base_url='http://localhost:11434', # Set the base URL where the Ollama service is running\n",
    "    temperature=0.0                  # Set the temperature for response variability\n",
    ") # You must have Ollama running on your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Desculpe, mas não consigo fornecer informações em tempo real, como o preço atual de ações ou fundos imobiliários. Para obter o preço do RBRF11, recomendo que você consulte uma plataforma de investimentos, um site de finanças ou um aplicativo que forneça cotações atualizadas.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_openai.invoke(\"Qual o preço do RBRF11?\").content # This is a test to see if the model is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Não tenho informações sobre o valor atual do RBRF11. O valor de ações pode variar rapidamente e depende de muitos fatores, incluindo as condições atuais do mercado, os resultados financeiros da empresa e outros eventos que possam afetar sua valorização. Se você está procurando informações sobre o preço atual ou histórico do RBRF11, recomendo verificar um site de negociação de ações confiável ou consultar uma fonte financeira especializada para obter as informações mais atualizadas e precisas.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_llama.invoke(\"Qual o preço do RBRF11?\").content # This is a test to see if the model is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O fundo hglg11 (Fundo de Investimento Imobiliário) está custando R$ 105.00 com uma alta de 1.50%'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests  # Import the requests library to make HTTP requests\n",
    "from bs4 import BeautifulSoup  # Import BeautifulSoup to parse HTML content\n",
    "\n",
    "def fetch_latest_funds_price(ticker: str) -> str:\n",
    "    \"\"\" Fetch the latest price of a real estate investment trust (REIT) in Brazil \"\"\"\n",
    "\n",
    "    # Simulate the response from a web page\n",
    "    full_name = 'Fundo de Investimento Imobiliário'  # Define the full name of the REIT\n",
    "    price = 105.00  # Define the current price of the REIT\n",
    "    change_percentage = 1.5  # Define the change percentage of the REIT\n",
    "    change_class = 'alta'  # Define the class of the change (alta = increase, baixa = decrease)\n",
    "\n",
    "    # Return a formatted string with the REIT's ticker, full name, current price, and change percentage\n",
    "    return f'O fundo {ticker} ({full_name}) está custando R$ {price:.2f} com uma {change_class} de {change_percentage:.2f}%'\n",
    "\n",
    "# Test the function with a sample ticker symbol\n",
    "fetch_latest_funds_price('hglg11')  # This is a test to see if the function is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'not_implemented',\n",
       " 'id': ['langchain_core', 'tools', 'structured', 'StructuredTool'],\n",
       " 'repr': \"StructuredTool(name='fetch_latest_funds_price', description='Fetch the latest price of a real estate investment trust (REIT) in Brazil', args_schema=<class 'pydantic.v1.main.fetch_latest_funds_priceSchema'>, func=<function fetch_latest_funds_price at 0x7d613bd75d00>)\",\n",
       " 'name': 'fetch_latest_funds_price'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a StructuredTool instance from the fetch_latest_funds_price function\n",
    "tool_fetch_latest_funds_price = StructuredTool.from_function(\n",
    "    func=fetch_latest_funds_price,  # Specify the function to be used by the tool\n",
    "    parse_docstring=True,           # Enable parsing of the function's docstring to generate input and output schema\n",
    ")\n",
    "\n",
    "# Convert the tool's schema to JSON format and print it\n",
    "tool_fetch_latest_funds_price.to_json()  # This will output the schema generated from the function's docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind the fetch_latest_funds_price tool to the ChatOpenAI model\n",
    "# This allows the model to use the tool during its operations\n",
    "model_openai_with_tools = model_openai.bind_tools([tool_fetch_latest_funds_price])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ugJE9TFcQGHqi3jlfIfT9fuz', 'function': {'arguments': '{\"ticker\":\"RBRF11\"}', 'name': 'fetch_latest_funds_price'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 66, 'total_tokens': 86, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-a9df5244-af15-44de-b4eb-3662f925d6dc-0', tool_calls=[{'name': 'fetch_latest_funds_price', 'args': {'ticker': 'RBRF11'}, 'id': 'call_ugJE9TFcQGHqi3jlfIfT9fuz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 66, 'output_tokens': 20, 'total_tokens': 86})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke the model with the bound tools to get the price of the specified REIT\n",
    "# The model uses the fetch_latest_funds_price tool to fetch the latest price\n",
    "output = model_openai_with_tools.invoke(\"Qual o preço do RBRF11?\")\n",
    "\n",
    "# Display the output, which contains the price information of the REIT\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'fetch_latest_funds_price',\n",
       "  'args': {'ticker': 'RBRF11'},\n",
       "  'id': 'call_ugJE9TFcQGHqi3jlfIfT9fuz',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.tool_calls # The model doesn't call any function, but it tells you in a structured way which function you should call and with which arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'not_implemented',\n",
       " 'id': ['langchain_core', 'tools', 'structured', 'StructuredTool'],\n",
       " 'repr': \"StructuredTool(name='fetch_latest_crypto_price', description='Fetch the latest price of a cryptocurrency in Brazil. Accepts only BTC and ETH for now', args_schema=<class 'pydantic.v1.main.fetch_latest_crypto_priceSchema'>, func=<function fetch_latest_crypto_price at 0x7d613bd77b00>)\",\n",
       " 'name': 'fetch_latest_crypto_price'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's simulate a function that fetches the latest price of a cryptocurrency in Brazil\n",
    "\n",
    "def fetch_latest_crypto_price(crypto_ticker):\n",
    "    \"\"\" Fetch the latest price of a cryptocurrency in Brazil. Accepts only BTC and ETH for now \"\"\"\n",
    "    \n",
    "    # Check if the cryptocurrency ticker is BTC (Bitcoin)\n",
    "    if crypto_ticker == 'BTC':\n",
    "        return f'O Bitcoin está custando R$ 400.000,00'  # Return the price of Bitcoin\n",
    "    \n",
    "    # Check if the cryptocurrency ticker is ETH (Ethereum)\n",
    "    elif crypto_ticker == 'ETH':\n",
    "        return f'O Ethereum está custando R$ 20.000,00'  # Return the price of Ethereum\n",
    "    \n",
    "    # If the ticker is neither BTC nor ETH, return an information not available message\n",
    "    else:\n",
    "        return f'Não tenho informações sobre a criptomoeda {crypto_ticker}'\n",
    "\n",
    "# Create a StructuredTool instance from the fetch_latest_crypto_price function\n",
    "tool_fetch_latest_crypto_price = StructuredTool.from_function(\n",
    "    func=fetch_latest_crypto_price,  # Specify the function to be used by the tool\n",
    "    parse_docstring=True,            # Enable parsing of the function's docstring to generate input and output schema\n",
    ")\n",
    "\n",
    "# Convert the tool's schema to JSON format and print it\n",
    "tool_fetch_latest_crypto_price.to_json()  # This will output the schema generated from the function's docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind multiple tools to the ChatOpenAI model\n",
    "# This allows the model to use both the fetch_latest_funds_price and fetch_latest_crypto_price tools\n",
    "model_openai_with_tools = model_openai.bind_tools([\n",
    "    tool_fetch_latest_funds_price,  # Tool to fetch the latest price of a REIT\n",
    "    tool_fetch_latest_crypto_price  # Tool to fetch the latest price of a cryptocurrency\n",
    "])  # We can bind multiple tools at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'fetch_latest_funds_price',\n",
       "  'args': {'ticker': 'RBRF11'},\n",
       "  'id': 'call_kXIJ1QkEpA9oDGNFJgDviexb',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model_openai_with_tools.invoke(\"Qual o preço do RBRF11?\") # The model still knows how to answer the question about the REIT\n",
    "output.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'fetch_latest_crypto_price',\n",
       "  'args': {'crypto_ticker': 'BTC'},\n",
       "  'id': 'call_Zl01r2tpLXJCC1wtvq1b0Ely',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model_openai_with_tools.invoke(\"Qual o preço do Bitcoin?\") # As you can see, the model properly calls the function that fetches the latest price of a cryptocurrency and converts \"Bitcoin\" do BTC\n",
    "output.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'fetch_latest_crypto_price',\n",
       "  'args': {'crypto_ticker': 'ETH'},\n",
       "  'id': 'call_oRhM7AVsZ1d0xCgnUqcbcdTk',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model_openai_with_tools.invoke(\"Qual o preço do Ethereum?\") # The same happens with Ethereum\n",
    "output.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even when an LLM cannot directly execute actions, it can generate the necessary arguments for tools, making it a powerful resource for automating tasks and interacting with external systems. This ability to call tools and interface with the outside world is a key aspect of agentic behavior in LLMs.\n",
    "\n",
    "#### Replicating Tool Interactions with Llama 3.1 Locally\n",
    "\n",
    "To see how we can achieve similar tool interactions using Llama 3.1 on a local machine, you'll first need to ensure the required models are downloaded locally. Once the models are downloaded and available on your local machine, you can proceed with integrating Llama 3.1 into your workflow to enable tool interactions similar to what we observed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'not_implemented',\n",
       " 'id': ['langchain_core', 'tools', 'structured', 'StructuredTool'],\n",
       " 'repr': \"StructuredTool(name='calculator', description='Perform a mathematical operation on two numbers.\\\\nOperations: add, subtract, multiply, divide', args_schema=<class 'pydantic.v1.main.calculatorSchema'>, func=<function calculator at 0x7d6148c55bc0>)\",\n",
       " 'name': 'calculator'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculator(a: float, b: float, operation: str) -> float:\n",
    "    \"\"\"Perform a mathematical operation on two numbers.\n",
    "    Operations: add, subtract, multiply, divide\n",
    "    \"\"\"\n",
    "    # Check the operation type and perform the corresponding calculation\n",
    "    if operation == 'add':\n",
    "        return a + b  # Addition\n",
    "    elif operation == 'subtract':\n",
    "        return a - b  # Subtraction\n",
    "    elif operation == 'multiply':\n",
    "        return a * b  # Multiplication\n",
    "    elif operation == 'divide':\n",
    "        return a / b  # Division\n",
    "    else:\n",
    "        return 'Invalid operation'  # Return an error message for invalid operations\n",
    "\n",
    "# Create a tool using the StructuredTool class from the function we defined\n",
    "tool_calculator = StructuredTool.from_function(\n",
    "    func=calculator,       # Pass the calculator function\n",
    "    parse_docstring=True,  # Enable parsing of the docstring\n",
    ")\n",
    "\n",
    "# Convert the tool to JSON format\n",
    "tool_calculator.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind multiple tools to the Ollama model\n",
    "# This allows the model to use the fetch_latest_funds_price, fetch_latest_crypto_price, and time_now tools\n",
    "model_llama_with_tools = model_llama.bind_tools([\n",
    "    tool_fetch_latest_funds_price,  # Tool to fetch the latest price of a REIT\n",
    "    tool_fetch_latest_crypto_price,  # Tool to fetch the latest price of a cryptocurrency\n",
    "    tool_calculator  # Tool to perform mathematical operations\n",
    "])  # We can bind multiple tools at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'fetch_latest_funds_price',\n",
       "  'args': {'ticker': 'RBRF11'},\n",
       "  'id': '086a7309-7a74-4f30-9656-bbca2f1671fe',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model_llama_with_tools.invoke(\"Qual o preço do RBRF11?\") # The model still knows how to answer the question about the REIT\n",
    "output.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'fetch_latest_crypto_price',\n",
       "  'args': {'crypto_ticker': 'BTC'},\n",
       "  'id': 'e023eb0a-199e-46cc-8b1e-551a4a6d5aa2',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model_llama_with_tools.invoke(\"Qual o preço do Bitcoin?\") # As you can see, the model properly calls the function that fetches the latest price of a cryptocurrency and converts \"Bitcoin\" do BTC\n",
    "output.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'fetch_latest_crypto_price',\n",
       "  'args': {'crypto_ticker': 'ETH'},\n",
       "  'id': '86152051-31d6-4cb6-90cc-f5479c0f6cc4',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model_llama_with_tools.invoke(\"Qual o preço do Ethereum?\") # The same happens with Ethereum\n",
    "output.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'calculator',\n",
       "  'args': {'a': '125', 'b': '125', 'operation': 'multiply'},\n",
       "  'id': '041498eb-ad44-4fac-babf-8feabd7f7588',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model_llama_with_tools.invoke(\"Quanto é 125 X 125?\") # The model properly calls the function that returns the current time\n",
    "output.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'fetch_weather_info',\n",
       "  'args': {'location': 'Brazil'},\n",
       "  'id': 'a0d5b7d2-033d-48c6-adea-3935490455e6',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model_llama_with_tools.invoke(\"Qual a cor do céu?\") # The model doesn't have a tool for that, so it will return an empty tool_call\n",
    "output.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But it can still answer the question using the model's capabilities\n",
    "output.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Creating an Agent and AgentExecutor\n",
    "\n",
    "Integrating Language Models (LLMs) with external tools and resources can significantly enhance their capabilities, enabling them to perform a wider range of tasks autonomously. Both OpenAI and local Llama 3.1 models can be used to replicate tool interactions and achieve agentic behavior in LLMs.\n",
    "\n",
    "To demonstrate the agentic behavior of LLMs in action, we can create an **Agent** and an **AgentExecutor**:\n",
    "\n",
    "- An **Agent** is a system that utilizes an LLM as a reasoning engine to determine necessary actions and their inputs.\n",
    "- The **AgentExecutor** is a runtime that executes the actions determined by the Agent.\n",
    "\n",
    "By combining these components, we can create an autonomous system that can interact with external tools and resources to perform tasks without human intervention.\n",
    "\n",
    "Let's go back to OpenAI GPT-4o to see how we can create an Agent and an AgentExecutor to replicate tool interactions and achieve agentic behavior in LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage \n",
    "\n",
    "# Define the chat prompt template with a series of messages\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # System message to establish the assistant's role\n",
    "        (\"system\", \"You are a helpful assistant. Make sure to provide the best information about investments in Brazil.\"),\n",
    "\n",
    "        # Placeholder for chat history to maintain context|\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "\n",
    "        # Human message placeholder for user input\n",
    "        (\"human\", \"{input}\"),\n",
    "        \n",
    "        # Placeholder for the agent's intermediate thinking process\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# List of tools the agent can use to fetch data\n",
    "tools = [tool_fetch_latest_funds_price, tool_fetch_latest_crypto_price, tool_calculator]\n",
    "\n",
    "# Construct the agent with the specified language model, tools, and prompt\n",
    "agent = create_tool_calling_agent(\n",
    "    llm=model_openai,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `fetch_latest_crypto_price` with `{'crypto_ticker': 'BTC'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mO Bitcoin está custando R$ 400.000,00\u001b[0m\u001b[32;1m\u001b[1;3mO preço do Bitcoin atualmente é de R$ 400.000,00.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Qual o preço do Bitcoin?',\n",
       " 'output': 'O preço do Bitcoin atualmente é de R$ 400.000,00.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of AgentExecutor with specified agent, tools, and verbosity\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Invoke the agent_executor with a dictionary containing the input query\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Qual o preço do Bitcoin?\",  # The input query asking for the price of Bitcoin\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also force the agent to parse the output in a structured way by defining the output schema.\n",
    "# For that, LangChain relies on Pydantic, a library for data validation and settings management using Python type annotations.\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "# Define a Pydantic model for the expected response structure\n",
    "class PriceResponse(BaseModel):\n",
    "    \"\"\" The response of a function that fetches the latest price of a financial asset \"\"\"\n",
    "    price: float = Field(description=\"The price of the asset\")\n",
    "    currency: str = Field(description=\"The currency of the price\")\n",
    "    ticker: str = Field(description=\"The ticker of the asset\")\n",
    "    full_name: str = Field(description=\"The full name of the asset\")\n",
    "\n",
    "# Create a parser that uses the Pydantic model\n",
    "parser = PydanticOutputParser(pydantic_object=PriceResponse)\n",
    "\n",
    "# Define a prompt template for the chat, including system instructions and placeholders\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Make sure to provide the best information about investments in Brazil. You always parse your output {format_instructions}.\"),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the tools that the agent can use (e.g., functions to fetch latest fund and crypto prices)\n",
    "tools = [tool_fetch_latest_funds_price, tool_fetch_latest_crypto_price, tool_calculator]\n",
    "\n",
    "# Construct the agent with the given language model, tools, and prompt\n",
    "agent = create_tool_calling_agent(\n",
    "    llm=model_openai,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `fetch_latest_crypto_price` with `{'crypto_ticker': 'BTC'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mO Bitcoin está custando R$ 400.000,00\u001b[0m\u001b[32;1m\u001b[1;3m{\n",
      "  \"price\": 400000,\n",
      "  \"currency\": \"BRL\",\n",
      "  \"ticker\": \"BTC\",\n",
      "  \"full_name\": \"Bitcoin\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an executor to run the agent, with verbose output for debugging\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Invoke the agent executor with the input question and format instructions for parsing the output\n",
    "output = agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Qual o preço do Bitcoin?\",\n",
    "        \"format_instructions\": parser.get_format_instructions(),\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PriceResponse(price=400000.0, currency='BRL', ticker='BTC', full_name='Bitcoin')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following line uses a parser to parse the 'output' dictionary's 'output' key\n",
    "# and assigns the parsed result to 'parsed_output'\n",
    "parsed_output = parser.parse(output['output'])\n",
    "\n",
    "# Display the parsed output\n",
    "parsed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `fetch_latest_funds_price` with `{'ticker': 'KNSC11'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mO fundo KNSC11 (Fundo de Investimento Imobiliário) está custando R$ 105.00 com uma alta de 1.50%\u001b[0m\u001b[32;1m\u001b[1;3m{\n",
      "  \"price\": 105.00,\n",
      "  \"currency\": \"BRL\",\n",
      "  \"ticker\": \"KNSC11\",\n",
      "  \"full_name\": \"KNSC11 - Fundo de Investimento Imobiliário\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Call the invoke method on the agent_executor object\n",
    "# The input is a dictionary with the following keys and values:\n",
    "\n",
    "output = agent_executor.invoke(\n",
    "    {\n",
    "        # \"input\" key contains the question we want to ask\n",
    "        \"input\": \"Qual o preço do KNSC11?\",  \n",
    "        \n",
    "        # \"format_instructions\" key contains instructions for how the output should be formatted\n",
    "        \"format_instructions\": parser.get_format_instructions(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PriceResponse(price=105.0, currency='BRL', ticker='KNSC11', full_name='KNSC11 - Fundo de Investimento Imobiliário')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following line uses a parser to parse the 'output' dictionary's 'output' key\n",
    "# and assigns the parsed result to 'parsed_output'\n",
    "parsed_output = parser.parse(output['output'])\n",
    "\n",
    "# Display the parsed output\n",
    "parsed_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Reconstructing the Agent Executor with LangGraph\n",
    "\n",
    "LangGraph is a robust library designed to build stateful, multi-actor applications leveraging Large Language Models (LLMs). It excels in creating agent and multi-agent workflows due to its unique strengths: support for cycles, granular control, and built-in persistence. Unlike frameworks that depend on Directed Acyclic Graphs (DAGs), LangGraph can handle cyclical flows, which are essential for most agent-based architectures. Its low-level design provides developers with detailed oversight over application flow and state, crucial for building dependable agents. Additionally, LangGraph's integrated persistence allows advanced functionalities such as human-in-the-loop processes and memory features.\n",
    "\n",
    "LangGraph's design is inspired by Pregel and Apache Beam, with a public interface that draws from NetworkX. Though developed by LangChain Inc., the creators behind LangChain, LangGraph can be used independently.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Cycles and Branching**: Implement loops and conditional actions in applications. This is crucial for scenarios where an agent might need to revisit previous steps based on new information.\n",
    "- **Persistence**: Automatically save the state after each step. This is particularly useful for error recovery, human-in-the-loop workflows, and creating applications with memory features.\n",
    "- **Human-in-the-Loop**: Pause graph execution to allow for human approval or modification of the agent's actions. This adds a layer of oversight and adaptability to the system.\n",
    "- **Streaming Support**: Stream outputs, including token streaming, as they are produced by each node. This allows for real-time processing and feedback.\n",
    "- **Integration with LangChain**: Seamlessly integrates with LangChain and LangSmith, though not required. This provides flexibility in choosing complementary tools and frameworks.\n",
    "\n",
    "### Central Concept: State Management\n",
    "\n",
    "A central concept in LangGraph is **state**. During graph execution, a state object is passed between nodes and updated according to each node's output. The method of updating the state can be determined by the graph type or a custom function defined by the developer. This state management is crucial for maintaining continuity and coherence in multi-step processes.\n",
    "\n",
    "### Expanded Explanation\n",
    "\n",
    "LangGraph's ability to handle cycles and branching is particularly important for agent-based systems that require iterative processes, such as refining a search based on new data or revisiting previous decisions. This cyclical capability sets LangGraph apart from traditional DAG-based frameworks, which are limited to linear, acyclic workflows.\n",
    "\n",
    "The built-in persistence feature ensures that the state of the application is saved at each step, allowing for robust error recovery. Should an error occur, the system can resume from the last saved state rather than starting over. This is especially valuable in complex workflows where starting from scratch would be inefficient and costly.\n",
    "\n",
    "Human-in-the-loop functionality pauses the graph's execution to incorporate human judgment. For instance, in a legal document review application, an agent might pause to seek a human expert's approval on a critical decision, ensuring higher accuracy and reliability.\n",
    "\n",
    "Streaming support enables outputs to be processed in real-time. For example, in a real-time language translation application, each token generated by the model can be immediately displayed to the user, providing a smoother and more interactive experience.\n",
    "\n",
    "LangGraph's assimilation capability with LangChain and LangSmith, while not mandatory, offers enhanced flexibility. These integrations can simplify the development process by leveraging existing tools and libraries that complement LangGraph's functionalities.\n",
    "\n",
    "### Addressing Potential Questions\n",
    "\n",
    "- **Why are cycles important in agent-based architectures?**\n",
    "Cycles allow an agent to revisit previous steps based on new information, enabling more dynamic and adaptable workflows.\n",
    "\n",
    "- **How does persistence improve error recovery?**\n",
    "By saving the state after each step, the system can resume from the last saved state in case of an error, avoiding the need to restart from the beginning.\n",
    "\n",
    "- **What is the advantage of human-in-the-loop processes?**\n",
    "Human-in-the-loop processes incorporate human judgment and oversight, enhancing the accuracy and reliability of the system, particularly in critical or complex decision-making scenarios.\n",
    "\n",
    "- **How does streaming support benefit real-time applications?**\n",
    "Streaming allows outputs to be processed and displayed as they are produced, providing a more responsive and interactive user experience.\n",
    "\n",
    "LangGraph offers a powerful framework for developing sophisticated, LLM-powered applications with complex workflows and state management requirements. Its unique features and flexibility make it an excellent choice for building dependable, adaptable, and efficient agent-based systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='fetch_latest_funds_price', description='Fetch the latest price of a real estate investment trust (REIT) in Brazil', args_schema=<class 'pydantic.v1.main.fetch_latest_funds_priceSchema'>, func=<function fetch_latest_funds_price at 0x7d613bd75d00>),\n",
       " StructuredTool(name='fetch_latest_crypto_price', description='Fetch the latest price of a cryptocurrency in Brazil. Accepts only BTC and ETH for now', args_schema=<class 'pydantic.v1.main.fetch_latest_crypto_priceSchema'>, func=<function fetch_latest_crypto_price at 0x7d613bd77b00>),\n",
       " StructuredTool(name='calculator', description='Perform a mathematical operation on two numbers.\\nOperations: add, subtract, multiply, divide', args_schema=<class 'pydantic.v1.main.calculatorSchema'>, func=<function calculator at 0x7d6148c55bc0>)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2669310/3751651211.py:4: LangGraphDeprecationWarning: ToolExecutor is deprecated as of version 0.2.0 and will be removed in 0.3.0. Use langgraph.prebuilt.ToolNode instead.\n",
      "  tool_executor = ToolExecutor(tools)\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolExecutor\n",
    "\n",
    "# We wrap our tools defined before in a ToolExecutor. This is simple class that takes in a ToolInvocation and calls that tool, returning the output. A ToolInvocation is any class with tool and tool_input attribute.\n",
    "tool_executor = ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_openai_with_tools = model_openai.bind_tools(tools) # The model needs to know which tools it can use, that why we bind the tools - NOT THE TOOLKIT - to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7d6148073410>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7d613bd66950>, root_client=<openai.OpenAI object at 0x7d6164481190>, root_async_client=<openai.AsyncOpenAI object at 0x7d613bd66690>, model_name='gpt-4o-mini', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'fetch_latest_funds_price', 'description': 'Fetch the latest price of a real estate investment trust (REIT) in Brazil', 'parameters': {'type': 'object', 'properties': {'ticker': {'type': 'string'}}, 'required': ['ticker']}}}, {'type': 'function', 'function': {'name': 'fetch_latest_crypto_price', 'description': 'Fetch the latest price of a cryptocurrency in Brazil. Accepts only BTC and ETH for now', 'parameters': {'type': 'object', 'properties': {'crypto_ticker': {}}, 'required': ['crypto_ticker']}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Perform a mathematical operation on two numbers.\\nOperations: add, subtract, multiply, divide', 'parameters': {'type': 'object', 'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}, 'operation': {'type': 'string'}}, 'required': ['a', 'b', 'operation']}}}]})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_openai_with_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Agent State\n",
    "\n",
    "The primary graph used in *LangGraph* is referred to as the **StateGraph**. This graph is characterized by a state object that traverses through each node. Each node within the StateGraph is responsible for performing operations that modify the state. These operations can either:\n",
    "\n",
    "- **SET** specific attributes on the state, effectively replacing the current values.\n",
    "- **ADD** to the existing attribute, augmenting the current values.\n",
    "\n",
    "The choice between setting and adding is determined by the annotations on the state object used to construct the graph.\n",
    "\n",
    "#### Monitoring State with a Message List\n",
    "\n",
    "In the context of this explanation, the state we will monitor consists of a list of messages. Our objective is for each node within the StateGraph to append messages to this list. To achieve this, we will use a **TypedDict** with a single key, `messages`, and annotate it to ensure that messages are always appended.\n",
    "\n",
    "#### Key Concepts\n",
    "\n",
    "- **StateGraph**: The primary structure in *LangGraph* that circulates the state object through each node.\n",
    "- **State Object**: A dynamic data structure that nodes modify as it traverses the graph.\n",
    "- **Node Operations**: Actions performed by nodes to modify the state, either by setting or adding attributes.\n",
    "- **SET**: Replaces the current value of an attribute.\n",
    "- **ADD**: Augments the current value of an attribute.\n",
    "\n",
    "#### Example Scenario\n",
    "\n",
    "To better understand these concepts, consider a scenario where the state object is designed to hold a list of messages. As the state object moves through the nodes, each node appends a new message to the list. This can be visualized as follows:\n",
    "\n",
    "1. **Initial State**: The state object starts with an empty list of messages.\n",
    "2. **Node A**: Appends a message to the list.\n",
    "3. **Node B**: Appends another message to the list.\n",
    "4. **Final State**: The state object contains a list with messages added by both Node A and Node B.\n",
    "\n",
    "\n",
    "> **TypedDict**: A specialized dictionary in Python that allows for type hints, ensuring that the `messages` key is used consistently across the graph.\n",
    "> - **Why use a TypedDict?**\n",
    ">   - TypedDict provides type safety, ensuring that the state object maintains a consistent structure throughout its traversal of the StateGraph.\n",
    "> - **What if a node incorrectly modifies the state?**\n",
    ">   - Proper annotations and consistent use of TypedDict help prevent such issues, but additional validation logic can be implemented to handle erroneous modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "# Import the BaseMessage class from langchain_core.messages\n",
    "# BaseMessage is the base class for different types of messages (e.g., HumanMessage, AIMessage)\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "# Define a TypedDict named AgentState\n",
    "# TypedDict is used to define a dictionary with a specific structure and types for its keys and values\n",
    "class AgentState(TypedDict):\n",
    "    # The 'messages' key is annotated with a sequence of BaseMessage objects\n",
    "    # Annotated is used to add metadata to the type hint\n",
    "    # Here, operator.add is used as metadata, but it doesn't affect the type itself\n",
    "    # This means 'messages' should be a sequence (e.g., list) of BaseMessage objects\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Nodes\n",
    "\n",
    "In this section, we will establish several nodes in our graph. In **LangGraph**, a node can be categorized as either a *function* or a *runnable*. The two primary nodes required are:\n",
    "\n",
    "1. **The Agent**: This node determines what actions, if any, should be taken.\n",
    "2. **Function to Invoke Tools**: If the agent decides that an action is necessary, this node will execute that action.\n",
    "\n",
    "#### Additional Considerations\n",
    "\n",
    "We also need to define some edges. These edges can be **conditional**, meaning that depending on the node's output, different paths may be followed. The specific path taken isn't determined until the node is executed, which is decided by the Language Learning Model (LLM).\n",
    "\n",
    "#### Types of Edges\n",
    "\n",
    "- **Conditional Edge**: After the agent is called, there are two possibilities:\n",
    "    1. **Action Required**: If the agent decides to take an action, then the function to invoke tools should be called.\n",
    "    2. **No Action Required**: If the agent decides that no further action is needed, the process should end.\n",
    "\n",
    "- **Normal Edge**: Once the tools have been invoked, the process should always return to the agent to decide the next step.\n",
    "\n",
    "#### Workflow Summary\n",
    "\n",
    "1. **Agent Node**: Determines the need of an action.\n",
    "2. **Conditional Edge**:\n",
    "    - If action is required, proceed to the function to invoke tools.\n",
    "    - If no action is required, the process ends.\n",
    "3. **Function to Invoke Tools Node**: Executes the required action.\n",
    "4. **Normal Edge**: Returns to the agent for the next decision.\n",
    "\n",
    "> **Note:** The conditional edge is critical because it allows the graph to dynamically adapt based on the agent's decisions.\n",
    "\n",
    "By defining these nodes and the function to determine which conditional edge to follow, we can create a flexible and responsive workflow within our graph.\n",
    "\n",
    "Next, we will proceed by defining the nodes and a function to determine which conditional edge to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state):\n",
    "    # Extract the list of messages from the state dictionary\n",
    "    messages = state[\"messages\"]\n",
    "    # Get the last message in the list\n",
    "    last_message = messages[-1]\n",
    "    # Check if the last message contains any tool calls\n",
    "    # If there are no tool calls, return \"end\" to indicate the process should finish\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    # If there are tool calls, return \"continue\" to indicate the process should continue\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state):\n",
    "    # Extract the list of messages from the state dictionary\n",
    "    messages = state[\"messages\"]\n",
    "    # Invoke the model with the current list of messages and get the response\n",
    "    response = model_openai_with_tools.invoke(messages)\n",
    "    # Return a dictionary with the response message wrapped in a list\n",
    "    # This will be added to the existing list of messages in the state\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Define the function to execute tools\n",
    "def call_tool(state):\n",
    "    # Extract the list of messages from the state dictionary\n",
    "    messages = state[\"messages\"]\n",
    "    # Get the last message in the list, which involves a tool call\n",
    "    last_message = messages[-1]\n",
    "    # Extract the first tool call from the last message\n",
    "    tool_call = last_message.tool_calls[0]\n",
    "    # Construct a ToolInvocation object from the tool call details\n",
    "    action = ToolInvocation(\n",
    "        tool=tool_call[\"name\"],  # Name of the tool to be invoked\n",
    "        tool_input=tool_call[\"args\"],  # Arguments for the tool\n",
    "    )\n",
    "    # Invoke the tool executor with the constructed ToolInvocation and get the response\n",
    "    response = tool_executor.invoke(action)\n",
    "    # Create a ToolMessage object using the response from the tool executor\n",
    "    function_message = ToolMessage(\n",
    "        content=str(response),  # Content of the response\n",
    "        name=action.tool,  # Name of the tool\n",
    "        tool_call_id=tool_call[\"id\"]  # ID of the tool call\n",
    "    )\n",
    "    # Return a dictionary with the function message wrapped in a list\n",
    "    # This will be added to the existing list of messages in the state\n",
    "    return {\"messages\": [function_message]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Graph\n",
    "\n",
    "Having established the primary nodes and the types of edges, we can now integrate these elements to define the graph. This graph will represent the workflow, guiding the decision-making process and subsequent actions.\n",
    "\n",
    "#### Components of the Graph\n",
    "\n",
    "- **Nodes**: The fundamental units of the graph, representing decision points and actions.\n",
    "    1. **Agent Node**: Determines the necessity of an action.\n",
    "    2. **Function to Invoke Tools Node**: Executes the required action if deemed necessary by the agent.\n",
    "\n",
    "- **Edges**: The connections between nodes, dictating the flow of the process.\n",
    "- **Conditional Edges**: These edges are based on the agent's decision:\n",
    "    - **If action required**: Connects the agent node to the function to invoke tools node.\n",
    "    - **If no action required**: Ends the process.\n",
    "- **Normal Edge**: Connects the function to invoke tools node back to the agent node for further decisions.\n",
    "\n",
    "#### Graph Workflow\n",
    "\n",
    "1. **Initialization**: Start at the agent node.\n",
    "2. **Decision Point**: The agent node evaluates whether an action is necessary.\n",
    "    - **If action required**: Proceed to the function to invoke tools node.\n",
    "    - **If no action required**: End the process.\n",
    "3. **Action Execution**: If directed, the function to invoke tools node executes the action.\n",
    "4. **Feedback Loop**: After executing the action, the normal edge returns the process to the agent node for further evaluation and decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "# Define a new state graph for the workflow\n",
    "# StateGraph is used to create a directed graph where nodes represent states and edges represent transitions\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes to the graph\n",
    "# Each node represents a state in the workflow and is associated with a function to be executed\n",
    "\n",
    "# Add a node named \"agent\" that will call the model\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "\n",
    "# Add a node named \"action\" that will call the tool\n",
    "workflow.add_node(\"action\", call_tool)\n",
    "\n",
    "# Set the entry point of the workflow to the \"agent\" node\n",
    "# This means the \"agent\" node will be the first node executed when the workflow starts\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# Add conditional edges from the \"agent\" node\n",
    "# Conditional edges determine the next node to be executed based on the output of a function\n",
    "\n",
    "# Define conditional edges for the \"agent\" node\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",  # Start node for the conditional edges\n",
    "    should_continue,  # Function to determine the next node\n",
    "    {\n",
    "        \"continue\": \"action\",  # If the function returns \"continue\", transition to the \"action\" node\n",
    "        \"end\": END,  # If the function returns \"end\", terminate the workflow\n",
    "    },\n",
    ")\n",
    "\n",
    "# Add a normal edge from the \"action\" node to the \"agent\" node\n",
    "# This creates a cycle between the \"agent\" and \"action\" nodes\n",
    "# After the \"action\" node is executed, the workflow transitions back to the \"agent\" node\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "\n",
    "# Compile the workflow into a LangChain Runnable\n",
    "# This allows the workflow to be executed as a runnable object\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Visual Representation\n",
    "\n",
    "- **Agent Node**: The starting point and decision-maker.\n",
    "- **Conditional Edge**: Leads to either the function to invoke tools node or ends the process.\n",
    "- **Function to Invoke Tools Node**: Executes the action if needed.\n",
    "- **Normal Edge**: Loops back to the agent node.\n",
    "\n",
    "> **Note:** The dynamic nature of the conditional edge allows the graph to adapt based on real-time decisions made by the agent.\n",
    "\n",
    "Let's see below an image representing the graph workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle\n",
    "\n",
    "try:\n",
    "    # Generate and display a visual representation of the workflow graph\n",
    "    # The get_graph method is called on the app object with xray=True to include detailed information\n",
    "    # The draw_mermaid_png method converts the graph to a PNG image using Mermaid.js\n",
    "    # The curve_style parameter is set to CurveStyle.NATURAL to use smooth curves for the edges in the graph\n",
    "    graph_image = app.get_graph(xray=True).draw_mermaid_png(curve_style=CurveStyle.NATURAL)\n",
    "    \n",
    "    # Display the generated image in the Jupyter notebook\n",
    "    display(Image(graph_image))\n",
    "except Exception as e:\n",
    "    # If an error occurs during the graph generation or display, print the error message\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use our Graph like any other LangChain runnable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2669310/4280605802.py:37: LangGraphDeprecationWarning: ToolInvocation is deprecated as of version 0.2.0 and will be removed in 0.3.0. Use langgraph.prebuilt.ToolNode instead.\n",
      "  action = ToolInvocation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Qual o preço do BitCoin'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_SWcQzS46PWAvOaHGRRurukIv', 'function': {'arguments': '{\"crypto_ticker\":\"BTC\"}', 'name': 'fetch_latest_crypto_price'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 139, 'total_tokens': 157, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_54e2f484be', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-50a487b2-1089-4e7c-8138-a3683d7c77ec-0', tool_calls=[{'name': 'fetch_latest_crypto_price', 'args': {'crypto_ticker': 'BTC'}, 'id': 'call_SWcQzS46PWAvOaHGRRurukIv', 'type': 'tool_call'}], usage_metadata={'input_tokens': 139, 'output_tokens': 18, 'total_tokens': 157}), ToolMessage(content='O Bitcoin está custando R$ 400.000,00', name='fetch_latest_crypto_price', tool_call_id='call_SWcQzS46PWAvOaHGRRurukIv'), AIMessage(content='O preço do Bitcoin é de R$ 400.000,00.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 180, 'total_tokens': 196, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e402cc08-191e-44de-a2d9-a3cc2ee9559e-0', usage_metadata={'input_tokens': 180, 'output_tokens': 16, 'total_tokens': 196})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# We can use just like the Agent + Agent Executor created above\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Qual o preço do BitCoin\")]}\n",
    "result = app.invoke(inputs)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_EDnF3KxBEmVmG8fN341uzRtj', 'function': {'arguments': '{\"crypto_ticker\":\"BTC\"}', 'name': 'fetch_latest_crypto_price'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 139, 'total_tokens': 157, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3a3f5c0b-e03d-4ae7-aad9-b86a9a8b36bc-0', tool_calls=[{'name': 'fetch_latest_crypto_price', 'args': {'crypto_ticker': 'BTC'}, 'id': 'call_EDnF3KxBEmVmG8fN341uzRtj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 139, 'output_tokens': 18, 'total_tokens': 157})]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'action':\n",
      "---\n",
      "{'messages': [ToolMessage(content='O Bitcoin está custando R$ 400.000,00', name='fetch_latest_crypto_price', tool_call_id='call_EDnF3KxBEmVmG8fN341uzRtj')]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2669310/4280605802.py:37: LangGraphDeprecationWarning: ToolInvocation is deprecated as of version 0.2.0 and will be removed in 0.3.0. Use langgraph.prebuilt.ToolNode instead.\n",
      "  action = ToolInvocation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='O preço do Bitcoin é de R$ 400.000,00.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 180, 'total_tokens': 196, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-597c9bc2-6bc2-4ddb-adb6-8f15ad87b5d1-0', usage_metadata={'input_tokens': 180, 'output_tokens': 16, 'total_tokens': 196})]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can also stream the execution of the workflow\n",
    "\n",
    "for output in app.stream(inputs):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unleashing the power of cycles\n",
    "\n",
    "LangGraph's ability to handle cycles is a game-changer for agent-based systems. Cycles allow agents to revisit previous steps based on new information, enabling more dynamic and adaptable workflows. This flexibility is crucial for scenarios where an agent needs to refine a search based on updated data or revisit previous decisions based on new insights. This makes the Agent capable to handle complex tasks.\n",
    "Let's use this cycle capability to test if the agent can make more complex reasoning, like handling multiple questions and tasks at once.\n",
    "\n",
    "In the example below, we'll ask \"How many BTC can I buy with 1,000 HGLG11?\". Note that the Agent will need to:\n",
    "- Get BTC prices\n",
    "- Get HGLG11 prices\n",
    "- Reason about the conversion rate\n",
    "\n",
    "This is a more complex task that requires multiple steps and reasoning. Let's see how the Agent can handle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_J2MNNUHPp9d0gABlQwzhlqk9', 'function': {'arguments': '{\"ticker\":\"HGLG11\"}', 'name': 'fetch_latest_funds_price'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 151, 'total_tokens': 171, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0b207849-fb70-4310-b4e8-7a49badd7eef-0', tool_calls=[{'name': 'fetch_latest_funds_price', 'args': {'ticker': 'HGLG11'}, 'id': 'call_J2MNNUHPp9d0gABlQwzhlqk9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 151, 'output_tokens': 20, 'total_tokens': 171})]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'action':\n",
      "---\n",
      "{'messages': [ToolMessage(content='O fundo HGLG11 (Fundo de Investimento Imobiliário) está custando R$ 105.00 com uma alta de 1.50%', name='fetch_latest_funds_price', tool_call_id='call_J2MNNUHPp9d0gABlQwzhlqk9')]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2669310/4280605802.py:37: LangGraphDeprecationWarning: ToolInvocation is deprecated as of version 0.2.0 and will be removed in 0.3.0. Use langgraph.prebuilt.ToolNode instead.\n",
      "  action = ToolInvocation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lvoXHlVzlvuULJxrTUm0powL', 'function': {'arguments': '{\"crypto_ticker\":\"BTC\"}', 'name': 'fetch_latest_crypto_price'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 216, 'total_tokens': 234, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2195345f-0ca2-48fc-acbd-99b4a25c9411-0', tool_calls=[{'name': 'fetch_latest_crypto_price', 'args': {'crypto_ticker': 'BTC'}, 'id': 'call_lvoXHlVzlvuULJxrTUm0powL', 'type': 'tool_call'}], usage_metadata={'input_tokens': 216, 'output_tokens': 18, 'total_tokens': 234})]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'action':\n",
      "---\n",
      "{'messages': [ToolMessage(content='O Bitcoin está custando R$ 400.000,00', name='fetch_latest_crypto_price', tool_call_id='call_lvoXHlVzlvuULJxrTUm0powL')]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2669310/4280605802.py:37: LangGraphDeprecationWarning: ToolInvocation is deprecated as of version 0.2.0 and will be removed in 0.3.0. Use langgraph.prebuilt.ToolNode instead.\n",
      "  action = ToolInvocation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_9JyBqptX6jhzTBZgfpykpPw4', 'function': {'arguments': '{\"a\":1000,\"b\":105,\"operation\":\"multiply\"}', 'name': 'calculator'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 257, 'total_tokens': 280, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4a9cb7d5-d197-4c57-9fb1-2bd0648e3431-0', tool_calls=[{'name': 'calculator', 'args': {'a': 1000, 'b': 105, 'operation': 'multiply'}, 'id': 'call_9JyBqptX6jhzTBZgfpykpPw4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 257, 'output_tokens': 23, 'total_tokens': 280})]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'action':\n",
      "---\n",
      "{'messages': [ToolMessage(content='105000.0', name='calculator', tool_call_id='call_9JyBqptX6jhzTBZgfpykpPw4')]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2669310/4280605802.py:37: LangGraphDeprecationWarning: ToolInvocation is deprecated as of version 0.2.0 and will be removed in 0.3.0. Use langgraph.prebuilt.ToolNode instead.\n",
      "  action = ToolInvocation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_MQgazCakfTjh5Pass1nNx4uC', 'function': {'arguments': '{\"a\":105000,\"b\":400000,\"operation\":\"divide\"}', 'name': 'calculator'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 291, 'total_tokens': 315, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d8ab72c2-37bf-46ad-962c-a1c4bbe86a0e-0', tool_calls=[{'name': 'calculator', 'args': {'a': 105000, 'b': 400000, 'operation': 'divide'}, 'id': 'call_MQgazCakfTjh5Pass1nNx4uC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 291, 'output_tokens': 24, 'total_tokens': 315})]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'action':\n",
      "---\n",
      "{'messages': [ToolMessage(content='0.2625', name='calculator', tool_call_id='call_MQgazCakfTjh5Pass1nNx4uC')]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2669310/4280605802.py:37: LangGraphDeprecationWarning: ToolInvocation is deprecated as of version 0.2.0 and will be removed in 0.3.0. Use langgraph.prebuilt.ToolNode instead.\n",
      "  action = ToolInvocation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='Com 1000 cotas do HGLG11, que estão custando R$ 105, você teria R$ 105.000. Com esse valor, você conseguiria comprar aproximadamente 0,2625 bitcoins, considerando que o preço do Bitcoin é R$ 400.000.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 326, 'total_tokens': 387, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-22a43a92-d822-43fe-9116-219836dd91f8-0', usage_metadata={'input_tokens': 326, 'output_tokens': 61, 'total_tokens': 387})]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": [HumanMessage(content=\"Quantos bitcoins eu consigo comprar com 1000 cotas do HGLG11?\")]}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Multi-Agent Systems in LangGraph\n",
    ">\n",
    "> In the previous example, we demonstrated a basic agent capable of handling simple tasks. However, LangGraph's true potential lies in its ability to create more complex agents and multi-agent systems. These systems can manage multiple tasks simultaneously and interact with each other to achieve sophisticated objectives.\n",
    ">\n",
    "> A multi-agent system consists of multiple agents that collaborate to solve problems or achieve goals that are beyond the capabilities of a single agent. This collaboration can be orchestrated in various ways, depending on the architecture and the specific requirements of the task.\n",
    ">\n",
    "> One example of a multi-agent system is the **Agent Supervisor Architecture**. In this setup, multiple agents work together under the supervision of a central agent (the supervisor). The supervisor coordinates the activities of the individual agents, ensuring that they work towards a common goal efficiently.\n",
    ">\n",
    "> - **Key Components**:\n",
    ">   - **Supervisor Agent**: This agent oversees the entire system, assigning tasks to individual agents and monitoring their progress.\n",
    ">   - **Worker Agents**: These agents perform the tasks assigned by the supervisor. Each worker agent may specialize in different types of tasks, allowing the system to handle a variety of activities simultaneously.\n",
    ">\n",
    "> Below is a diagram illustrating the Agent Supervisor Architecture:\n",
    ">\n",
    "> <p align=\"center\">\n",
    "> <img src=\"images/agent_supervisor_diagram.png\" alt=\"Agent Supervisor Diagram\" style=\"width: 30%; height: 30%\"/>\n",
    "> </p>\n",
    ">\n",
    "> - **Benefits of Multi-Agent Systems**:\n",
    ">    - **Scalability**: Multi-agent systems can easily scale by adding more agents to handle increased workload.\n",
    ">   - **Flexibility**: Different agents can be designed to handle specific tasks, making the system adaptable to various requirements.\n",
    ">   - **Robustness**: The failure of a single agent does not necessarily compromise the entire system, as other agents can continue to function independently.\n",
    ">\n",
    ">\n",
    ">\n",
    "> > **Note**: Understanding the interactions and coordination between agents is crucial for designing effective multi-agent systems. Ensure that the roles and responsibilities of each agent are clearly defined to avoid conflicts and inefficiencies.\n",
    ">\n",
    "> To dive deeper into multi-agent workflows and explore more complex architectures, refer to [this post](https://blog.langchain.dev/langgraph-multi-agent-workflows/).\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Agent that interacts with Pandas DataFrame\n",
    "\n",
    "LangChain provides a convenient way to create an Agent that interacts with a Pandas DataFrame. This Agent can perform various operations on the DataFrame based on user queries, such as filtering, sorting, and summarizing data.\n",
    "\n",
    "### Creating a Pandas DataFrame Agent\n",
    "\n",
    "LangChain offers the `create_pandas_dataframe_agent` function, which allows you to easily build an Agent that interacts with a Pandas DataFrame. Here's a step-by-step breakdown of the process:\n",
    "\n",
    "1. **Define the DataFrame**: Start by creating or loading your Pandas DataFrame that contains the data you want to work with.\n",
    "\n",
    "2. **Create the Agent**: Use the `create_pandas_dataframe_agent` function provided by LangChain to create the Agent. This function takes the DataFrame and the specified tools as input and returns an Agent instance.\n",
    "\n",
    "3. **Interact with the Agent**: Once the Agent is created, you can provide user queries or instructions to it. The Agent will analyze the query, determine the appropriate tool or sequence of tools to use, and generate the corresponding tool calls to perform the requested operation on the DataFrame.\n",
    "\n",
    "4. **Retrieve the Results**: After the Agent executes the tool calls, it returns the results, which can be the modified DataFrame, a subset of the data, or any relevant information based on the user's query.\n",
    "\n",
    "### Security Considerations\n",
    "\n",
    "> **Important Security Notice:**\n",
    ">\n",
    "> The Pandas DataFrame Agent relies on access to a Python REPL (Read-Eval-Print Loop) tool, which allows the execution of arbitrary code. This can be dangerous and requires a specially sandboxed environment to be used safely.\n",
    ">\n",
    "> Failure to run this code in a properly sandboxed environment can lead to arbitrary code execution vulnerabilities, which can result in data breaches, data loss, or other security incidents.\n",
    ">\n",
    "> To mitigate these risks:\n",
    "> - Do not use this code with untrusted inputs or in environments with elevated permissions.\n",
    "> - Opt-in to this functionality explicitly by setting `allow_dangerous_code=True`.\n",
    "\n",
    "<br>\n",
    "\n",
    "`Let's see that in action using the widely known Iris dataset!`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth         Name\n",
       "0          5.1         3.5          1.4         0.2  Iris-setosa\n",
       "1          4.9         3.0          1.4         0.2  Iris-setosa\n",
       "2          4.7         3.2          1.3         0.2  Iris-setosa\n",
       "3          4.6         3.1          1.5         0.2  Iris-setosa\n",
       "4          5.0         3.6          1.4         0.2  Iris-setosa"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the function to create an agent that works with pandas DataFrames\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "\n",
    "# Import the pandas library for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Read the Iris dataset from the provided URL into a pandas DataFrame\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/iris.data')\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the data has been loaded correctly\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a ChatOpenAI model with specific parameters\n",
    "model_openai = ChatOpenAI(\n",
    "    model='gpt-4o-mini',  # Specify the model to use\n",
    "    temperature=0         # Set the temperature to 0 for deterministic responses\n",
    ") \n",
    "\n",
    "# Create a pandas dataframe agent using the specified LLM model and dataframe\n",
    "pandas_agent = create_pandas_dataframe_agent(\n",
    "    llm=model_openai,             # Pass the initialized ChatOpenAI model\n",
    "    df=df,                        # Provide the dataframe to be used by the agent\n",
    "    verbose=True,                 # Enable verbose mode for detailed logging\n",
    "    agent_type='openai-tools',    # Specify the type of agent to create\n",
    "    allow_dangerous_code=True     # Opt-in to allow the use of the REPL tool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': 'df.shape'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m(150, 5)\u001b[0m\u001b[32;1m\u001b[1;3mThe dataset has 150 rows and 5 columns.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = pandas_agent.invoke(\"How many rows and columns does this dataset have?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'How many rows and columns does this dataset have?',\n",
       " 'output': 'The dataset has 150 rows and 5 columns.'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df['Name'].value_counts()\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mName\n",
      "Iris-setosa        50\n",
      "Iris-versicolor    50\n",
      "Iris-virginica     50\n",
      "Name: count, dtype: int64\u001b[0m\u001b[32;1m\u001b[1;3mThe dataset contains the following counts of each species:\n",
      "\n",
      "- Iris-setosa: 50\n",
      "- Iris-versicolor: 50\n",
      "- Iris-virginica: 50\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = pandas_agent.invoke(\"How many of each species are in this dataset?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains the following counts of each species:\n",
      "\n",
      "- Iris-setosa: 50\n",
      "- Iris-versicolor: 50\n",
      "- Iris-virginica: 50\n"
     ]
    }
   ],
   "source": [
    "print(output['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df.groupby('Name')['SepalLength'].mean()\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mName\n",
      "Iris-setosa        5.006\n",
      "Iris-versicolor    5.936\n",
      "Iris-virginica     6.588\n",
      "Name: SepalLength, dtype: float64\u001b[0m\u001b[32;1m\u001b[1;3mThe average sepal length of each species is as follows:\n",
      "\n",
      "- **Iris-setosa**: 5.006\n",
      "- **Iris-versicolor**: 5.936\n",
      "- **Iris-virginica**: 6.588\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = pandas_agent.invoke(\"What is the average sepal length of each species?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average sepal length of each species is as follows:\n",
      "\n",
      "- **Iris-setosa**: 5.006\n",
      "- **Iris-versicolor**: 5.936\n",
      "- **Iris-virginica**: 6.588\n"
     ]
    }
   ],
   "source": [
    "print(output['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name\n",
       "Iris-setosa        5.006\n",
       "Iris-versicolor    5.936\n",
       "Iris-virginica     6.588\n",
       "Name: SepalLength, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Name')['SepalLength'].mean() # To confirm the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output\n",
    "In some cases, it can be beneficial to constrain the LLM's output to a specific format or structure, even though LLMs are capable of generating arbitrary text. This is known as structured output, and it is particularly useful when the output needs to be stored in a relational database or when extracting specific information from unstructured text.\n",
    "\n",
    "### .with_structured_output() Method\n",
    "LangChain provides a convenient `.with_structured_output()` method for some chat models that support structured output. This method takes a schema as input and returns a dict or Pydantic object. It handles the necessary prompting and output parsing under the hood, making it a good starting point when working with structured output.\n",
    "\n",
    "> **Note:** If the chat model you are using does not support tool calling or if you are working with very complex schemas, you may need to use other techniques for generating structured output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other ways to get structured outputs\n",
    "\n",
    "#### JSON Mode\n",
    "Some models, such as Mistral, OpenAI, Together AI, and Ollama, support a feature called JSON mode. When enabled, JSON mode constrains the model's output to always be valid JSON. This mode often requires some custom prompting, but it is generally simpler to use directly and more commonly available than tool calling.\n",
    "\n",
    "#### Tool Calling for Structured Output\n",
    "For models that support it, tool calling can be a convenient way to generate structured output. By binding the desired schema to a chat model using the `.bind_tools()` method, the model will generate an `AIMessage` containing a `tool_calls` field with args that match the desired shape.\n",
    "\n",
    "Tool calling provides a consistent way to get a model to generate structured output and is the default technique used for the `.with_structured_output()` method when a model supports it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Model to Extract Structured Information\n",
    "\n",
    "To extract information from text according to predefined schemas, we can explore the `ChatOpenAI` model in combination with the `.with_structured_output()` method. This approach allows us to:\n",
    "\n",
    "1. **Prompt the model** with our specific requirements and guidelines for extracting the desired information.\n",
    "2. **Parse the model's output** to match the structure defined by our schemas.\n",
    "\n",
    "#### How It Works\n",
    "\n",
    "1. **Define the Schema**: First, we need to define the schema that outlines the structure and format of the information we want to extract. The schema serves as a template, specifying the fields and data types expected in the output.\n",
    "\n",
    "2. **Prepare the Prompt**: Next, we craft a prompt that instructs the model on how to extract the information according to the defined schema. The prompt should provide clear guidelines and examples to guide the model's output.\n",
    "\n",
    "3. **Call the `.with_structured_output()` Method**: We pass the prompt and the defined schema to the `.with_structured_output()` method of the `ChatOpenAI` model. This method handles the interaction with the model, sending the prompt and receiving the generated output.\n",
    "\n",
    "4. **Parse the Output**: The `.with_structured_output()` method automatically parses the model's output to match the structure specified by the schema. It extracts the relevant information and organizes it according to the defined fields and data types.\n",
    "\n",
    "#### Benefits of Using `.with_structured_output()`\n",
    "\n",
    "- **Simplified Prompting**: The `.with_structured_output()` method abstracts away the complexities of crafting prompts for structured output. We only need to provide the schema and the prompt, and the method handles the rest.\n",
    "\n",
    "- **Automatic Parsing**: The method automatically parses the model's output to match the defined schema. This saves us the effort of manually extracting and organizing the information from the generated text.\n",
    "\n",
    "- **Consistent Output Structure**: By using a predefined schema, we ensure that the extracted information follows a consistent structure across different inputs. This makes it easier to process and use the extracted data in downstream tasks.\n",
    "\n",
    "\n",
    "#### Benefits of Structured Output\n",
    "Structured output provides several advantages:\n",
    "- **Consistency**: Ensures that the data follows a specific format, which reduces errors when processing the data.\n",
    "- **Ease of Storage**: Structured data can be easily stored in databases and other storage systems.\n",
    "- **Simplified Parsing**: Extracting specific information from structured data is more straightforward compared to unstructured text.\n",
    "\n",
    "#### Potential Challenges\n",
    "While structured output offers many benefits, there are also challenges to consider:\n",
    "- **Model Limitations**: Not all models support structured output, which may limit the applicability of certain methods.\n",
    "- **Complex Schemas**: Handling very complex schemas might require custom solutions beyond the built-in methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical Example 1 - Zero-Shot Named Entity Recognition\n",
    "\n",
    "> But... What is Zero-Shot Learning?\n",
    ">\n",
    "> Zero-shot learning (ZSL) is a machine learning pattern where a model is trained to recognize and categorize data it has never seen before. Unlike traditional learning methods that require labeled examples for each class during training, zero-shot learning leverages auxiliary information to make predictions about new, unseen classes.\n",
    ">\n",
    "\n",
    "Let's consider a practical example where we need to extract structured information from a legal text. This involves defining schemas for different entities such as medications, legislation, and public entities, and then using a language model to extract this information.\n",
    "\n",
    "To systematically extract information, we'll use Pydantic to define schemas for the entities we are interested in. This ensures that the extracted information is structured and standardized.\n",
    "\n",
    "- **Key Entities and Their Schemas**\n",
    "    - **Medication**: This schema will capture information about medications mentioned in the text. It might include fields like the name of the medication, dosage, and any relevant notes.\n",
    "    - **Legislation**: This schema will cover details about any legislation referenced in the text. Fields might include the name of the legislation, the section referenced, and a brief description.\n",
    "    - **PublicEntity**: This schema will gather information about public entities mentioned, such as government agencies or public officials. Fields might include the name of the entity, its role, and any relevant details.\n",
    "\n",
    "\n",
    "**Understanding Schemas**\n",
    "Schemas act as blueprints for the data we want to extract. By defining schemas, we can ensure that the data is consistent and follows a predefined format. This is particularly useful in natural language processing (NLP) tasks where the text can be ambiguous or varied.\n",
    "\n",
    "**Why Use Pydantic?**\n",
    "Pydantic is a library for data validation and settings management using Python type annotations. It allows us to define schemas in a declarative way, making our code more readable and maintainable. Pydantic also ensures that the extracted data adheres to the defined types, reducing the risk of errors.\n",
    "\n",
    "\n",
    "> Remember, the goal of defining schemas and using a language model for NER is to transform unstructured text into structured, actionable data. This structured data can then be used for various downstream tasks, enhancing both the efficiency and effectiveness of legal text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import Optional, List\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the ChatOpenAI model with specific parameters\n",
    "model_openai = ChatOpenAI(\n",
    "    model='gpt-4o-mini', \n",
    "    temperature=0\n",
    ") \n",
    "\n",
    "class Medication(BaseModel):\n",
    "    \"\"\"Information about a mentioned medication. Does not include supplements or food/nutritional formulas.\"\"\"\n",
    "    \n",
    "    # The commercial name of the medication, if available\n",
    "    commercial_name: Optional[str] = Field(default_factory=str, description=\"The commercial name of the medication\") \n",
    "    # The pharmacologically active ingredient of the medication, without the salt name, if available\n",
    "    active_ingredient: Optional[str] = Field(\n",
    "        default_factory=str, description=\"The pharmacologically active ingredient of the medication, without the salt name.\"\n",
    "    ) \n",
    "    # The dosage of the medication, if available\n",
    "    dosage: Optional[str] = Field(\n",
    "        default_factory=str, description=\"The dosage of the medication\"\n",
    "    ) \n",
    "\n",
    "class Legislation(BaseModel):\n",
    "    \"\"\"Information about a mentioned legislation.\"\"\"\n",
    "    \n",
    "    # The number of the legislation, if available\n",
    "    number: Optional[str] = Field(default_factory=str, description=\"The number of the legislation\") \n",
    "    # The year the legislation was enacted, if available\n",
    "    year: Optional[str] = Field(default_factory=str, description=\"The year of the legislation\") \n",
    "    # The article of the legislation, if available\n",
    "    article: Optional[str] = Field(default_factory=str, description=\"The article of the legislation\") \n",
    "    # The item of the legislation, if available\n",
    "    item: Optional[str] = Field(default_factory=str, description=\"The item of the legislation\") \n",
    "    # The paragraph of the legislation, if available\n",
    "    paragraph: Optional[str] = Field(default_factory=str, description=\"The paragraph of the legislation\") \n",
    "\n",
    "class PublicEntity(BaseModel):\n",
    "    \"\"\"Information about a mentioned public entity.\"\"\"\n",
    "    \n",
    "    # The name of the public entity, if available\n",
    "    name: Optional[str] = Field(default_factory=str, description=\"The name of the public entity\") \n",
    "    # The acronym of the public entity, if available\n",
    "    acronym: Optional[str] = Field(default_factory=str, description=\"The acronym of the public entity\") \n",
    "\n",
    "class InformationExtractonResponse(BaseModel):\n",
    "    \"\"\"The response of a function that extracts information from a legal text.\"\"\"\n",
    "    \n",
    "    # A list of mentioned medications in the legal text, if any\n",
    "    medications: Optional[List[Medication]] = Field(default_factory=list, description=\"A list with mentioned medications\") \n",
    "    # A list of mentioned legislations in the legal text, if any\n",
    "    legislation: Optional[List[Legislation]] = Field(default_factory=list, description=\"A list with mentioned legislations\") \n",
    "    # A list of mentioned public entities in the legal text, if any\n",
    "    public_entities: Optional[List[PublicEntity]] = Field(default_factory=list, description=\"A list with mentioned public entities\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the `ChatOpenAI` model with the `.with_structured_output()` method to extract information according to our defined schemas. This method will handle the prompting and parsing of the output to match our schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a variable to hold the OpenAI model with structured output capabilities\n",
    "model_extractor_openai = model_openai.with_structured_output(InformationExtractonResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"Passo a analisar o pedido de tutela antecipada.\n",
    "A Lei no 10.259, de 12/7/2001, em seu art. 4o, por sua vez, autoriza a concessão, “ex officio”, de medida cautelar, provimento de urgência que tem cunho eminentemente de decisão antecipatória dos efeitos da tutela de mérito.\n",
    "No caso específico das obrigações de fazer e de não fazer, a antecipação dos efeitos da tutela está disciplinada no art. 461, § 3o, do Código de Processo Civil, o qual estabelece dois pressupostos para seu deferimento: relevância do fundamento da demanda (fumaça do bom direito) e justificado receio de ineficácia do provimento final (perigo da demora).\n",
    "Na hipótese presente, por todos os fundamentos já expostos, é patente relevância do fundamento da demanda, até porque se está julgando procedente o pedido. A ocorrência de perigo de dano irreparável ou de difícil reparação (segundo requisito necessário à concessão da medida urgente) caracteriza-se pela necessidade de fazer uso do mencionado medicamento em face do seu estado de saúde.\n",
    "Ante às razões invocadas, julgo procedente o pedido (art. 269, I do CPC), para: a) antecipar a tutela e condenar o ESTADO DO RIO GRANDE DO NORTE na obrigação de fornecer à parte autora os medicamentos CENTRUM, PANTAZOL(20 mg), RÉVIA (50mg), PROCIMAX, NEURAL(25mg), DIAZEPAN(10mg) e SUBUTRAMINA, na forma prescrita nos atestados médicos constantes dos autos, no prazo de 10 dias, independentemente de qualquer transferência de verbas da União e do Município, sob pena de multa diária por descumprimento no montante de R$ 100,00; b) para condenar a UNIÃO FEDERAL e o MUNICÍPIO DE NATAL no custeio, cada um, de 1/3 dos recursos necessários para aquisição do medicamento, o que deverá ser realizado através de compensação/transferência entre recursos no âmbito do SUS.\n",
    "Defiro o benefício de justiça gratuita pleiteado. Sem custas e honorários advocatícios (art. 55 da Lei no 9.099/95).\n",
    "Registro da sentença decorre de sua validação no sistema virtual\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model_extractor_openai.invoke(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InformationExtractonResponse(medications=[Medication(commercial_name='CENTRUM', active_ingredient='', dosage=''), Medication(commercial_name='PANTAZOL', active_ingredient='', dosage='20 mg'), Medication(commercial_name='RÉVIA', active_ingredient='', dosage='50 mg'), Medication(commercial_name='PROCIMAX', active_ingredient='', dosage=''), Medication(commercial_name='NEURAL', active_ingredient='', dosage='25 mg'), Medication(commercial_name='DIAZEPAN', active_ingredient='', dosage='10 mg'), Medication(commercial_name='SUBUTRAMINA', active_ingredient='', dosage='')], legislation=[Legislation(number='10.259', year='2001', article='4', item='', paragraph=''), Legislation(number='CPC', year='', article='461', item='', paragraph='3'), Legislation(number='9.099', year='1995', article='55', item='', paragraph='')], public_entities=[PublicEntity(name='ESTADO DO RIO GRANDE DO NORTE', acronym=''), PublicEntity(name='UNIÃO FEDERAL', acronym=''), PublicEntity(name='MUNICÍPIO DE NATAL', acronym='')])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'medications': [{'commercial_name': 'CENTRUM',\n",
       "   'active_ingredient': '',\n",
       "   'dosage': ''},\n",
       "  {'commercial_name': 'PANTAZOL', 'active_ingredient': '', 'dosage': '20 mg'},\n",
       "  {'commercial_name': 'RÉVIA', 'active_ingredient': '', 'dosage': '50 mg'},\n",
       "  {'commercial_name': 'PROCIMAX', 'active_ingredient': '', 'dosage': ''},\n",
       "  {'commercial_name': 'NEURAL', 'active_ingredient': '', 'dosage': '25 mg'},\n",
       "  {'commercial_name': 'DIAZEPAN', 'active_ingredient': '', 'dosage': '10 mg'},\n",
       "  {'commercial_name': 'SUBUTRAMINA', 'active_ingredient': '', 'dosage': ''}],\n",
       " 'legislation': [{'number': '10.259',\n",
       "   'year': '2001',\n",
       "   'article': '4',\n",
       "   'item': '',\n",
       "   'paragraph': ''},\n",
       "  {'number': 'CPC',\n",
       "   'year': '',\n",
       "   'article': '461',\n",
       "   'item': '',\n",
       "   'paragraph': '3'},\n",
       "  {'number': '9.099',\n",
       "   'year': '1995',\n",
       "   'article': '55',\n",
       "   'item': '',\n",
       "   'paragraph': ''}],\n",
       " 'public_entities': [{'name': 'ESTADO DO RIO GRANDE DO NORTE', 'acronym': ''},\n",
       "  {'name': 'UNIÃO FEDERAL', 'acronym': ''},\n",
       "  {'name': 'MUNICÍPIO DE NATAL', 'acronym': ''}]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practical Example 2: Zero-Shot Text Classification\n",
    "\n",
    "Zero-shot text classification is a powerful technique where a model classifies text without needing prior training on specific categories. Instead, we define a schema representing different classes or categories, and the model generates output that aligns with this schema. This approach is flexible and can be adapted to various classification tasks.\n",
    "\n",
    "In this example, we will perform zero-shot sentiment analysis on hypothetical reviews of our classes. We will define a schema for sentiment analysis with two categories: positive and negative. Here are our steps:\n",
    "\n",
    "1. **Define the Schema**:\n",
    "    - **Positive**: Reviews that express satisfaction or approval.\n",
    "    - **Negative**: Reviews that express dissatisfaction or disapproval.\n",
    "\n",
    "2. **Prompting the Model**:\n",
    "    - We input the text we want to classify into the model.\n",
    "    - The model generates output that matches either the positive or negative category based on the schema.\n",
    "\n",
    "**Example Scenario**:\n",
    "\n",
    "Imagine you have received the following review for your class:\n",
    "\n",
    "*\"The content was well-structured and engaging, but the pace was a bit too fast.\"*\n",
    "\n",
    "Using zero-shot text classification, the model will analyze this review and classify it based on the defined schema. This method allows for flexible and efficient classification of text data, even when dealing with categories the model has not been explicitly trained on. It ensures that the classification process is streamlined and adaptable to various contexts and requirements.\n",
    "\n",
    "\n",
    "> **Note**: If you have any real negative feedback, [please let me know](https://jacob.al/feedbacks) so I can improve! I am as much a learner as you are! 😄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_feedbacks = [\n",
    "    \"A aula foi muito entediante e difícil de acompanhar.\",\n",
    "    \"Não gostei da forma como o conteúdo foi apresentado.\",\n",
    "    \"O professor não explicou bem os conceitos.\",\n",
    "    \"Achei o material de apoio confuso e desorganizado.\",\n",
    "    \"A aula foi muito longa e cansativa.\",\n",
    "    \"Não consegui entender a maioria dos tópicos abordados.\",\n",
    "    \"A metodologia de ensino não foi eficaz para mim.\",\n",
    "    \"As atividades práticas não ajudaram a fixar o conteúdo.\",\n",
    "    \"O professor é horrível, deveria ser expulso da UFRN\",\n",
    "    \"A interação com os alunos foi muito limitada.\"\n",
    "]\n",
    "\n",
    "positive_feedbacks = [\n",
    "    \"A aula foi extremamente informativa e bem estruturada.\",\n",
    "    \"Gostei muito da didática do professor.\",\n",
    "    \"Os exemplos práticos foram muito úteis para entender o conteúdo.\",\n",
    "    \"O material de apoio estava bem organizado e claro.\",\n",
    "    \"A aula foi dinâmica e cativante.\",\n",
    "    \"Consegui entender todos os tópicos abordados.\",\n",
    "    \"A metodologia de ensino foi muito eficaz.\",\n",
    "    \"As atividades práticas ajudaram a consolidar o aprendizado.\",\n",
    "    \"O professor é uma gracinha, queria levar pra casa\",\n",
    "    \"A interação com os alunos foi excelente.\"\n",
    "]\n",
    "\n",
    "unlabelled_feedbacks = positive_feedbacks + negative_feedbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentAnalysisResponse(sentiment='positive')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import Optional, List, Literal\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the ChatOpenAI model with specific parameters\n",
    "model_openai = ChatOpenAI(\n",
    "    model='gpt-4o-mini', \n",
    "    temperature=0\n",
    ") \n",
    "\n",
    "class SentimentAnalysisResponse(BaseModel):\n",
    "    \"\"\"The response of a function that performs sentiment analysis on text.\"\"\"\n",
    "    \n",
    "    # The sentiment label assigned to the text\n",
    "    sentiment: Literal['positive', 'negative'] = Field(default_factory=str, description=\"The sentiment label assigned to the text. You can only have 'positive' or 'negative' as values.\")\n",
    "    \n",
    "\n",
    "model_sentiment_openai = model_openai.with_structured_output(SentimentAnalysisResponse)\n",
    "\n",
    "output = model_sentiment_openai.invoke(\"A aula foi muito boa e esclarecedora.\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback: A aula foi extremamente informativa e bem estruturada.\n",
      "Sentiment: sentiment='positive'\n",
      "---\n",
      "Feedback: Gostei muito da didática do professor.\n",
      "Sentiment: sentiment='positive'\n",
      "---\n",
      "Feedback: Os exemplos práticos foram muito úteis para entender o conteúdo.\n",
      "Sentiment: sentiment='positive'\n",
      "---\n",
      "Feedback: O material de apoio estava bem organizado e claro.\n",
      "Sentiment: sentiment='positive'\n",
      "---\n",
      "Feedback: A aula foi dinâmica e cativante.\n",
      "Sentiment: sentiment='positive'\n",
      "---\n",
      "Feedback: Consegui entender todos os tópicos abordados.\n",
      "Sentiment: sentiment='positive'\n",
      "---\n",
      "Feedback: A metodologia de ensino foi muito eficaz.\n",
      "Sentiment: sentiment='positive'\n",
      "---\n",
      "Feedback: As atividades práticas ajudaram a consolidar o aprendizado.\n",
      "Sentiment: sentiment='positive'\n",
      "---\n",
      "Feedback: O professor é uma gracinha, queria levar pra casa\n",
      "Sentiment: sentiment='positive'\n",
      "---\n",
      "Feedback: A interação com os alunos foi excelente.\n",
      "Sentiment: sentiment='positive'\n",
      "---\n",
      "Feedback: A aula foi muito entediante e difícil de acompanhar.\n",
      "Sentiment: sentiment='negative'\n",
      "---\n",
      "Feedback: Não gostei da forma como o conteúdo foi apresentado.\n",
      "Sentiment: sentiment='negative'\n",
      "---\n",
      "Feedback: O professor não explicou bem os conceitos.\n",
      "Sentiment: sentiment='negative'\n",
      "---\n",
      "Feedback: Achei o material de apoio confuso e desorganizado.\n",
      "Sentiment: sentiment='negative'\n",
      "---\n",
      "Feedback: A aula foi muito longa e cansativa.\n",
      "Sentiment: sentiment='negative'\n",
      "---\n",
      "Feedback: Não consegui entender a maioria dos tópicos abordados.\n",
      "Sentiment: sentiment='negative'\n",
      "---\n",
      "Feedback: A metodologia de ensino não foi eficaz para mim.\n",
      "Sentiment: sentiment='negative'\n",
      "---\n",
      "Feedback: As atividades práticas não ajudaram a fixar o conteúdo.\n",
      "Sentiment: sentiment='negative'\n",
      "---\n",
      "Feedback: O professor é horrível, deveria ser expulso da UFRN\n",
      "Sentiment: sentiment='negative'\n",
      "---\n",
      "Feedback: A interação com os alunos foi muito limitada.\n",
      "Sentiment: sentiment='negative'\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for feedback in unlabelled_feedbacks:\n",
    "    output = model_sentiment_openai.invoke(feedback)\n",
    "    print(f\"Feedback: {feedback}\")\n",
    "    print(f\"Sentiment: {output}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, structured output is a powerful feature that can be used as a zero-shot tool to extract specific information from text and ensure that it follows a predefined format. We can also use these schemas to perform zero-shot text classification. By defining schemas and using the appropriate methods, you can exploit structured output to enhance the capabilities of language models and automate information extraction tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "1. What is agentic behavior in the context of language models (LLMs)?\n",
    "\n",
    "2. What role does LangChain play in creating agents with LLMs?\n",
    "\n",
    "3. What are some examples of agent architectures mentioned in the class?\n",
    "\n",
    "4. What is tool/function calling and why is it important for LLMs?\n",
    "\n",
    "5. What is the general flow for using tool calling with LLMs?\n",
    "\n",
    "6. What is structured output, and how is it useful?\n",
    "\n",
    "7. What are some practical implementations of agentic behavior and tool calling demonstrated in the class?\n",
    "\n",
    "8. What is the role of the AgentExecutor in LangChain?\n",
    "\n",
    "9. Why is it important to consider security effects when using DataFrame agents or other powerful tools?\n",
    "\n",
    "10. How does the `.with_structured_output()` method in LangChain help in generating structured output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Answers are commented inside this cell`\n",
    "\n",
    "<!-- - Agentic behavior refers to the ability of language models to perform goal-directed actions autonomously based on inputs and context, allowing them to make decisions and take actions without direct human intervention.\n",
    "\n",
    "- LangChain facilitates the creation of agents by using LLMs as reasoning engines to determine necessary actions and inputs, enabling more complex and autonomous decision-making processes.\n",
    "\n",
    "- The class mentions several agent architectures, including ReAct, BabyAGI, and MRKL.\n",
    "\n",
    "- Tool/function calling refers to the ability of LLMs to interact with external tools and resources, extending their capabilities beyond text generation. It enables LLMs to perform a wider range of tasks and handle complex queries by breaking them down into smaller, manageable steps.\n",
    "\n",
    "- The general flow involves generating tool calls with a chat model, invoking the appropriate tools, formatting the results as ToolMessages, and passing the messages back to the model to generate a final answer.\n",
    "\n",
    "- Structured output constrains the LLM's output to a specific format or structure, which is useful for data storage, information extraction, and ensuring consistent data formats.\n",
    "\n",
    "- The class demonstrates practical implementations using the LangChain framework with OpenAI and local Llama 3.1 models, including examples of fetching financial data, creating agents that interact with Pandas DataFrames, and extracting structured information from text.\n",
    "\n",
    "- The AgentExecutor is a runtime that executes the actions determined by the Agent, enabling the creation of autonomous systems that can interact with external tools and resources.\n",
    "\n",
    "- It is important to consider security effects because allowing arbitrary code execution can lead to vulnerabilities such as data breaches or data loss. Proper sandboxing techniques should be used to mitigate these risks.\n",
    "\n",
    "- The `.with_structured_output()` method takes a schema as input and returns a dict or Pydantic object. It handles the necessary prompting and output parsing, ensuring that the LLM's output adheres to the specified format and structure. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
