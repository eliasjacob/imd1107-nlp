{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG)\n",
    "## IMD1107 - Natural Language Processing\n",
    "### [Dr. Elias Jacob de Menezes Neto](htttps://docente.ufrn.br/elias.jacob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Keypoints\n",
    "\n",
    "- Retrieval-Augmented Generation (RAG) enhances traditional generative models by integrating information retrieval systems.\n",
    "\n",
    "- RAG addresses challenges like limited knowledge scope, factual inaccuracy, and contextual irrelevance in generative AI.\n",
    "\n",
    "- The RAG architecture consists of a retriever component to search external knowledge sources and a generator to produce responses.\n",
    "\n",
    "- Vector databases like ChromaDB are used to efficiently store and query embedding data for RAG systems.\n",
    "\n",
    "- Proper chunking of documents is crucial for effective storage and retrieval in RAG systems.\n",
    "\n",
    "- Different embedding models and LLMs can be combined to create varied RAG implementations.\n",
    "\n",
    "### Takeaways\n",
    "\n",
    "- RAG systems significantly improve the accuracy and relevance of AI-generated responses by leveraging external knowledge.\n",
    "\n",
    "- Careful consideration of chunking strategies, embedding models, and retrieval methods is essential for optimal RAG performance.\n",
    "\n",
    "- The choice of vector database and embedding model impacts the efficiency and effectiveness of information retrieval.\n",
    "\n",
    "- Integrating retrievers with LLMs using tools like LangChain enables flexible and powerful RAG implementations.\n",
    "\n",
    "- Maximum Marginal Relevance (MMR) search can enhance result diversity and reduce redundancy in retrieved information.\n",
    "\n",
    "- RAG systems can be adapted for various domains and use cases, making them versatile for knowledge-intensive AI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "## Definition and Concept\n",
    "Retrieval-Augmented Generation (RAG) is a powerful AI framework that enhances the capabilities of traditional generative models by integrating information retrieval systems. This combination allows RAG to generate text that is not only coherent and contextually relevant but also accurate and up-to-date. By leveraging the strengths of both retrieval and generation, RAG provides a robust solution for various applications requiring precise and contextually enriched information.\n",
    "\n",
    "### Key Principles of RAG\n",
    "- Retrieval of relevant information from an external knowledge base\n",
    "- Assimilation of retrieved information into the generation process\n",
    "- Improved context awareness and factual accuracy in generated outputs\n",
    "- Enhanced flexibility and scalability through external knowledge sources\n",
    "- Real-time access to up-to-date information for dynamic applications\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What problems does RAG solve?\n",
    "\n",
    "Retrieval-Augmented Generation (RAG) addresses several key challenges in the field of natural language processing (NLP) and artificial intelligence (AI). Below are some of the primary problems that RAG aims to solve:\n",
    "\n",
    "1. Limited Knowledge Scope of Generative Models\n",
    "    - **Problem**: Traditional generative models (e.g., GPT-3) are limited by the static knowledge they acquired during their training phase. They cannot access or utilize information that was not included in their training data, making them less effective in providing up-to-date or domain-specific information.\n",
    "    - **RAG Solution**: RAG incorporates an information retrieval component that allows the model to fetch relevant, up-to-date information from external knowledge sources. This expands the knowledge base beyond the training data and enables the generation of more current and relevant content.\n",
    "\n",
    "2. Factual Inaccuracy\n",
    "    - **Problem**: Generative models can produce text that is grammatically correct and coherent but factually incorrect. This is particularly problematic in applications where accuracy is critical, such as healthcare, legal advice, and academic writing.\n",
    "    - **RAG Solution**: By retrieving factual information from reliable external sources and integrating it into the generation process, RAG enhances the factual accuracy of the generated text. This ensures that the responses are not only linguistically sound but also factually correct.\n",
    "\n",
    "3. Contextual Irrelevance\n",
    "    - **Problem**: Generative models often struggle with maintaining context, especially in multi-turn conversations or complex queries. They may provide responses that are contextually irrelevant or inconsistent with previous information.\n",
    "    - **RAG Solution**: The retrieval component of RAG allows the model to consider a broader and more relevant context, leading to more coherent and contextually appropriate responses. This is particularly beneficial for dialogue systems and complex question-answering tasks.\n",
    "\n",
    "4. Data Sparsity and Training Limitations\n",
    "    - **Problem**: Generative models require large amounts of diverse training data to perform well across different domains. However, gathering and curating such extensive datasets can be resource-intensive and time-consuming.\n",
    "    - **RAG Solution**: RAG reduces the reliance on extensive training data by leveraging external knowledge bases. This means that even with less training data, RAG can still perform effectively across various topics and domains by retrieving and using relevant external information.\n",
    "\n",
    "5. Inflexibility and Scalability\n",
    "    - **Problem**: Traditional models need to be retrained to incorporate new information or adapt to different domains, which can be a costly and time-consuming process.\n",
    "    - **RAG Solution**: RAG systems can be easily updated by modifying the external knowledge source without requiring retraining of the entire model. This makes RAG more flexible and adaptable to new information and different domains, enhancing its scalability.\n",
    "\n",
    "6. Real-Time Information Retrieval\n",
    "    - **Problem**: Many applications require real-time access to the most current information. Traditional generative models, which rely solely on pre-trained data, cannot meet this demand effectively.\n",
    "    - **RAG Solution**: RAG's retrieval mechanism enables real-time access to the latest information, making it suitable for applications that require immediate and current responses, such as news generation or real-time customer support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages of RAG\n",
    "RAG offers several advantages over traditional generation methods:\n",
    "\n",
    "1. **Enhanced Factual Accuracy**: By retrieving relevant information from a reliable external source, RAG can generate responses that are more factually accurate and consistent with real-world knowledge.\n",
    "\n",
    "2. **Improved Context Awareness**: The retrieval component allows RAG to consider a wider range of contextual information, enabling it to generate more coherent and contextually appropriate responses.\n",
    "\n",
    "3. **Reduced Reliance on Training Data**: RAG can capitalize on external knowledge sources, reducing the need for extensive training data to cover a wide range of topics and domains.\n",
    "\n",
    "4. **Flexibility and Adaptability**: RAG systems can be easily adapted to different domains or updated with new knowledge by modifying the external knowledge source, without requiring retraining of the entire model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Use Cases and Applications\n",
    "RAG finds applications in various real-world scenarios where accurate and contextually relevant language generation is crucial:\n",
    "\n",
    "- **Question Answering**: RAG can retrieve relevant information to provide accurate and informative answers to user queries.\n",
    "\n",
    "- **Dialogue Systems**: RAG enables more engaging and contextually appropriate conversations in chatbots and virtual assistants.\n",
    "\n",
    "- **Content Generation**: RAG can assist in generating articles, summaries, or descriptions by retrieving relevant facts and details from external sources.\n",
    "\n",
    "- **Knowledge-Intensive Tasks**: RAG is particularly useful in domains that require access to a large amount of factual knowledge, such as healthcare, finance, or legal services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Architecture and Overview\n",
    "\n",
    "## Components of a RAG System\n",
    "A typical RAG system consists of two main components:\n",
    "\n",
    "1. **Retriever**: The retriever is responsible for searching and retrieving relevant information from an external knowledge source based on the input query or context. It uses techniques like similarity search or information retrieval to find the most relevant pieces of information.\n",
    "\n",
    "2. **Generator**: The generator is a language model that takes the retrieved information as input and generates the final output response. It integrates the retrieved knowledge into the generation process to produce informative and contextually appropriate responses.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"images/rag.webp\" alt=\"\" style=\"width: 50%; height: 50%\"/>\n",
    "</p>\n",
    " \n",
    "The diagram illustrates the components and workflow of a Retrieval-Augmented Generation (RAG) application. Here’s a detailed explanation of each component:\n",
    "\n",
    "### Data Preparation\n",
    "1. **Raw Data Sources (A)**: This is the initial stage where raw data is collected from various sources such as documents, PDFs, web pages, etc.\n",
    "\n",
    "2. **Information Extraction (B)**: This step involves extracting relevant information from the raw data. Techniques like Optical Character Recognition (OCR), PDF data extraction, and web crawlers are used to convert unstructured data into a structured format.\n",
    "\n",
    "3. **Chunking (C)**: The extracted information is then divided into smaller, manageable chunks. This process helps in handling large documents and ensures that the data can be processed efficiently.\n",
    "\n",
    "4. **Embedding (D)**: Each chunk of data is converted into a vector representation (embedding). This numerical representation captures the semantic meaning of the text, making it easier to compare and retrieve relevant information.\n",
    "\n",
    "### Retrieval-Augmented Generation (RAG) Workflow\n",
    "1. **Query (1)**: A user query is received, which initiates the RAG process.\n",
    "\n",
    "2. **Embedding (2)**: The query is also converted into an embedding (vector representation) to assist comparison with the stored data embeddings.\n",
    "\n",
    "3. **Vector Database**: Both the data embeddings and the query embedding are stored and managed in a vector database. This specialized database is optimized for handling and retrieving vector data.\n",
    "\n",
    "4. **Relevant Data (3)**: The vector database is queried to find the most relevant data chunks that match the query embedding. These relevant data chunks are then retrieved.\n",
    "\n",
    "5. **LLM(s) (4)**: The retrieved relevant data is fed into a Large Language Model (LLM). The LLM uses this data to generate a response that is contextually accurate and relevant to the query.\n",
    "\n",
    "6. **Response (5)**: Finally, the generated response is provided to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Flow in RAG\n",
    "The data flow in a RAG system follows these steps:\n",
    "\n",
    "1. The input query or context is provided to the retriever.\n",
    "2. The retriever searches the external knowledge source and retrieves the most relevant information based on the input.\n",
    "3. The retrieved information is passed to the generator along with the input query or context.\n",
    "4. The generator integrates the retrieved knowledge into the generation process and produces the final output response.\n",
    "\n",
    "## Incorporation with LLMs\n",
    "RAG can be integrated with existing Large Language Models (LLMs) to enhance their generation capabilities. The retriever component can be added as a preprocessing step before feeding the input to the LLM. The retrieved information can be concatenated with the input or used to condition the LLM's generation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Databases\n",
    "\n",
    "A vector database is a specialized database designed to efficiently store and query embedding data, extending the capabilities of traditional relational databases. The key distinguishing feature of a vector database is that query results are not exact matches to the query. Instead, using a specified similarity metric, the vector database returns embeddings that are similar to the query. This makes vector databases ideal for applications that involve comparing and retrieving embeddings based on their similarity rather than exact values.\n",
    "\n",
    "## Example Use Case\n",
    "\n",
    "Suppose you have stored some information about UFRN, like recent news and legislation that applies to our undergrad students. You can embed this information and store it in a vector database. When a user asks a question about UFRN, the query is embedded and compared to the stored embeddings. The vector database returns the most similar embeddings, which can then be used to generate a response. The vector database will accept a query like `Com quantos dias de antecedência um professor deve divulgar os resultados de uma prova antes de aplicar a próxima prova?` and embed the query (using the same embedding model as the one used to populate the database). It will then compare the embedded query to other embeddings in the vector database and return the documents that have embeddings most similar to the query embedding.\n",
    "\n",
    "The vector database will identify the document that had an embedding most similar to the query, likely based on the document's semantics. With that information, the LLM can generate a response that is contextually relevant to the user's query and factually accurate based on the retrieved document.\n",
    "\n",
    "## Fundamental Components of a Vector Database\n",
    "\n",
    "To make efficient storage and querying of embeddings possible, vector databases are equipped with features that balance the speed and accuracy of query results. Here are the central components you should know about:\n",
    "\n",
    "1. **Embedding Function**: When using a vector database, you often store and query data in its raw form rather than uploading embeddings directly. Internally, the vector database needs to know how to convert your data to embeddings, and you have to specify an embedding function for this. For text, you can use embedding functions from libraries like SentenceTransformers or OpenAI's embedding models (or any other function that maps raw text to vectors).\n",
    "\n",
    "2. **Similarity Metric**: To assess embedding similarity, you need a similarity metric such as cosine similarity, dot product, or Euclidean distance. Choosing the right similarity metric depends on your specific application.\n",
    "\n",
    "3. **Indexing**: When dealing with a large number of embeddings, comparing a query embedding to every stored embedding can be too slow. Vector databases employ indexing algorithms that group similar embeddings together. At query time, the query embedding is compared to a smaller subset of embeddings based on the index. This is called approximate nearest neighbor search, as the recommended embeddings aren't guaranteed to have the highest similarity to the query.\n",
    "\n",
    "4. **Metadata**: You can store metadata with each embedding to provide context and make query results more precise. Metadata can be filtered much like in a relational database. For example, you could store the publication year of a document as metadata and only search for similar documents published in a specific year.\n",
    "\n",
    "5. **Storage Location**: Vector databases can store embeddings and metadata both in memory and on disk. In-memory storage allows for faster reads and writes, while disk storage is important for data persistence.\n",
    "\n",
    "6. **CRUD Operations**: Most vector databases support create, read, update, and delete (CRUD) operations, allowing you to maintain and interact with data similar to a relational database.\n",
    "\n",
    "> While there is much more detail and complexity to explore with vector databases, these central concepts provide a solid foundation to get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ChromaDB](https://www.trychroma.com/): A Vector Database for Embeddings\n",
    "\n",
    "ChromaDB is a specialized vector database designed for storing and querying embeddings. Built upon SQLite, a renowned relational database, ChromaDB utilizes the SQLite engine to efficiently manage the storage and retrieval of embeddings. This system provides a straightforward and user-friendly interface for handling embeddings and querying similar vectors. Below are some key features and details about ChromaDB:\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Efficient Storage**: ChromaDB utilizes SQLite's robust storage mechanisms to store embeddings efficiently. This ensures that large volumes of data can be handled without significant performance degradation.\n",
    "\n",
    "- **Querying Capabilities**: The database is optimized for querying similar vectors, which is essential for tasks involving embeddings, such as nearest neighbor searches and similarity computations.\n",
    "\n",
    "- **Intuitive Interface**: ChromaDB offers a simple and intuitive interface for managing embeddings, making it accessible for users with varying levels of database proficiency.\n",
    "\n",
    "\n",
    "### Running ChromaDB\n",
    "\n",
    "You can use ChromaDB in several ways:\n",
    "- Using a in-memory database, that will be lost when the program ends.\n",
    "- Using a file-based database, that will be persisted in a file.\n",
    "- Running as a server, that will allow you to query the database from other applications. For this, there are Docker images available.\n",
    "\n",
    "You can interact with ChromaDB using their Python library, their REST API or through LangChain, which has a built-in ChromaDB integration. For our class, we'll use a file-based database and LangChain to interact with ChromaDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building your RAG System with ChromaDB and LangChain\n",
    "\n",
    "We'll create a chatbot that has access to a knowledge base about UFRN. The chatbot will use a RAG system to retrieve information from the knowledge base and generate responses to user queries. We'll utilize ChromaDB to store and query embeddings of the knowledge base documents and LangChain to interact with ChromaDB and generate responses using a Large Language Model (LLM).\n",
    "\n",
    "For documents about UFRN, we'll use the following sources:\n",
    "- https://ufrn.br/imprensa/materias-especiais/80473/primeira-patente-da-ufrn-completa-uma-decada\n",
    "- https://ufrn.br/imprensa/materias-especiais/80657/design-de-aplicativo-na-escola\n",
    "- https://ufrn.br/imprensa/materias-especiais/80222/forro-na-ufrn-2\n",
    "- https://ufrn.br/imprensa/materias-especiais/79929/projeto-do-ceres-resgata-especies-nativas-da-caatinga\n",
    "- [Estatuto da UFRN](https://sigrh.ufrn.br/sigrh/public/colegiados/anexos/estatuto.pdf)\n",
    "- [Regulamento dos Cursos de Graduação](https://ufrn.br/resources/documentos/regulamentos/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf)\n",
    "- [Vídeo sobre o Restaurante Universitário](https://youtu.be/OHv-nx4ukZU?si=-uo5kd8OK_Zg7T9s)\n",
    "\n",
    "This way, we'll see how to use [LangChain Document Loaders](https://python.langchain.com/v0.2/docs/how_to/#document-loaders) to retrieve information from several types of sources and how to use ChromaDB to store and query embeddings of these documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Define our LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na Universidade Federal do Rio Grande do Norte (UFRN), o processo avaliativo pode ser organizado em até quatro avaliações ao longo do semestre. Essa estrutura é parte das diretrizes pedagógicas da instituição, que busca promover uma avaliação contínua e diversificada do aprendizado dos alunos. Para informações mais detalhadas e atualizadas, é sempre bom consultar o regulamento específico ou a coordenação do curso.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Load environment variables from a .env file into the environment\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the ChatOpenAI model with specific parameters\n",
    "# 'model' specifies the model to use, in this case 'gpt-4o-mini'\n",
    "# 'temperature' controls the randomness of the model's output, with 0 being deterministic\n",
    "model_openai = ChatOpenAI(\n",
    "    model='gpt-4o-mini',\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Invoke the model with a specific prompt/question\n",
    "response = model_openai.invoke(\"O processo avaliativo na UFRN pode ser organizado em até quantas avaliações?\")\n",
    "\n",
    "# Print the content of the response from the model\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A resposta é 5.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the ChatOllama model with specific parameters\n",
    "\n",
    "model_llama = ChatOllama(\n",
    "    model='llama3.1', # 'model' specifies the model to use, in this case 'llama3.1'\n",
    "    temperature=0, # 'temperature' controls the randomness of the model's output, with 0 being deterministic\n",
    "    base_url='http://localhost:11434' # 'base_url' specifies the base URL for the model's API endpoint\n",
    ")\n",
    "\n",
    "# Invoke the model with a specific prompt/question\n",
    "response = model_llama.invoke(\"O processo avaliativo na UFRN pode ser organizado em até quantas avaliações?\")\n",
    "\n",
    "# Print the content of the response from the model\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just wrong. According to article 100 of [this document](https://ufrn.br/resources/documentos/regulamentos/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf), the maximum number is 3.\n",
    "\n",
    ">> Art. 100. O processo avaliativo pode ser organizado em até 3 (três) unidades avaliativas\n",
    "\n",
    "OpenAI's model is very powerful, but doesn't really know the specifics of UFRN's regulations. That why it hallucinated a number that is not correct. We can use the LLM to generate the response, but we need to make sure the information is correct. This is one major advantage of using RAG systems.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Load the Documents\n",
    "\n",
    "To prepare the documents for use with ChromaDB, we need to follow these steps:\n",
    "\n",
    "- Downloading the Documents\n",
    "\n",
    "- Extracting Text from Documents\n",
    "\n",
    "- Splitting Text into Chunks\n",
    "- Determine an appropriate chunk size for your specific use case.\n",
    "- Consider factors like the desired granularity of information retrieval and the limitations of the basic storage system.\n",
    "- Implement a function to split the extracted text into smaller chunks based on the chosen chunk size.\n",
    "- Options include splitting by a fixed number of characters, sentences, or paragraphs.\n",
    "- Ensure that the chunks are meaningful and maintain coherence.\n",
    "- Store the resulting chunks in a list or any other suitable data structure.\n",
    "\n",
    "- Storing Chunks in ChromaDB\n",
    "- Initialize a connection to ChromaDB using the provided API or client library.\n",
    "- Create a new collection or database to store the text chunks.\n",
    "- Repeat over the list of text chunks and insert each chunk into ChromaDB.\n",
    "- Use appropriate methods provided by the ChromaDB library to insert the chunks efficiently.\n",
    "- Consider adding metadata or tags to each chunk if needed for better organization and retrieval.\n",
    "- Verify that the chunks are successfully stored in ChromaDB by querying the database.\n",
    "\n",
    "\n",
    "LangChain provides several [document loaders](https://python.langchain.com/v0.2/docs/integrations/document_loaders/) that can help you load data from various sources, such as URLs, files, and databases. You can use these loaders to extract text from different types of documents and prepare them for storage in ChromaDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Import PyPDFLoader from langchain_community.document_loaders to load and process PDF documents\n",
    "# Documentation: https://python.langchain.com/v0.2/docs/how_to/document_loader_pdf/#loading-pdf-with-pypdf2\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Import YoutubeLoader from langchain_community.document_loaders.youtube to load and process YouTube transcripts\n",
    "# Documentation: https://python.langchain.com/v0.2/docs/integrations/document_loaders/youtube_transcript/\n",
    "from langchain_community.document_loaders.youtube import YoutubeLoader\n",
    "\n",
    "# Initialize an empty list to store all documents\n",
    "all_documents = []\n",
    "\n",
    "# Function to download a PDF document from a given URL and save it with a specified filename\n",
    "def download_pdf(url, filename):\n",
    "    # Check if the file already exists to avoid re-downloading\n",
    "    if not os.path.exists(filename):\n",
    "        # Make a GET request to the URL to fetch the PDF content\n",
    "        r = requests.get(url)\n",
    "        # Open the file in write-binary mode and save the content\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "\n",
    "# Download the PDF document from the specified URL and save it to the 'data' directory\n",
    "download_pdf('https://ufrn.br/resources/documentos/regulamentos/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf', 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf')\n",
    "\n",
    "# Initialize the PyPDFLoader with the path to the downloaded PDF document\n",
    "pdf_loader = PyPDFLoader('data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf')\n",
    "\n",
    "# Load and split the PDF document into individual pages\n",
    "pages = pdf_loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='MINISTÉRIO DA EDUCAÇÃO  \n",
      "UNIVERSIDADE FEDERAL DO RIO GRANDE DO NORTE  \n",
      "                  \n",
      "       \n",
      " \n",
      "  \n",
      "RESOLUÇÃO Nº 016/2023 -CONSEPE, de 04 de julho de 2023.  \n",
      " \n",
      " \n",
      "Atualiza o Regulamento dos Cursos de Graduação da \n",
      "Universidade Federal do Rio Grande do Norte - UFRN.  \n",
      " \n",
      " \n",
      "O VICE -REITOR DA UNIVERSIDADE FEDERAL DO RIO GRANDE DO NORTE faz saber que o \n",
      "Conselho de Ensino, Pesquisa e Extensão, no uso das atribuições que lhe confere o art. 17, Inciso III, do \n",
      "Estatuto da UFRN,   \n",
      " \n",
      "CONSIDERANDO o art. 207 da Constituição Federal ao d eterminar que as universidades gozam \n",
      "de autonomia didático -científica, administrativa e de gestão financeira e patrimonial, e obedecerão ao \n",
      "princípio de indissociabilidade entre ensino, pesquisa e extensão;  \n",
      " \n",
      "CONSIDERANDO a Lei nº 9.394/1996, que estabelec e as diretrizes e bases da educação \n",
      "nacional;  \n",
      " \n",
      "CONSIDERANDO a necessidade de atualizar as normas relativas ao ensino de graduação, \n",
      "conforme determina o art. 359 da Resolução no 171/2013 - CONSEPE, de 5 de novembro de 2013, que \n",
      "aprovou o Regulamento dos Cur sos Regulares de Graduação; e  \n",
      " \n",
      "CONSIDERANDO o que consta no Processo nº 23077.066985/2023 -42, \n",
      " \n",
      " \n",
      "RESOLVE:  \n",
      " \n",
      "Art. 1º  Atualizar o Regulamento dos Cursos de Graduação da Universidade Federal do Rio \n",
      "Grande do Norte – UFRN.  \n",
      " \n",
      "TÍTULO I  \n",
      "DAS DISPOSIÇÕES PRELIMINARES  \n",
      " \n",
      "Art. 2º  Este Regulamento tem por finalidade normatizar o ensino de graduação da Universidade \n",
      "Federal do Rio Grande do Norte - UFRN.  \n",
      " \n",
      "Parágrafo único.   Os cursos que não possuem oferta regular serão regidos, conforme suas \n",
      "especificidades, por este Regulame nto e por legislação específica.  \n",
      " \n",
      "TÍTULO II  \n",
      "DA GESTÃO DAS ATIVIDADES ACADÊMICAS' metadata={'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "# Print the content of the first page of the PDF document\n",
    "# 'pages' is a list where each element represents a page of the PDF\n",
    "print(pages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents += pages\n",
    "pages = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Sumário\n",
      "TÍTULOI–DAINSTITUIÇÃO..............................................................5\n",
      "CAPÍTULOI–Danaturezajurídica..............................................5\n",
      "CAPÍTULOII–Dosprincípiosedosobjetivos...........................6\n",
      "SEÇÃOI–Dosprincípios.......................................................6\n",
      "SEÇÃOII–Dosobjetivos........................................................7\n",
      "CAPÍTULOIII–Daconstituiçãobásica.......................................9\n",
      "TÍTULOII–DAADMINISTRAÇÃOUNIVERSITÁRIA....................14\n",
      "CAPÍTULOI–DosConselhosSuperiores................................14\n",
      "SEÇÃOI–DoConselhoUniversitário–CONSUNI.........14\n",
      "SEÇÃOII–DaAssembleiaUniversitária...........................17\n",
      "SEÇÃOIII–DoConselhodeEnsino,Pesquisae\n",
      "Extensão–CONSEPE....................................18\n",
      "SEÇÃOIV–DoConselhodeAdministração–\n",
      "CONSAD..........................................................22\n",
      "SEÇÃOV–DoConselhodeCuradores–CONCURA......25\n",
      "CAPÍTULOII–DaReitoria..........................................................28\n",
      "CAPÍTULOIII–DaAdministraçãoAcadêmica.........................31\n",
      "SEÇÃOI–DosCentrosAcadêmicos.................................32\n",
      "SEÇÃOII–DosConselhosdeCentros\n",
      "AcadêmicosedeUnidadesAcadêmicas\n",
      "Especializadas..................................................32' metadata={'source': 'data/estatuto.pdf', 'page': 2}\n"
     ]
    }
   ],
   "source": [
    "# Download the second PDF document from the specified URL and save it to the 'data' directory\n",
    "download_pdf('https://sigrh.ufrn.br/sigrh/public/colegiados/anexos/estatuto.pdf', 'data/estatuto.pdf')\n",
    "\n",
    "# Initialize the PyPDFLoader with the path to the downloaded PDF document\n",
    "pdf_loader = PyPDFLoader('data/estatuto.pdf')\n",
    "\n",
    "# Load and split the PDF document into individual pages\n",
    "pages = pdf_loader.load_and_split()\n",
    "\n",
    "# Print the content of the second page of the PDF document\n",
    "# 'pages' is a list where each element represents a page of the PDF\n",
    "print(pages[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents += pages\n",
    "pages = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading HTML from URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jacob/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Import the UnstructuredURLLoader class from the langchain_community.document_loaders module\n",
    "# This class is used to load and process content from URLs\n",
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Define a list of URLs to be loaded\n",
    "urls = [\n",
    "    'https://portal.imd.ufrn.br/portal/noticias/7318/ufrn-associa-se-a-fiware-foundation-e-cria-ihub-em-cidades-inteligentes-no-imd',\n",
    "    'https://portal.imd.ufrn.br/portal/noticias/7338/equipes-ligadas-ao-imd-vencem-hackathon-inovar-2024',\n",
    "    'https://portal.imd.ufrn.br/portal/noticias/7319/projeto-do-imd-com-idosos-comemora-conclus%C3%A3o-da-primeira-turma',\n",
    "]\n",
    "\n",
    "# Initialize the UnstructuredURLLoader with the list of URLs\n",
    "# This loader will fetch and process the content from the provided URLs\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "\n",
    "# Load the content from the URLs\n",
    "# 'pages' will be a list where each element contains the content of one URL\n",
    "pages = loader.load()\n",
    "\n",
    "# Note: For pages where the content is created dynamically (e.g., using JavaScript), there are other loaders that can be used with Selenium and PlayWright.\n",
    "# You can learn more about them on the Document Loaders Page of Langchain Community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Mais notícias\n",
      "\n",
      "UFRN associa-se a FIWARE Foundation e cria iHUB em Cidades Inteligentes no IMD\n",
      "\n",
      "UFRN associa-se a FIWARE Foundation e cria iHUB em Cidades Inteligentes no IMD\n",
      "\n",
      "Iniciativa visa tornar cidades brasileiras mais inteligentes, sustentáveis e integradas\n",
      "\n",
      "27-06-2024 / ASCOM\n",
      "\n",
      "Cidades Inteligentes Smart Metropolis\n",
      "\n",
      "Após assinar um associação com a Fundação FIWARE, organização internacional que promove o desenvolvimento de soluções inteligentes em todo o mundo, a Universidade Federal do Rio Grande do Norte (UFRN) prevê a criação de um novo espaço (iHUB) para desenvolvimento de pesquisas, estudantes e iniciativas na área de Cidades Inteligentes.\n",
      "\n",
      "Durante o Summit Cidades, evento nacional que aconteceu em Florianópolis (SC) na última terça-feira, 25, o Instituto Metrópole Digital (IMD/UFRN), representado pelo professor Frederico Lopes, oficializou o acordo, que marcou o início da criação do iHUB e de uma série de ações possibilitam a disseminação de tecnologias open-source, responsáveis por tornar as cidades brasileiras mais inteligentes, sustentáveis e integradas.\n",
      "\n",
      "O novo espaço será sediado no próprio IMD, com apoio do seu Parque Tecnológico Metrópole Digital (Metrópole Parque), e estará atrelado ao Smart Metrópolis – laboratório do IMD especializado em Cidades Inteligentes – o qual também dá nome ao espaço: Smart Metrópolis iHUB FIWARE.\n",
      "\n",
      "1ª do Brasil\n",
      "\n",
      "O acordo, assinado pelo reitor da UFRN, professor Daniel Diniz Melo, classifica a Universidade como a primeira do Brasil a contar com um iHUB Fiware. Essa iniciativa existe em diferentes países ao redor do mundo, empenhados com o surgimento de soluções inteligentes para tornar cidades integradas e mais funcionais para seus moradores.\n",
      "\n",
      "Localizado na sala B424 do IMD, o novo iHUB ofertará uma série de serviços, como treinamentos para prefeituras e empresas na área de Cidades Inteligentes, além de análise de dados e auxílio em tomadas de decisões no campo das políticas públicas.\n",
      "\n",
      "Também nesse ambiente, com articulação de professores e alunos de graduação e pós-graduação, serão conduzidas turmas de nível superior sobre Cidades Inteligentes e uso da tecnologia FIWARE.\n",
      "\n",
      "“Nossa proposta é contemplar projetos de pesquisa, desenvolvimento e inovação com a plataforma FIWARE, envolvendo tecnologias como Internet das Coisas, Inteligência Artificial, blockchain, computação em nuvem, dados abertos, engenharia de software, entre outras áreas”, comenta Frederico Lopes.\n",
      "\n",
      "Outras Notícias\n",
      "\n",
      "IMD abre seleção para bolsistas com remuneração de R$ 3 mil\n",
      "\n",
      "Oportunidades são para área de Computação e afins. Inscrições vão até o dia 16 de setembro\n",
      "\n",
      "Metrópole Parque confirma presença e realizará palestras no GO!RN\n",
      "\n",
      "Encontro é o maior do ramo do empreendedorismo inovador do Rio Grande do Norte' metadata={'source': 'https://portal.imd.ufrn.br/portal/noticias/7318/ufrn-associa-se-a-fiware-foundation-e-cria-ihub-em-cidades-inteligentes-no-imd'}\n"
     ]
    }
   ],
   "source": [
    "print(pages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents += pages\n",
    "pages = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Youtube Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you have installed the necessary packages:\n",
    "# pip install youtube-transcript-api pytube\n",
    "\n",
    "# Import the YoutubeLoader class from the langchain_community.document_loaders module\n",
    "# This class is used to load and process transcripts from YouTube videos\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "# Initialize the YoutubeLoader with the URL of the YouTube video\n",
    "\n",
    "\n",
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    \"https://youtu.be/OHv-nx4ukZU?si=-uo5kd8OK_Zg7T9s\", # 'from_youtube_url' is a class method that creates an instance of YoutubeLoader\n",
    "    add_video_info=True, # 'add_video_info=True' indicates that additional video information (like title and description) should be included\n",
    "    language=['pt'] # 'language=['pt']' specifies the language of the transcript to be loaded (Portuguese in this case)\n",
    ")\n",
    "\n",
    "# Load the transcript and additional video information\n",
    "# 'pages' will be a list where each element contains a part of the transcript and video information\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='[Música] o restaurante universitário tem uma longa história no campus central werre ou foi construído no ano de 1973 e até hoje é um dos estados mais movimentados do campo podem usar o restaurante todos os alunos matriculados técnicos e professores em atividade na ufsm diariamente uma rio oferece opções de pratos à base de proteínas tratos vegetarianos acompanhamentos socos e sócia beijo [Música] até pessoas do rio são preparados com valorização de nutricionistas com medo pesquisas a equipe com esses traços que mais agradam os usuários também podem opinar sobre a comida lá mesmo no local e fará sua mãe que anda conectada o cardápio está disponível diariamente pelo aplicativo do é rio para ter acesso ao restaurante é preciso ter vocação para fazer o seu barco que elegerá o feito de atendimento à docência não sei se o relógio do sol a documentação exigida para alunos é um atestado de matrícula em documento com foto recarregar o cartão fácil se existem dois caminhos pelo cigás rolar mesmo no caso de a mas vale lembrar não esqueceu o cartão porque ele é de uso pessoal exclusivo esteja sempre com ele em mãos civis que a vontade [Música] [Música] e se você gostou os alvinegros se inscreva se em nosso canal' metadata={'source': 'OHv-nx4ukZU', 'title': 'Tô no Campus - Restaurante Universitário (RU)', 'description': 'Unknown', 'view_count': 6798, 'thumbnail_url': 'https://i.ytimg.com/vi/OHv-nx4ukZU/hq720.jpg', 'publish_date': '2017-06-20 00:00:00', 'length': 143, 'author': 'Canal UFRN'}\n"
     ]
    }
   ],
   "source": [
    "print(pages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents += pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Arbitrary Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbitrary_text = \"\"\"\n",
    "Fortalecer a atuação do Poder Judiciário na proteção do meio ambiente com uso de Inteligência Artificial (IA): esse é um dos objetivos de projeto realizado pelo Programa das Nações Unidas para o Desenvolvimento (Pnud), o Conselho Nacional de Justiça (CNJ) e a Universidade Federal do Rio Grande do Norte (UFRN). A iniciativa utilizará IA e técnicas da ciência de dados para extrair informações úteis dos textos processuais, a fim de realizar análises e previsões em ações judiciais do assunto Direito Ambiental.  \n",
    "\n",
    "Segundo explica Rafael Leite, juiz auxiliar da Presidência do CNJ, o projeto visa usar IA, técnicas de processamento de linguagem natural e análise dos dados do processo e do conteúdo textual de suas peças para obter informações sobre a atuação do Judiciário na área do meio ambiente. “A IA é importante ferramenta para dar suporte à atuação dos magistrados e aumentar a efetividade da jurisdição – por exemplo, identificando padrões de conduta, impacto em biomas específicos e efeitos cumulativos de determinadas atividades –, além de melhor orientar ações de fiscalização de combate ao desmatamento ilegal e outros crimes ambientais”, afirma o magistrado.  \n",
    "\n",
    "O CNJ já realiza acompanhamento de ações judiciais nos assuntos de Direito Ambiental por meio do Painel Interativo SireneJud, que reúne informações, por exemplo, sobre Terras Indígenas e áreas de desmatamento. O painel consome dados de diferentes fontes, como o DataJud – Base Nacional de Dados do Poder Judiciário, o Instituto Nacional de Pesquisas Espaciais (Inpe) e o Instituto Brasileiro de Geografia e Estatística (IBGE). \n",
    "\n",
    "A UFRN irá colocar à disposição do SireneJud as APIs (Application Programming Interfaces) desenvolvidas de modo a agregar novas informações ao painel interativo. As APIs permitem que os sistemas se comuniquem e os dados sejam integrados. \n",
    "\n",
    "Arquitetura\n",
    "No projeto, a arquitetura definida para desenvolver as soluções insere-se na linguística computacional, que usa redes neurais e outros métodos para “extrair sentido de texto”, explica Elias Jacob, professor da UFRN. “A IA nada mais é do que uma representação do mundo a partir dos dados que foram passados para ela. O que ela faz? Detecta padrões”, descreve Jacob. \n",
    "\n",
    "A Plataforma Codex proverá o conjunto de dados que serão utilizados pelos analistas e desenvolvedores na construção dos modelos de IA e demais soluções. “O Codex importa as informações dos diversos sistemas processuais eletrônicos utilizados pelos tribunais. Ele extrai tanto os metadados do processo, como número e nome das partes, quanto o teor dos textos que estão lá”, explica o professor. \n",
    "\n",
    "De acordo com o Painel de Monitoramento de Implantação do Codex, o sistema tem extraído informações de 141 fontes de dados vinculadas a sistemas processuais dos tribunais brasileiros. “Todo o projeto tem a função de detectar padrões para extrair informação – que antes era inacessível – para que o humano possa tomar as decisões necessárias”, diz Jacob.  \n",
    "\n",
    "Uso de IA no Poder Judiciário\n",
    "Elias Jacob também propõe desmistificar a ideia de que modelos de IA promoveriam uma espécie de robotização do trabalho de juízes e juízas. “O que precisa ficar claro é que são ferramentas que nos ajudam a fazer algo, e não que vieram substituir o trabalho humano”, diz. \n",
    "\n",
    "Ele ressalta que a demanda social pelo serviço prestado pela jurisdição é elevada e, mesmo com a digitalização do processo judicial e a alta produtividade de magistrados e servidores, o Poder Judiciário enfrenta problemas de congestionamento processual. Nesse sentido, a IA é um caminho: “no Brasil, um juiz julga mais de 9 mil processos por ano. Existem várias formas de melhorar o atendimento dessa demanda. Uma delas é o desenvolvimento de ferramentas de IA”. \n",
    "\n",
    "O projeto com a UFRN é realizado no âmbito do Programa Justiça 4.0. A iniciativa busca fortalecer a atuação do Judiciário na tutela do meio ambiente, considerando que a Justiça brasileira dispõe de um conjunto de informações e dados relevantes sobre conflitos e crimes ambientais, explica Jacob. “Os problemas da sociedade recaem no Judiciário, que, em tese, é a melhor fonte de conhecimento sobre os problemas que assolam o país; na questão ambiental, não seria diferente”, argumenta o professor. \n",
    "\n",
    "Conheça os produtos previstos na parceria entre CNJ, PNUD e UFRN:\n",
    "Solução de IA capaz de recomendar aos magistrados precedentes na área ambiental, buscando situações similares e permitindo maior uniformização dos julgamentos; \n",
    "Dados tratados contendo o recorte de causas ambientais que já tramitaram no Brasil;  \n",
    "Ferramenta para identificar os maiores réus em causas ambientais e poluidores em geral a partir de dados retirados da Base Nacional de Dados do Poder Judiciário (DataJud);   \n",
    "Solução de IA capaz de ler textos jurídicos e identificar elementos importantes, como o tipo de crime cometido, o dano causado, o bioma envolvido, o valor da condenação e o uso da legislação nacional e internacional; e\n",
    "Solução de IA para prever os resultados de processos judiciais na área ambiental. \n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'title': 'IA e ciência de dados vão auxiliar o Judiciário na proteção do meio ambiente', 'author': 'Conselho Nacional de Justiça', 'source': 'https://www.cnj.jus.br/ia-e-ciencia-de-dados-vao-auxiliar-o-judiciario-na-protecao-do-meio-ambiente/'}, page_content='\\nFortalecer a atuação do Poder Judiciário na proteção do meio ambiente com uso de Inteligência Artificial (IA): esse é um dos objetivos de projeto realizado pelo Programa das Nações Unidas para o Desenvolvimento (Pnud), o Conselho Nacional de Justiça (CNJ) e a Universidade Federal do Rio Grande do Norte (UFRN). A iniciativa utilizará IA e técnicas da ciência de dados para extrair informações úteis dos textos processuais, a fim de realizar análises e previsões em ações judiciais do assunto Direito Ambiental.  \\n\\nSegundo explica Rafael Leite, juiz auxiliar da Presidência do CNJ, o projeto visa usar IA, técnicas de processamento de linguagem natural e análise dos dados do processo e do conteúdo textual de suas peças para obter informações sobre a atuação do Judiciário na área do meio ambiente. “A IA é importante ferramenta para dar suporte à atuação dos magistrados e aumentar a efetividade da jurisdição – por exemplo, identificando padrões de conduta, impacto em biomas específicos e efeitos cumulativos de determinadas atividades –, além de melhor orientar ações de fiscalização de combate ao desmatamento ilegal e outros crimes ambientais”, afirma o magistrado.  \\n\\nO CNJ já realiza acompanhamento de ações judiciais nos assuntos de Direito Ambiental por meio do Painel Interativo SireneJud, que reúne informações, por exemplo, sobre Terras Indígenas e áreas de desmatamento. O painel consome dados de diferentes fontes, como o DataJud – Base Nacional de Dados do Poder Judiciário, o Instituto Nacional de Pesquisas Espaciais (Inpe) e o Instituto Brasileiro de Geografia e Estatística (IBGE). \\n\\nA UFRN irá colocar à disposição do SireneJud as APIs (Application Programming Interfaces) desenvolvidas de modo a agregar novas informações ao painel interativo. As APIs permitem que os sistemas se comuniquem e os dados sejam integrados. \\n\\nArquitetura\\nNo projeto, a arquitetura definida para desenvolver as soluções insere-se na linguística computacional, que usa redes neurais e outros métodos para “extrair sentido de texto”, explica Elias Jacob, professor da UFRN. “A IA nada mais é do que uma representação do mundo a partir dos dados que foram passados para ela. O que ela faz? Detecta padrões”, descreve Jacob. \\n\\nA Plataforma Codex proverá o conjunto de dados que serão utilizados pelos analistas e desenvolvedores na construção dos modelos de IA e demais soluções. “O Codex importa as informações dos diversos sistemas processuais eletrônicos utilizados pelos tribunais. Ele extrai tanto os metadados do processo, como número e nome das partes, quanto o teor dos textos que estão lá”, explica o professor. \\n\\nDe acordo com o Painel de Monitoramento de Implantação do Codex, o sistema tem extraído informações de 141 fontes de dados vinculadas a sistemas processuais dos tribunais brasileiros. “Todo o projeto tem a função de detectar padrões para extrair informação – que antes era inacessível – para que o humano possa tomar as decisões necessárias”, diz Jacob.  \\n\\nUso de IA no Poder Judiciário\\nElias Jacob também propõe desmistificar a ideia de que modelos de IA promoveriam uma espécie de robotização do trabalho de juízes e juízas. “O que precisa ficar claro é que são ferramentas que nos ajudam a fazer algo, e não que vieram substituir o trabalho humano”, diz. \\n\\nEle ressalta que a demanda social pelo serviço prestado pela jurisdição é elevada e, mesmo com a digitalização do processo judicial e a alta produtividade de magistrados e servidores, o Poder Judiciário enfrenta problemas de congestionamento processual. Nesse sentido, a IA é um caminho: “no Brasil, um juiz julga mais de 9 mil processos por ano. Existem várias formas de melhorar o atendimento dessa demanda. Uma delas é o desenvolvimento de ferramentas de IA”. \\n\\nO projeto com a UFRN é realizado no âmbito do Programa Justiça 4.0. A iniciativa busca fortalecer a atuação do Judiciário na tutela do meio ambiente, considerando que a Justiça brasileira dispõe de um conjunto de informações e dados relevantes sobre conflitos e crimes ambientais, explica Jacob. “Os problemas da sociedade recaem no Judiciário, que, em tese, é a melhor fonte de conhecimento sobre os problemas que assolam o país; na questão ambiental, não seria diferente”, argumenta o professor. \\n\\nConheça os produtos previstos na parceria entre CNJ, PNUD e UFRN:\\nSolução de IA capaz de recomendar aos magistrados precedentes na área ambiental, buscando situações similares e permitindo maior uniformização dos julgamentos; \\nDados tratados contendo o recorte de causas ambientais que já tramitaram no Brasil;  \\nFerramenta para identificar os maiores réus em causas ambientais e poluidores em geral a partir de dados retirados da Base Nacional de Dados do Poder Judiciário (DataJud);   \\nSolução de IA capaz de ler textos jurídicos e identificar elementos importantes, como o tipo de crime cometido, o dano causado, o bioma envolvido, o valor da condenação e o uso da legislação nacional e internacional; e\\nSolução de IA para prever os resultados de processos judiciais na área ambiental. \\n')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Document class from the langchain_core.documents module\n",
    "# This class is used to create and manage document objects\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Create a Document object with specified content and metadata\n",
    "# 'page_content' is the main content of the document, which is stored in the variable 'arbitrary_text'\n",
    "# 'metadata' is a dictionary containing additional information about the document\n",
    "# 'title' specifies the title of the document\n",
    "# 'author' specifies the author of the document\n",
    "# 'source' specifies the source URL of the document\n",
    "doc = Document(\n",
    "    page_content=arbitrary_text,\n",
    "    metadata={\n",
    "        'title': 'IA e ciência de dados vão auxiliar o Judiciário na proteção do meio ambiente',\n",
    "        'author': 'Conselho Nacional de Justiça',\n",
    "        'source': 'https://www.cnj.jus.br/ia-e-ciencia-de-dados-vao-auxiliar-o-judiciario-na-protecao-do-meio-ambiente/'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Display the Document object\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Breaking Down the Text into Manageable Segments\n",
    "\n",
    "When working with dense, information-rich texts, it's crucial to divide them into smaller, more manageable segments for efficient storage and retrieval. This process, known as **chunking**, breaks the information into smaller pieces, making it easier to store and more meaningful. Chunking enables more relevant information retrieval in response to specific queries and reduces costs by including only a portion of a document in the LLM prompt instead of the entire document.\n",
    "\n",
    "### Chunking Strategies\n",
    "\n",
    "The following chunking techniques typically use two main parameters:\n",
    "\n",
    "- **chunk_size**: Determines the size of each text segment.\n",
    "- **chunk_overlap**: Controls how much text overlaps between one segment and the next.\n",
    "\n",
    "#### Character Chunking\n",
    "\n",
    "Character Chunking is the simplest strategy, dividing the text into segments based on a fixed number of characters. While straightforward, this method can sometimes disrupt the flow of text by breaking sentences or words unexpectedly. Despite its limitations, it serves as a good starting point for more advanced methods.\n",
    "\n",
    "#### Recursive Character Chunking\n",
    "\n",
    "Recursive Character Chunking builds on the basic concept of Character Chunking by dividing the text into segments until a specific condition, such as a minimum chunk size, is met. This method ensures that the chunking process aligns with the text's structure, preserving more meaning. Its adaptability makes it suitable for texts with varied structures.\n",
    "\n",
    "#### Document Specific Chunking\n",
    "\n",
    "Document Specific Chunking respects the document's innate structure by creating segments that align with the logical sections of the document, such as paragraphs or subsections, instead of using a fixed number of characters or a recursive process. This approach maintains the original organization of the content, making the retrieved information more relevant and useful, especially for structured documents with clearly defined sections.\n",
    "\n",
    "#### Token-based Chunking\n",
    "\n",
    "When dividing your text into segments, it's advisable to count the number of tokens to ensure compliance with the token limit of the language model being used. To ensure accuracy, use the same tokenizer for counting tokens as the one used in the language model.\n",
    "\n",
    "#### Semantic Chunking\n",
    "\n",
    "Semantic Chunking considers the relationships within the text, dividing it into meaningful, semantically complete segments. This approach ensures the integrity of the information during retrieval, leading to more accurate and contextually appropriate outcomes. The process involves:\n",
    "\n",
    "1. Taking the embeddings of every sentence in the document.\n",
    "2. Comparing the similarity of all sentences with each other.\n",
    "3. Grouping sentences with the most similar embeddings together.\n",
    "\n",
    "By focusing on the text's meaning and context, Semantic Chunking significantly enhances the quality of retrieval. It's an excellent choice when maintaining the semantic integrity of the text is crucial. However, this method requires more effort and is slower than the previous ones.\n",
    "\n",
    "#### Agent Chunking\n",
    "\n",
    "Agent Chunking mimics how humans might process a new document:\n",
    "\n",
    "1. Start at the top of the document, treating the first part as a segment.\n",
    "2. Continue down the document, deciding if a new sentence or piece of information belongs with the first segment or should start a new one.\n",
    "3. Repeat this process until reaching the end of the document.\n",
    "\n",
    "### Choosing the Right Chunking Strategy\n",
    "\n",
    "Each chunking strategy has its strengths and weaknesses, and the choice of method depends on the specific requirements of the text and the intended use. Consider the following factors when selecting a chunking strategy:\n",
    "\n",
    "- **Text structure**: For well-structured documents with clearly defined sections, Document Specific Chunking may be the most appropriate choice.\n",
    "- **Semantic integrity**: If maintaining the semantic integrity of the text is crucial, Semantic Chunking is the best option, despite being more time-consuming and effort-intensive.\n",
    "- **Simplicity**: Character Chunking and Recursive Character Chunking are straightforward and easy to implement, making them suitable for quick experimentation or when the text structure is less important.\n",
    "- **Language model compatibility**: Token-based Chunking ensures compliance with the token limit of the language model being used, making it a reliable choice when working with LLMs.\n",
    "\n",
    "\n",
    "### Implementing Token-based Chunking for Our Class\n",
    "\n",
    "For our class, we'll use a simple, token-based chunking strategy to divide the text into manageable segments. This approach ensures that the generated responses are concise and aligned with the token limits of the language model. Because different language models have varying token limits and tokenization methods, it's essential to consider these factors when designing your chunking strategy.\n",
    "\n",
    "### Comparing Embedding Models and Adjusting Chunk Size\n",
    "\n",
    "Later, we'll purposely use two different strategies to generate the embeddings for the documents:\n",
    "\n",
    "1. Using a Sentence Transformer to generate the embeddings.\n",
    "2. Using OpenAI embedding models.\n",
    "\n",
    "This will allow us to compare the results and see how different embedding models can impact the performance of the RAG system. However, there's a difference between the two strategies that we'll need to address:\n",
    "\n",
    "> Our Sentence-Transformer has a 512 token limit, while OpenAI's model has an 8192 token limit.\n",
    "\n",
    "This means that we'll need to adjust the chunk size for the OpenAI embeddings to make sure they fit within the token limit. This is a common challenge when working with different embedding models and language models, and it's essential to consider these limitations during the design of your RAG system. Note that, because they are two different models, the tokens generated by each model may not be directly comparable.\n",
    "\n",
    "Let's dive into [LangChain Text Splitters](https://python.langchain.com/v0.2/docs/concepts/#text-splitters) to see how we can implement token-based chunking for our class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the necessary packages are installed and up-to-date\n",
    "# !pip install --upgrade --quiet langchain-text-splitters tiktoken\n",
    "\n",
    "# Import the RecursiveCharacterTextSplitter class from langchain_text_splitters\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# Import the AutoTokenizer class from transformers\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load a pre-trained Hugging Face tokenizer from the specified path\n",
    "hf_tokenizer = AutoTokenizer.from_pretrained('outputs/sentence_transformers/sentence-transformer')\n",
    "\n",
    "# Create a RecursiveCharacterTextSplitter instance using OpenAI's tiktoken encoder\n",
    "splitter_openai = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",  # Specify the encoding name\n",
    "    chunk_size=8191,              # Define the maximum size of each chunk\n",
    "    chunk_overlap=0,              # Define the overlap between chunks\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \",\", \" \", \"\"]  # Define the separators to use for splitting\n",
    ")\n",
    "\n",
    "# Create a RecursiveCharacterTextSplitter instance using the Hugging Face tokenizer\n",
    "splitter_sentence_transformers = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=hf_tokenizer,       # Pass the loaded Hugging Face tokenizer\n",
    "    chunk_size=512,               # Define the maximum size of each chunk\n",
    "    chunk_overlap=0,              # Define the overlap between chunks\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \",\", \" \", \"\"]  # Define the separators to use for splitting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splitter_sentence_transformers.split_text(arbitrary_text)), len(splitter_openai.split_text(arbitrary_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "chunked_documents_openai = splitter_openai.split_documents(all_documents)\n",
    "chunked_documents_sentence_transformers = splitter_sentence_transformers.split_documents(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 222)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunked_documents_openai), len(chunked_documents_sentence_transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Storing Chunks in ChromaDB\n",
    "\n",
    "After splitting the text into manageable segments, the next step is to store these chunks in ChromaDB for efficient retrieval during the RAG (Retrieval-Augmented Generation) process. ChromaDB is a powerful database designed for storing and querying vector embeddings, making it an ideal choice for this task. Let's dive into the details of storing chunks in ChromaDB.\n",
    "\n",
    "### Establishing a Connection\n",
    "\n",
    "To interact with ChromaDB, you first need to establish a connection to your ChromaDB instance. This is typically done using the provided API or client library specific to your programming language. It's essential to ensure that you have the necessary credentials and permissions to access the database securely. Proper authentication and authorization mechanisms should be in place to protect your data and maintain the integrity of your ChromaDB instance.\n",
    "\n",
    "### Creating a Collection\n",
    "\n",
    "Once you have successfully connected to ChromaDB, the next step is to create a collection or database to store your text chunks. Collections serve as logical containers for organizing and grouping related data. By creating a dedicated collection for your text chunks, you can easily manage and query them later. When naming your collection, choose a meaningful and descriptive name that reflects the nature of the data it holds. This will make it easier to identify and work with the collection throughout your RAG process.\n",
    "\n",
    "### Inserting Chunks into ChromaDB\n",
    "\n",
    "With the collection created, you can now proceed to insert the text chunks into ChromaDB. This involves iterating over the list of chunks and using the appropriate methods provided by the ChromaDB library to store each chunk efficiently. During the insertion process, consider adding metadata or tags to each chunk. Metadata can include relevant information such as the source of the text, the date of creation, or specific keywords associated with the chunk. By attaching metadata, you enhance the organizational structure and enable more targeted queries and analysis later on.\n",
    "\n",
    "### Verifying Data Insertion\n",
    "\n",
    "After inserting the chunks into ChromaDB, it's crucial to verify that the data has been successfully stored. You can accomplish this by running test queries against the database and examining the results. Perform queries that retrieve specific chunks based on their content or metadata to ensure that the data is accessible and matches your expectations. This verification step helps confirm the integrity and reliability of your stored data, giving you confidence in the subsequent stages of your RAG process.\n",
    "\n",
    "> **Important Note:**\n",
    "> When working with embeddings, it's vital to [remember this](https://www.youtube.com/watch?v=ulD7IsecPbU). So, keep in mind that embeddings are only comparable within the same model. If you use different models to generate embeddings for your text chunks and queries, the embeddings will not be directly comparable. To ensure compatibility and accurate retrieval, make sure to use the same embedding model consistently throughout your RAG system. This includes embedding the user queries using the same model that was used to embed the documents stored in ChromaDB.\n",
    "\n",
    "\n",
    "> We will save local files with ChromaDb, but you can also use the Chroma in [Client/Server Mode](https://docs.trychroma.com/guides#running-chroma-in-client/server-mode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you have installed the necessary packages:\n",
    "# pip install langchain_chroma chromadb langchain-huggingface\n",
    "\n",
    "# Import the Chroma class from the langchain_chroma module\n",
    "# This class is used for managing and querying embeddings with Chroma\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Import the HuggingFaceEmbeddings class from the langchain_huggingface module\n",
    "# This class is used to generate embeddings using Hugging Face models\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Import the OpenAIEmbeddings class from the langchain_openai module\n",
    "# This class is used to generate embeddings using OpenAI models\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Initialize the HuggingFaceEmbeddings with a specified model\n",
    "# 'model_name' specifies the path to the pre-trained Sentence Transformers model\n",
    "# 'show_progress=True' enables the display of progress during embedding generation\n",
    "# 'model_kwargs' is a dictionary of additional arguments for the model, here specifying to use the CPU\n",
    "embedding_function_sentence_transformers = HuggingFaceEmbeddings(\n",
    "    model_name='outputs/sentence_transformers/sentence-transformer',\n",
    "    show_progress=True,\n",
    "    model_kwargs={'device': 'cpu'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e19790a9b1e4b3eb66eecdfacb8f14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a ChromaDB instance and save it to a specified directory\n",
    "# 'db_sentence_transformers' will store the ChromaDB instance created from the documents and embeddings\n",
    "\n",
    "# Initialize the ChromaDB instance using the 'from_documents' method\n",
    "# 'documents' is a list of chunked documents that will be stored in the database\n",
    "# 'embedding' is the embedding function used to generate embeddings for the documents\n",
    "# 'persist_directory' specifies the directory where the ChromaDB instance will be saved\n",
    "db_sentence_transformers = Chroma.from_documents(\n",
    "    documents=chunked_documents_sentence_transformers,\n",
    "    embedding=embedding_function_sentence_transformers,\n",
    "    persist_directory='/tmp/chroma_db_sentence_transformer'\n",
    ")\n",
    "\n",
    "# The ChromaDB instance 'db_sentence_transformers' is now created and saved to '/tmp/chroma_db_sentence_transformer'\n",
    "# This instance can be used for querying and managing document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAIEmbeddings with a specified model\n",
    "# 'model' specifies the OpenAI model to be used for generating embeddings\n",
    "embedding_function_openai = OpenAIEmbeddings(\n",
    "    model='text-embedding-3-small'\n",
    ")\n",
    "\n",
    "# Create a ChromaDB instance using the OpenAI embeddings and save it to a specified directory\n",
    "# 'db_openai' will store the ChromaDB instance created from the documents and embeddings\n",
    "\n",
    "# Initialize the ChromaDB instance using the 'from_documents' method\n",
    "# 'documents' is a list of chunked documents that will be stored in the database\n",
    "# 'embedding' is the embedding function used to generate embeddings for the documents\n",
    "# 'persist_directory' specifies the directory where the ChromaDB instance will be saved\n",
    "db_openai = Chroma.from_documents(\n",
    "    documents=chunked_documents_openai,\n",
    "    embedding=embedding_function_openai,\n",
    "    persist_directory='/tmp/chroma_db_openai'\n",
    ")\n",
    "\n",
    "# The ChromaDB instance 'db_openai' is now created and saved to '/tmp/chroma_db_openai'\n",
    "# This instance can be used for querying and managing document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can reload the ChromaDB instances from the saved files at any time by specifying the persist_directory\n",
    "\n",
    "# Reload the ChromaDB instance for Sentence Transformers embeddings\n",
    "# 'persist_directory' specifies the directory where the ChromaDB instance was previously saved\n",
    "# 'embedding_function' specifies the embedding function used to generate embeddings for the documents\n",
    "db_sentence_transformers = Chroma(\n",
    "    persist_directory='/tmp/chroma_db_sentence_transformer',\n",
    "    embedding_function=embedding_function_sentence_transformers\n",
    ")\n",
    "\n",
    "# Reload the ChromaDB instance for OpenAI embeddings\n",
    "# 'persist_directory' specifies the directory where the ChromaDB instance was previously saved\n",
    "# 'embedding_function' specifies the embedding function used to generate embeddings for the documents\n",
    "db_openai = Chroma(\n",
    "    persist_directory='/tmp/chroma_db_openai',\n",
    "    embedding_function=embedding_function_openai\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e25f09231ac4746a330e3656202eb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the query string to search for relevant documents\n",
    "query = 'O processo avaliativo na UFRN pode ser organizado em até quantas avaliações?'\n",
    "\n",
    "# Perform a similarity search using the ChromaDB instance with Sentence Transformers embeddings\n",
    "# 'docs1' will store the documents that are most similar to the query based on Sentence Transformers embeddings\n",
    "docs1 = db_sentence_transformers.similarity_search(query)\n",
    "\n",
    "# Perform a similarity search using the ChromaDB instance with OpenAI embeddings\n",
    "# 'docs2' will store the documents that are most similar to the query based on OpenAI embeddings\n",
    "docs2 = db_openai.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'page': 24, 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf'}, page_content='das unidades, é obrigatória a realização de uma avaliação escrita, individual e presencial.  \\n \\n§4º  A unidade de vinculação do componen te curricular poderá, excepcionalmente, dispensar a \\nobrigatoriedade estabelecida no §3º  deste artigo.  \\n \\nArt. 101.  O rendimento acadêmico de cada unidade avaliativa é calculado a partir dos \\nresultados obtidos nos instrumentos avaliativos utilizados na unid ade.  \\n \\nParágrafo único.  A quantidade de instrumentos avaliativos por unidade é definida previamente \\npelo docente e divulgada no plano de ensino da turma.  \\n \\nArt. 102.   O rendimento acadêmico parcial (média parcial) é calculado pela média aritmética \\ndos rendi mentos acadêmicos obtidos em cada unidade avaliativa.  \\n \\nParágrafo único.  Em cada unidade avaliativa, o estudante deve atender o critério de'), Document(metadata={'page': 11, 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf'}, page_content='momentos presenciais destinados a avaliações da aprendizagem e atividades práticas de ensino , que \\ndevem ser realizadas no polo de apoio presencial ou no campus de funcionamento do curso.  \\n \\nArt. 44.  Ementa é a descrição sumária do conteúdo a ser desenvolvido no componente \\ncurricular, podendo ser alterada, desde que aprovada em órgão colegiado da unidade acadêmica ao \\nqual o componente curricular está vinculado.  \\n \\nParágrafo único.  As alterações nas ementas são registradas, no sistema de gestão acadêmica, \\npela PROGRAD e apensadas ao Projeto Pedagógico de Curso.  \\n \\nArt. 45.   Os componentes curriculares podem ser do tipo:  \\n \\nI - disciplina;  \\n \\nII - bloco; ou'), Document(metadata={'page': 43, 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf'}, page_content='e o valor acrescentado ao perfil inicial é descontado do prazo máximo para conclusão do curso.  \\n \\nCAPÍTULO III  \\nDA CRIAÇÃO DE T URMAS  \\n \\nArt. 195.   No prazo estabelecido no Calendário Universitário, as coordenações de curso devem \\nsolicitar às unidades acadêmicas de vinculação dos componentes curriculares a criação das turmas para \\no período letivo regular subsequente, indicando a mo dalidade de oferta da turma, o horário pretendido \\ne o número de vagas desejado para cada turno e ênfase ou habilitação.  \\n \\n§1º  A solicitação de turmas ocorre por meio do sistema de gestão acadêmica.'), Document(metadata={'page': 23, 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf'}, page_content='estudante, bem como a análise dos registros produzidos ao longo do processo para fins de atribuição do \\nrendimento acadêmico.  \\n \\nParágrafo único.  De modo complementar, os resultados do processo de avaliação devem \\nsubsidiar a reflexão e , caso necessário, o redimensionamento da prática pedagógica docente.  \\n \\nArt. 97.   A avaliação da aprendizagem deve verificar a apropriação dos conhecimentos por \\nparte dos estudantes, considerando os objetivos, conteúdos propostos no programa do componente \\ncurricular e o perfil do egresso estabelecido pelas Diretrizes Curriculares Nacionais e Projeto Pedagógico \\nde Curso.')]\n"
     ]
    }
   ],
   "source": [
    "print(docs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'page': 23, 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf'}, page_content='datas relativas a procedimentos reg ulares previstos neste regulamento.  \\n \\nArt. 94.   Os cursos de graduação se desenvolvem anualmente em dois períodos letivos \\nregulares estabelecidos no Calendário Universitário.  \\n \\n§1º  Os períodos letivos regulares têm duração de, no mínimo, 18 (dezoito) semana s de aulas.  \\n \\n§2º  Adicionalmente, a critério da instituição, pode ser realizado período letivo especial de \\nférias.  \\n \\n§3º  O período letivo especial de férias deve ter duração mínima de 4 (quatro) semanas.  \\n \\nArt. 95.   As aulas presenciais semanais da UFRN são  ministradas:  \\n \\nI - de segunda -feira a sábado, conforme o Calendário Universitário;  \\n \\nII - em três turnos diários: matutino, vespertino e noturno;  \\n \\nIII -  com duração de 50 (cinquenta) minutos de atividades; e  \\n \\nIV - conforme distribuição semanal dos horários  de aulas apresentada no Anexo I deste \\nRegulamento.  \\n \\n§1º  Deve ser ministrada a quantidade de aulas necessária para o cumprimento total da carga \\nhorária dos componentes curriculares no período letivo.  \\n \\n§2º  Quando necessário o docente deverá ministrar aula  de reposição para cumprir o que \\nestabelece o §1º  deste artigo.  \\n \\n§3º  As unidades de ensino do interior do estado podem estabelecer horários noturnos \\ndistintos dos definidos no Anexo I deste Regulamento, sem prejuízo de atendimento aos incisos I, II e III  \\ndeste artigo, mediante aprovação da Câmara de Graduação.  \\n \\nTÍTULO VI  \\nDA AVALIAÇÃO DE APRENDIZAGEM  \\n \\nArt. 96.   A avaliação da aprendizagem, processo mediado pelo docente, compreende o \\ndiagnóstico e o acompanhamento do desenvolvimento de conhecimentos, habil idades e atitudes pelo \\nestudante, bem como a análise dos registros produzidos ao longo do processo para fins de atribuição do \\nrendimento acadêmico.  \\n \\nParágrafo único.  De modo complementar, os resultados do processo de avaliação devem \\nsubsidiar a reflexão e , caso necessário, o redimensionamento da prática pedagógica docente.  \\n \\nArt. 97.   A avaliação da aprendizagem deve verificar a apropriação dos conhecimentos por \\nparte dos estudantes, considerando os objetivos, conteúdos propostos no programa do componente \\ncurricular e o perfil do egresso estabelecido pelas Diretrizes Curriculares Nacionais e Projeto Pedagógico \\nde Curso.'), Document(metadata={'page': 24, 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf'}, page_content='Parágrafo único.   Os critérios utilizados na avaliação devem ser divulgados pelo docente e \\nconstar no plano de ensino, conforme art. 47 des te Regulamento.  \\n \\nArt. 98.   Os instrumentos para avaliação da aprendizagem devem considerar as concepções \\nformativas definidas no Projeto Pedagógico do Curso.  \\n \\nParágrafo único.  Os Estudantes com Necessidades Educacionais Específicas - NEE poderão ter \\nmecan ismos de avaliação diferenciados de acordo com as suas necessidades, mediante parecer da \\nSecretaria de Inclusão e Acessibilidade - SIA. \\n \\nArt. 99.   O rendimento acadêmico é o resultado obtido pelo estudante nos instrumentos \\navaliativos adotados em cada comp onente curricular.  \\n \\n§1º  O rendimento acadêmico dos estudantes matriculados na turma é divulgado por meio de \\nnota ou situação final de aprovação ou reprovação, conforme §2º, do art. 59.  \\n \\n§2º  Ao estudante que não participa de uma atividade avaliativa é atr ibuída a nota 0 (zero).  \\n \\n§3º É facultado aos departamentos ou unidades acadêmicas especializadas estabelecer a \\naferição do rendimento de componentes curriculares por meio da situação de aprovação e reprovação, \\ndevendo esta característica constar no Projeto  Pedagógico do Curso.  \\n \\n§4º  Na hipótese descrita no §3º deste artigo o rendimento não será contabilizado para o \\ncálculo dos índices acadêmicos dos estudantes, devendo ser atendidos os critérios de assiduidade.  \\n \\nArt. 100.   O processo avaliativo pode ser org anizado em até 3 (três) unidades avaliativas.  \\n \\n§1º  Cada unidade avaliativa pode ser composta por um ou mais instrumentos de avaliação.  \\n \\n§2º  O número de unidades avaliativas é definido pela unidade de vinculação do componente \\ncurricular no momento de cria ção do componente curricular.  \\n \\n§3º  Para os componentes curriculares com 3 (três) unidades avaliativas, em pelo menos uma \\ndas unidades, é obrigatória a realização de uma avaliação escrita, individual e presencial.  \\n \\n§4º  A unidade de vinculação do componen te curricular poderá, excepcionalmente, dispensar a \\nobrigatoriedade estabelecida no §3º  deste artigo.  \\n \\nArt. 101.  O rendimento acadêmico de cada unidade avaliativa é calculado a partir dos \\nresultados obtidos nos instrumentos avaliativos utilizados na unid ade.  \\n \\nParágrafo único.  A quantidade de instrumentos avaliativos por unidade é definida previamente \\npelo docente e divulgada no plano de ensino da turma.  \\n \\nArt. 102.   O rendimento acadêmico parcial (média parcial) é calculado pela média aritmética \\ndos rendi mentos acadêmicos obtidos em cada unidade avaliativa.  \\n \\nParágrafo único.  Em cada unidade avaliativa, o estudante deve atender o critério de'), Document(metadata={'page': 28, 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf'}, page_content='§2º  É facultado ao docente utilizar um instrumento de avaliação único para todos os \\nestudantes que fazem avaliação de reposição ou adotar instrumentos de avaliação distintos \\nrelacionados aos conteúdos de cada uma das unidades.  \\n \\n§3º  Não há mecanismo de reposição de nota para o estudante que não comparece à avaliação \\nde reposição.  \\n \\nArt. 117.   O estudante que realiza avaliação de reposição é considerado aprovado, quanto à \\navaliação do rendimento acadêmico, caso obtenha média final igual ou superior a 5, 0 (cinco), com \\nrendimento acadêmico igual ou superior a 4,0 (quatro) na avaliação de reposição.  \\n \\nArt. 118.   O prazo para realização da avaliação de reposição é de, no mínimo, 3 (três) dias \\nletivos, contados a partir da divulgação da média parcial e da freq uência do estudante no sistema de \\ngestão acadêmica.  \\n \\nArt. 119.  Não deve ser realizada avaliação de reposição sem que a média parcial e a frequência \\ndos estudantes tenham sido cadastradas no sistema de gestão acadêmica, sob pena de a referida \\navaliação ser  anulada.  \\n \\n§1º  O pedido de anulação da avaliação pode ser realizado por qualquer estudante da turma, \\ndevendo ser protocolado na unidade acadêmica a qual o componente curricular é vinculado, no prazo \\nmáximo de até 1 (um) dia útil após a realização da ativi dade.  \\n \\n§2º  Compete à chefia da unidade acadêmica avaliar o pedido de anulação da atividade e, \\nsendo constatado que as condições previstas no caput  deste artigo não tenham sido cumpridas, \\ndeterminar a anulação da atividade e a publicação imediata da média parcial e da frequência dos \\nestudantes.  \\n \\nArt. 120.  O critério de assiduidade  em uma disciplina presencial é satisfeito quando o \\nestudante cumpre a frequência mínima correspondente a 75% (setenta e cinco por cento) da carga \\nhorária do componente curricular , considerando o rendimento acadêmico exigido.  \\n \\nArt. 121.   É permitido ao estudante, mediante requerimento fundamentado, solicitar revisão do \\nregistro de frequência em uma unidade avaliativa.   \\n \\nParágrafo único.  A revisão do registro de frequência segue p rocedimentos similares aos da \\nrevisão de rendimento acadêmico previstos no art. 107.  \\n \\nCAPÍTULO II  \\nDA AVALIAÇÃO DE APRENDIZAGEM EM BLOCOS  \\n \\nArt. 122.  Para aprovação em um bloco, o estudante deve ser aprovado em cada um de seus \\nsub-blocos, satisfazendo os cr itérios de aprovação tanto na avaliação do rendimento acadêmico quanto \\nna assiduidade, nos termos dos art. 114 e 120.  \\n \\n§1º  A média final do bloco será a média ponderada dos resultados obtidos nos sub -blocos, \\nconsiderando como pesos suas respectivas carga s horárias.'), Document(metadata={'page': 27, 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf'}, page_content='I - prova substitutiva a ser realizada em data alternativa, no turno de estudo do estudante ou \\nem outro horário agendado c om sua anuência expressa; ou  \\n \\nII - trabalho escrito ou outra modalidade de atividade de pesquisa com tema, objetivo e data de \\nentrega definidos pelo docente responsável.  \\n \\nParágrafo único.  O estudante que em virtude de escusa de consciência solicitar a rep osição da \\natividade avaliativa, deverá comprovar, no momento da solicitação, que pertence à instituição religiosa \\nconforme estabelecido no caput  deste artigo.  \\n  \\nCAPÍTULO I  \\nDA AVALIAÇÃO DA APRENDIZAGEM EM DISCIPLINAS  \\n \\nArt. 113.   O rendimento acadêmico nas disciplinas que têm previsão de nota deve ser expresso \\nem valores numéricos de 0 (zero) a 10 (dez), variando até a primeira casa decimal.  \\n \\nArt. 114.   É considerado aprovado, quanto à avaliação do rendimento acadêmico, o estudante \\nque tem média parcial igua l ou superior a 6,0 (seis), com rendimento acadêmico igual ou superior a 4,0 \\n(quatro) em todas as unidades.  \\n \\nParágrafo único. A média final para os estudantes aprovados, de acordo com os critérios \\nestabelecidos neste artigo, é igual à média parcial, fican do o estudante dispensado da atividade de \\nreposição.  \\n \\nArt. 115.   O estudante que não atinge os critérios de aprovação definidos no art. 114 tem \\ndireito à realização de uma avaliação de reposição se todas as seguintes condições forem atendidas:  \\n \\nI - o crité rio de assiduidade é satisfeito; e  \\n \\nII - o estudante tem média parcial igual ou superior a 3,0 (três).  \\n \\n§1º  O estudante que não atinge os critérios de aprovação definidos no art. 114 e que não pode \\nrealizar avaliação de reposição é considerado reprovado, com média final igual à média parcial.  \\n \\n§2º  O estudante que atinge os critérios de aprovação definidos no art. 114, não tem direito a \\nrealizar avaliação de reposição.  \\n \\n§3º  Caso o estudante não realize alguma atividade avaliativa, porém atinja os critério s de \\naprovação definidos art. 114, não terá direito a realizar avaliação de reposição.  \\n \\n§4º  Nos casos de turmas que contenham apenas uma unidade avaliativa fica dispensada a \\nexigência do critério estabelecido no inciso II deste artigo.  \\n \\nArt. 116.  Para o estudante que realiza avaliação de reposição, o rendimento acadêmico obtido \\nnesta avaliação substitui o menor rendimento acadêmico obtido em uma das unidades avaliativas.  \\n \\n§1º  A avaliação de reposição substitui a nota de somente uma das unidades avaliativ as.')]\n"
     ]
    }
   ],
   "source": [
    "print(docs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Retriever from a Vector Store\n",
    "\n",
    "To construct a retriever from a vector store, you can utilize its `.as_retriever()` method. This method allows you to create a retriever object that can efficiently search and retrieve relevant documents from the vector store. A retriever works as a runnable instance of the vector store, enabling you to perform similarity searches and retrieve documents based on their embeddings.\n",
    "\n",
    "#### Maximum Marginal Relevance Retrieval\n",
    "\n",
    "While the default retrieval method for a vector store is similarity search, ChromaDB supports an alternative approach called Maximum Marginal Relevance (MMR) search. MMR is a retrieval technique that aims to balance relevance and diversity in the retrieved documents.\n",
    "\n",
    "To use MMR-based retrieval with ChromaDB, you can specify it as the search type when creating the retriever. This is done by passing the appropriate parameter to the `.as_retriever()` method.\n",
    "\n",
    "#### Benefits of MMR-Based Search Compared to Similarity-Based Search\n",
    "\n",
    "MMR offers several advantages over traditional similarity-based search:\n",
    "\n",
    "1. **Diversity in Retrieved Documents**: MMR aims to retrieve a diverse set of documents that cover different aspects or subtopics related to the search query. This diversity helps to provide a more complete and well-rounded set of results.\n",
    "\n",
    "2. **Reduction of Redundant Information**: In similarity-based search, if multiple documents contain similar or near-redundant information and are highly similar to the search query, all of these documents tend to be retrieved. This redundancy can be problematic because it does not substantially add new information to the search results.\n",
    "\n",
    "MMR addresses this issue by considering not only the similarity of documents to the query but also the similarity between the retrieved documents themselves. It seeks to minimize redundancy by selecting documents that are both relevant to the query and dissimilar to the already retrieved documents.\n",
    "\n",
    "3. **Improved Information Coverage**: By retrieving a diverse set of documents, MMR helps to ensure that the search results cover a broader range of information related to the query. This is particularly useful when the user's information need is not fully satisfied by a single document or when exploring different perspectives on a topic.\n",
    "\n",
    "4. **Enhanced User Experience**: MMR-based search can lead to a better user experience by presenting users with a more varied and informative set of search results. Users can gain a more thorough understanding of the topic without having to sift through redundant information.\n",
    "\n",
    "> It's important to note that the effectiveness of MMR-based search depends on the quality and diversity of the documents in the vector store, as well as the tuning of the MMR algorithm parameters.\n",
    "\n",
    "With MMR, you can create a retriever that not only finds relevant documents but also promotes diversity in the search results. This approach can significantly enhance the usefulness and informativeness of the retrieved documents, leading to a more effective and satisfying search experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the ChromaDB instance with OpenAI embeddings into a retriever\n",
    "# 'as_retriever' method converts the ChromaDB instance into a retriever object\n",
    "# 'search_type='mmr'' specifies that the retriever should use Maximal Marginal Relevance (MMR) for search\n",
    "# MMR helps in diversifying the search results by balancing relevance and diversity\n",
    "retriever_openai = db_openai.as_retriever(search_type='mmr')\n",
    "\n",
    "# Convert the ChromaDB instance with Sentence Transformers embeddings into a retriever\n",
    "# Similar to the above, this converts the ChromaDB instance into a retriever object using MMR\n",
    "retriever_sentence_transformers = db_sentence_transformers.as_retriever(search_type='mmr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'page': 23, 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf'}, page_content='datas relativas a procedimentos reg ulares previstos neste regulamento.  \\n \\nArt. 94.   Os cursos de graduação se desenvolvem anualmente em dois períodos letivos \\nregulares estabelecidos no Calendário Universitário.  \\n \\n§1º  Os períodos letivos regulares têm duração de, no mínimo, 18 (dezoito) semana s de aulas.  \\n \\n§2º  Adicionalmente, a critério da instituição, pode ser realizado período letivo especial de \\nférias.  \\n \\n§3º  O período letivo especial de férias deve ter duração mínima de 4 (quatro) semanas.  \\n \\nArt. 95.   As aulas presenciais semanais da UFRN são  ministradas:  \\n \\nI - de segunda -feira a sábado, conforme o Calendário Universitário;  \\n \\nII - em três turnos diários: matutino, vespertino e noturno;  \\n \\nIII -  com duração de 50 (cinquenta) minutos de atividades; e  \\n \\nIV - conforme distribuição semanal dos horários  de aulas apresentada no Anexo I deste \\nRegulamento.  \\n \\n§1º  Deve ser ministrada a quantidade de aulas necessária para o cumprimento total da carga \\nhorária dos componentes curriculares no período letivo.  \\n \\n§2º  Quando necessário o docente deverá ministrar aula  de reposição para cumprir o que \\nestabelece o §1º  deste artigo.  \\n \\n§3º  As unidades de ensino do interior do estado podem estabelecer horários noturnos \\ndistintos dos definidos no Anexo I deste Regulamento, sem prejuízo de atendimento aos incisos I, II e III  \\ndeste artigo, mediante aprovação da Câmara de Graduação.  \\n \\nTÍTULO VI  \\nDA AVALIAÇÃO DE APRENDIZAGEM  \\n \\nArt. 96.   A avaliação da aprendizagem, processo mediado pelo docente, compreende o \\ndiagnóstico e o acompanhamento do desenvolvimento de conhecimentos, habil idades e atitudes pelo \\nestudante, bem como a análise dos registros produzidos ao longo do processo para fins de atribuição do \\nrendimento acadêmico.  \\n \\nParágrafo único.  De modo complementar, os resultados do processo de avaliação devem \\nsubsidiar a reflexão e , caso necessário, o redimensionamento da prática pedagógica docente.  \\n \\nArt. 97.   A avaliação da aprendizagem deve verificar a apropriação dos conhecimentos por \\nparte dos estudantes, considerando os objetivos, conteúdos propostos no programa do componente \\ncurricular e o perfil do egresso estabelecido pelas Diretrizes Curriculares Nacionais e Projeto Pedagógico \\nde Curso.'), Document(metadata={'page': 28, 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf'}, page_content='§2º  É facultado ao docente utilizar um instrumento de avaliação único para todos os \\nestudantes que fazem avaliação de reposição ou adotar instrumentos de avaliação distintos \\nrelacionados aos conteúdos de cada uma das unidades.  \\n \\n§3º  Não há mecanismo de reposição de nota para o estudante que não comparece à avaliação \\nde reposição.  \\n \\nArt. 117.   O estudante que realiza avaliação de reposição é considerado aprovado, quanto à \\navaliação do rendimento acadêmico, caso obtenha média final igual ou superior a 5, 0 (cinco), com \\nrendimento acadêmico igual ou superior a 4,0 (quatro) na avaliação de reposição.  \\n \\nArt. 118.   O prazo para realização da avaliação de reposição é de, no mínimo, 3 (três) dias \\nletivos, contados a partir da divulgação da média parcial e da freq uência do estudante no sistema de \\ngestão acadêmica.  \\n \\nArt. 119.  Não deve ser realizada avaliação de reposição sem que a média parcial e a frequência \\ndos estudantes tenham sido cadastradas no sistema de gestão acadêmica, sob pena de a referida \\navaliação ser  anulada.  \\n \\n§1º  O pedido de anulação da avaliação pode ser realizado por qualquer estudante da turma, \\ndevendo ser protocolado na unidade acadêmica a qual o componente curricular é vinculado, no prazo \\nmáximo de até 1 (um) dia útil após a realização da ativi dade.  \\n \\n§2º  Compete à chefia da unidade acadêmica avaliar o pedido de anulação da atividade e, \\nsendo constatado que as condições previstas no caput  deste artigo não tenham sido cumpridas, \\ndeterminar a anulação da atividade e a publicação imediata da média parcial e da frequência dos \\nestudantes.  \\n \\nArt. 120.  O critério de assiduidade  em uma disciplina presencial é satisfeito quando o \\nestudante cumpre a frequência mínima correspondente a 75% (setenta e cinco por cento) da carga \\nhorária do componente curricular , considerando o rendimento acadêmico exigido.  \\n \\nArt. 121.   É permitido ao estudante, mediante requerimento fundamentado, solicitar revisão do \\nregistro de frequência em uma unidade avaliativa.   \\n \\nParágrafo único.  A revisão do registro de frequência segue p rocedimentos similares aos da \\nrevisão de rendimento acadêmico previstos no art. 107.  \\n \\nCAPÍTULO II  \\nDA AVALIAÇÃO DE APRENDIZAGEM EM BLOCOS  \\n \\nArt. 122.  Para aprovação em um bloco, o estudante deve ser aprovado em cada um de seus \\nsub-blocos, satisfazendo os cr itérios de aprovação tanto na avaliação do rendimento acadêmico quanto \\nna assiduidade, nos termos dos art. 114 e 120.  \\n \\n§1º  A média final do bloco será a média ponderada dos resultados obtidos nos sub -blocos, \\nconsiderando como pesos suas respectivas carga s horárias.'), Document(metadata={'page': 39, 'source': 'data/estatuto.pdf'}, page_content='40\\nouequivalenteetenhamsidoclassificadosemprocesso\\nseletivo;\\nII.portadoresdediplomasdecursosuperior;\\nIII.transferênciasobrigatóriasefacultativas;\\nIV.bolsistasdeacordoculturalentreoBrasileoutros\\npaíses;\\nV.alunosdeoutrasinstituições,nascondições\\nestabelecidasemconvênioscomaUniversidade;\\nVI.Matrículasautorizadasnascondiçõesde\\nreciprocidadediplomática,previstasemlei.\\nArt.42.APós-Graduaçãocompreendequatrosníveis\\ndeformação:\\nI.aperfeiçoamento;\\nII.especialização;\\nIII.mestrado;\\nIV.doutorado.\\nParágrafoÚnico.Nenhumdosníveisconstitui\\nrequisitoindispensávelàmatrículaemoutro.\\nArt.43.OCursodeGraduaçãohabilitaàobtençãode\\ngrauacadêmicoouprofissionaleematividadetécnicaou\\ncientífica.'), Document(metadata={'page': 8, 'source': 'data/estatuto.pdf'}, page_content='9\\nregionais,eparaaelevaçãodoníveldevidadopovo\\nbrasileiro.\\nParágrafoÚnico.Nocumprimentodessesobjetivos,\\naUniversidadenãopermiteasuperposiçãodemeiosparao\\nalcancedefinsidênticosouequivalentes.\\n–CapítuloIII–\\nDaconstituiçãobásica\\nArt.5oAUniversidadeestáestruturadadaseguinte\\nforma:\\nI.ConselhosSuperiores;\\nII.Reitoria;\\nIII.CentrosAcadêmicos;\\nIV.UnidadesAcadêmicasEspecializadas;\\nV.DepartamentosAcadêmicos;\\nVI.UnidadesSuplementares;\\nVII.NúcleosdeEstudosInterdisciplinares;\\nVIII.ComissõesPermanentes.\\nParágrafoÚnico.AUniversidadetemuma\\nAssembleiaUniversitáriaparaosatosesolenidadesdefinidos')]\n"
     ]
    }
   ],
   "source": [
    "# Print the results of invoking the retriever with the specified query\n",
    "# 'retriever_openai' is the retriever object created from the ChromaDB instance with OpenAI embeddings\n",
    "# 'invoke(query)' method performs the search using the query and returns the most relevant documents\n",
    "print(retriever_openai.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07798121fe0240e1b130bc14aa115b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'page': 24, 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf'}, page_content='das unidades, é obrigatória a realização de uma avaliação escrita, individual e presencial.  \\n \\n§4º  A unidade de vinculação do componen te curricular poderá, excepcionalmente, dispensar a \\nobrigatoriedade estabelecida no §3º  deste artigo.  \\n \\nArt. 101.  O rendimento acadêmico de cada unidade avaliativa é calculado a partir dos \\nresultados obtidos nos instrumentos avaliativos utilizados na unid ade.  \\n \\nParágrafo único.  A quantidade de instrumentos avaliativos por unidade é definida previamente \\npelo docente e divulgada no plano de ensino da turma.  \\n \\nArt. 102.   O rendimento acadêmico parcial (média parcial) é calculado pela média aritmética \\ndos rendi mentos acadêmicos obtidos em cada unidade avaliativa.  \\n \\nParágrafo único.  Em cada unidade avaliativa, o estudante deve atender o critério de'), Document(metadata={'page': 43, 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf'}, page_content='e o valor acrescentado ao perfil inicial é descontado do prazo máximo para conclusão do curso.  \\n \\nCAPÍTULO III  \\nDA CRIAÇÃO DE T URMAS  \\n \\nArt. 195.   No prazo estabelecido no Calendário Universitário, as coordenações de curso devem \\nsolicitar às unidades acadêmicas de vinculação dos componentes curriculares a criação das turmas para \\no período letivo regular subsequente, indicando a mo dalidade de oferta da turma, o horário pretendido \\ne o número de vagas desejado para cada turno e ênfase ou habilitação.  \\n \\n§1º  A solicitação de turmas ocorre por meio do sistema de gestão acadêmica.'), Document(metadata={'page': 30, 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf'}, page_content='Art. 132.   As formas regulares de ingresso nos cursos de graduação da UFRN são:  \\n \\nI - Sistema de Seleção Unificada - SiSU;  \\n \\nII - Processo Seletivo Específico - PSE;  \\n \\nIII - Reingresso Específico;'), Document(metadata={'page': 2, 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf'}, page_content='§3º  É vedada a criação de ênfases em cursos que possuam habilitações ativas e a criação de \\nhabilitações em cursos que possuem ênfases ativas.  \\n \\n§4º  A matriz curricular do curso é constituída por uma ou mais estruturas curriculares, de \\nacordo com os art. 27 a 34.  \\n \\nArt. 12 .  Os cursos de graduação presenciais funcionam nos turnos matutino, vespertino ou \\nnoturno, podendo cada curso funcionar em mais de um turno ou em turnos combinados.')]\n"
     ]
    }
   ],
   "source": [
    "# Print the results of invoking the retriever with the specified query\n",
    "# 'retriever_sentence_transformers' is the retriever object created from the ChromaDB instance with Sentence Transformers embeddings\n",
    "# 'invoke(query)' method performs the search using the query and returns the most relevant documents\n",
    "print(retriever_sentence_transformers.invoke(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary classes from the langchain_core module\n",
    "# ChatPromptTemplate is used to define the structure of the chat prompt\n",
    "# HumanMessage, SystemMessage, and AIMessage are used to define different types of messages in the chat\n",
    "# StrOutputParser is used to parse the output of the chat\n",
    "# RunnablePassthrough is used to pass data through without modification\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Define the chat prompt template with a series of messages\n",
    "# 'from_messages' method creates a ChatPromptTemplate from a list of message tuples\n",
    "# Each tuple contains a message type and the message content\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # System message to establish the assistant's role\n",
    "        # This message sets the context for the assistant, instructing it to answer questions about UFRN\n",
    "        # If the assistant doesn't know the answer, it should say so\n",
    "        (\"system\", \"Você é um assistente de alunos que responde a dúvidas sobre a UFRN. Use as informações fornecidas para responder às perguntas dos alunos. Se você não souber a resposta, apenas diga que não sabe.\"),\n",
    "\n",
    "        # Placeholder for chat history to maintain context\n",
    "        # This placeholder will be replaced with the actual chat history during execution\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "\n",
    "        # Human message placeholder for user input\n",
    "        # This placeholder will be replaced with the user's question and context during execution\n",
    "        (\"human\", \"\\nCONTEXTO: {context} \\n\\nPERGUNTA: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define a function to format retrieved documents\n",
    "# 'docs' is a list of document objects\n",
    "# The function joins the page content of each document with four newline characters in between\n",
    "def format_retrieved_documents(docs):\n",
    "    return \"\\n\\n\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a base runnable for the Sentence Transformers retriever\n",
    "# This runnable will handle the context and question for the chat prompt\n",
    "base_runnable_sentence_transformers = (\n",
    "    {\n",
    "        # 'context' key will use the retriever to get relevant documents and format them\n",
    "        # 'retriever_sentence_transformers' retrieves relevant documents based on the query\n",
    "        # 'format_retrieved_documents' formats the retrieved documents for the chat prompt\n",
    "        \"context\": retriever_sentence_transformers | format_retrieved_documents,\n",
    "        \n",
    "        # 'question' key will pass the question directly to the retriever without modification\n",
    "        \"question\": RunnablePassthrough(), \n",
    "    } \n",
    "    # Combine the context and question with the chat prompt template\n",
    "    | prompt \n",
    ")\n",
    "\n",
    "# Define a base runnable for the OpenAI retriever\n",
    "# This runnable will handle the context and question for the chat prompt\n",
    "base_runnable_openai = (\n",
    "    {\n",
    "        # 'context' key will use the retriever to get relevant documents and format them\n",
    "        # 'retriever_openai' retrieves relevant documents based on the query\n",
    "        # 'format_retrieved_documents' formats the retrieved documents for the chat prompt\n",
    "        \"context\": retriever_openai | format_retrieved_documents,\n",
    "        \n",
    "        # 'question' key will pass the question directly to the retriever without modification\n",
    "        \"question\": RunnablePassthrough(), \n",
    "    } \n",
    "    # Combine the context and question with the chat prompt template\n",
    "    | prompt \n",
    ")\n",
    "\n",
    "# Initialize an output parser to parse the string output of the chat\n",
    "# 'StrOutputParser' is used to parse the output of the chat into a string format\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RAG (Retrieval-Augmented Generation) chain using Sentence Transformers embeddings and OpenAI model\n",
    "# 'base_runnable_sentence_transformers' handles the context and question for the chat prompt using Sentence Transformers embeddings\n",
    "# 'model_openai' is the OpenAI model used to generate responses based on the retrieved context and question\n",
    "# 'output_parser' parses the output of the OpenAI model into a string format\n",
    "\n",
    "rag_chain_sentence_transformers_openai = (\n",
    "    base_runnable_sentence_transformers  # Use the base runnable with Sentence Transformers embeddings\n",
    "    | model_openai                       # Pass the result to the OpenAI model for response generation\n",
    "    | output_parser                      # Parse the model's output into a string format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RAG (Retrieval-Augmented Generation) chain using Sentence Transformers embeddings and Llama 3.1 model\n",
    "\n",
    "rag_chain_sentence_transformers_llama = (\n",
    "    base_runnable_sentence_transformers  # Use the base runnable with Sentence Transformers embeddings\n",
    "    | model_llama                        # Pass the result to the Llama 3.1 model for response generation\n",
    "    | output_parser                      # Parse the model's output into a string format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RAG (Retrieval-Augmented Generation) chain using OpenAI embeddings and OpenAI model\n",
    "\n",
    "rag_chain_openai_openai = (\n",
    "    base_runnable_openai  # Use the base runnable with OpenAI embeddings\n",
    "    | model_openai        # Pass the result to the OpenAI model for response generation\n",
    "    | output_parser       # Parse the model's output into a string format\n",
    ")\n",
    "\n",
    "# Create a RAG (Retrieval-Augmented Generation) chain using OpenAI embeddings and Llama 3.1 model\n",
    "rag_chain_openai_llama = (\n",
    "    base_runnable_openai  # Use the base runnable with OpenAI embeddings\n",
    "    | model_llama         # Pass the result to the Llama 3.1 model for response generation\n",
    "    | output_parser       # Parse the model's output into a string format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Quando foi fundado o Restaurante Universitário da UFRN?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3eee485d509411986d07b8188630e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'O Restaurante Universitário da UFRN foi fundado em 1973.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_sentence_transformers_openai.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415f562737f64b36a58d03d0df688261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'O restaurante universitário tem uma longa história no campus central Werre, e foi construído no ano de 1973.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_sentence_transformers_llama.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O Restaurante Universitário da UFRN foi fundado em 1973.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_openai_openai.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Não sei. A informação não está disponível na seção de notícias que você forneceu.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_openai_llama.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d999913c451944cbac1f62b5408904e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a93c180a5ed467d8d838c8183f2c1ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Embedding: sentence_transformers\n",
      "LLM: openai\n",
      "Response: O projeto de IA para o Judiciário com foco em proteção ambiental está sendo realizado em parceria com a UFRN, sob a coordenação do professor Elias Jacob.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Embedding: sentence_transformers\n",
      "LLM: llama\n",
      "Response: O professor Elias Jacob está fazendo o projeto de IA para o Judiciário com foco em proteção ambiental. Ele explica que a iniciativa busca fortalecer a atuação do Judiciário na tutela do meio ambiente, considerando que a Justiça brasileira dispõe de um conjunto de informações e dados relevantes sobre conflitos e crimes ambientais.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Embedding: openai\n",
      "LLM: openai\n",
      "Response: O projeto de IA para o Judiciário com foco em proteção ambiental está sendo realizado pelo Programa das Nações Unidas para o Desenvolvimento (Pnud), o Conselho Nacional de Justiça (CNJ) e a Universidade Federal do Rio Grande do Norte (UFRN).\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Embedding: openai\n",
      "LLM: llama\n",
      "Response: Desculpe, mas não há informações suficientes no texto fornecido sobre um projeto específico de Inteligência Artificial (IA) para o Judiciário com foco em proteção ambiental. O texto menciona a conclusão da primeira turma do projeto \"Tecendo Conexões Digitais: Fake News e Storytelling\" pelo Instituto Metrópole Digital (IMD/UFRN), que visa promover a capacidade crítica no uso de meios digitais para idosos, mas não aborda diretamente um projeto relacionado à IA ou proteção ambiental. Se você tiver mais informações sobre o projeto específico em questão, ficarei feliz em tentar ajudar.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_response_all_models(query):\n",
    "    # Dictionary to store responses from different RAG chains\n",
    "    result = {\n",
    "        'sentence_transformers-openai': rag_chain_sentence_transformers_openai.invoke(query),\n",
    "        'sentence_transformers-llama': rag_chain_sentence_transformers_llama.invoke(query),\n",
    "        'openai-openai': rag_chain_openai_openai.invoke(query),\n",
    "        'openai-llama': rag_chain_openai_llama.invoke(query)\n",
    "    }\n",
    "    \n",
    "    # Iterate over the results and print them in a formatted manner\n",
    "    for k, v in result.items():\n",
    "        print('-'*50)  # Separator for readability\n",
    "        print(f\"Embedding: {k.split('-')[0]}\")  # Display the embedding type\n",
    "        print(f\"LLM: {k.split('-')[1]}\")  # Display the language model used\n",
    "        print(f\"Response: {v}\")  # Display the response\n",
    "        print('-'*50)  # Separator for readability\n",
    "        print(\"\\n\")  # Newline for better formatting\n",
    "        \n",
    "    return result  # Return the dictionary with all responses\n",
    "\n",
    "# Example query to test the function\n",
    "result = get_response_all_models('Quem está fazendo o projeto de IA para o Judiciário como foco em proteção ambiental?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973847ec1f004b8da5d9353bdb86733c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0505de4641f447eaef6df859699782e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Embedding: sentence_transformers\n",
      "LLM: openai\n",
      "Response: Não sei.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Embedding: sentence_transformers\n",
      "LLM: llama\n",
      "Response: Desculpe, mas não há informações disponíveis sobre a frequência mínima exigida para aprovação em uma disciplina na UFRN. As regras mencionadas se referem principalmente à matrícula, avaliação e certificação de estudantes, mas não especificam requisitos de frequência. Se você tiver mais informações ou precisar de ajuda com outra pergunta, estou aqui para ajudar!\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Embedding: openai\n",
      "LLM: openai\n",
      "Response: A frequência mínima exigida de um aluno para ser aprovado em uma disciplina na UFRN é de 75% (setenta e cinco por cento) da carga horária do componente curricular.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Embedding: openai\n",
      "LLM: llama\n",
      "Response: De acordo com o Artigo 120, a frequência mínima exigida é de 75% da carga horária do componente curricular.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = get_response_all_models('Qual é a frequência mínima exigida de um aluno para ser aprovado em uma disciplina na UFRN?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final thoughts\n",
    "\n",
    "In this notebook, we successfully created a chatbot capable of accessing a knowledge base about UFRN to provide accurate and relevant responses to user queries. The chatbot utilizes a Retrieval-Augmented Generation (RAG) system, which enables it to retrieve related information from the knowledge base and generate appropriate answers.\n",
    "\n",
    "The development of the RAG system involved several steps:\n",
    "\n",
    "1. **Defining the LLM Models**\n",
    "    - We employed models from OpenAI and Ollama to generate responses to user queries.\n",
    "    - While these models are highly capable, they may lack specific details about UFRN's regulations, emphasizing the importance of a RAG system.\n",
    "\n",
    "2. **Loading and Preparing Documents**\n",
    "    - We gathered documents from various sources, including PDFs, HTML pages, YouTube videos, and arbitrary text.\n",
    "    - LangChain's document loaders were utilized to extract and prepare these texts for storage.\n",
    "\n",
    "3. **Chunking the Text**\n",
    "    - The documents were divided into manageable segments using different chunking strategies, such as token-based chunking.\n",
    "    - Chunk size and overlap were carefully considered to ensure efficient storage and retrieval while maintaining information coherence.\n",
    "\n",
    "4. **Storing Chunks in ChromaDB**\n",
    "    - We established a connection to ChromaDB, created collections, and inserted our text chunks.\n",
    "    - Data integrity was verified through successful storage and queries.\n",
    "    - Consistent embedding models were used to ensure comparability.\n",
    "\n",
    "5. **Building Retrievers from Vector Stores**\n",
    "    - Retrievers were created using ChromaDB's similarity and Maximum Marginal Relevance (MMR)-based search methods.\n",
    "    - MMR-based search proved beneficial in reducing redundant information and enhancing the diversity of retrieved documents.\n",
    "\n",
    "6. **Integrating Retrievers with LLMs**\n",
    "    - The retrievers were integrated with our LLMs using LangChain's prompt templates and output parsers.\n",
    "    - This assimilation resulted in a system that efficiently retrieves relevant information and generates accurate responses to user queries.\n",
    "\n",
    "\n",
    "The combination of ChromaDB and LangChain provides a flexible and powerful foundation for developing knowledge-intensive AI applications. The techniques demonstrated in this project can be adapted for other domains and use cases, making it a versatile approach for building RAG systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final suggestion - [BGE-M3](https://arxiv.org/pdf/2402.03216)\n",
    "\n",
    "There is a new model on the block that is showing promising results in the field of RAG. The BGE-M3 model, developed by the Beijing Academy of Artificial Intelligence (BAAI), is a cutting-edge multilingual model that has shown promising results in the field of Retrieval-Augmented Generation (RAG). This state-of-the-art model is designed to generate high-quality embeddings for a wide range of languages, making it particularly well-suited for RAG applications requiring multilingual support.\n",
    "\n",
    "\n",
    "### Key Features and Capabilities\n",
    "\n",
    "1. **Multilingual Support**: BGE-M3 works seamlessly with 100 languages, enabling it to cater to a diverse range of multilingual RAG tasks.\n",
    "\n",
    "2. **Flexible Input Processing**: The model can handle inputs of varying granularities, from short sentences to long documents containing up to 8,192 tokens. This flexibility allows BGE-M3 to adapt to different text input sizes and types.\n",
    "\n",
    "3. **High-Quality Embeddings**: BGE-M3 generates high-quality embeddings that effectively capture the semantic information of the input text. These embeddings serve as a robust foundation for subsequent retrieval and generation tasks in RAG systems.\n",
    "\n",
    "\n",
    "### Accessing BGE-M3 through Ollama\n",
    "\n",
    "To use the BGE-M3 model in your RAG system, you can utilize the Ollama library. You'll need to pull from their hub using the following command:\n",
    "\n",
    "```bash\n",
    "(base) jacob@schrodinger ~ % ollama pull bge-m3\n",
    "pulling manifest\n",
    "pulling daec91ffb5dd... 100% ▕████████████████▏ 1.2 GB\n",
    "pulling a406579cd136... 100% ▕████████████████▏ 1.1 KB\n",
    "pulling 0c4c9c2a325f... 100% ▕████████████████▏ 337 B\n",
    "verifying sha256 digest\n",
    "writing manifest\n",
    "removing any unused layers\n",
    "success\n",
    "```\n",
    "\n",
    "This will download and set up the BGE-M3 model, making it readily available for embedding generation in your RAG system.\n",
    "\n",
    "### Advantages of BGE-M3 in RAG Systems\n",
    "\n",
    "- **Enhanced Multilingual Capabilities**: With support for 100 languages, BGE-M3 enables RAG systems to operate effectively in multilingual environments. This is particularly valuable for applications that require processing and generating text in multiple languages.\n",
    "\n",
    "- **Improved Handling of Long Documents**: The ability to process documents up to 8,192 tokens in length makes BGE-M3 well-equipped to handle longer text inputs. This is beneficial for RAG tasks that involve retrieving and generating information from extensive documents or passages.\n",
    "\n",
    "- **Increased Accuracy and Relevance**: The high-quality embeddings generated by BGE-M3 contribute to improved accuracy and relevance in the retrieval and generation components of RAG systems. By capturing the semantic information effectively, BGE-M3 helps ensure that the most relevant information is retrieved and used for generating accurate and coherent responses.\n",
    "\n",
    "and, best of all... it's `free`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model='bge-m3', # 'model' specifies the model to use, in this case 'bge-m3'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'Eu gostaria de saber mais sobre o processo avaliativo na UFRN.',\n",
    "    'Qual é a frequência mínima exigida de um aluno para ser aprovado em uma disciplina na UFRN?',\n",
    "    'Como funcionam os trabalhos na educação superior de uma Universidade federal brasileira?,'\n",
    "    'Cachorros são fofos'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = embeddings.embed_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.67359903 0.53965653]\n",
      " [0.67359903 1.         0.47929212]\n",
      " [0.53965653 0.47929212 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the cosine similarity between all documents\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate the cosine similarity between all pairs of vectors\n",
    "cosine_sim = cosine_similarity(vectors, vectors)\n",
    "\n",
    "# Print the cosine similarity matrix\n",
    "print(cosine_sim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between document 0 and document 1: 0.6735990293791523\n",
      "Similarity between document 0 and document 2: 0.5396565250362185\n",
      "Similarity between document 1 and document 2: 0.479292122881946\n"
     ]
    }
   ],
   "source": [
    "# Print the similarity between all pairs of documents\n",
    "for i in range(len(texts)):\n",
    "    for j in range(i + 1, len(texts)):\n",
    "        print(f\"Similarity between document {i} and document {j}: {cosine_sim[i][j]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "1. What is Retrieval-Augmented Generation (RAG), and how does it enhance traditional generative models?\n",
    "\n",
    "2. What are the main challenges in generative AI that RAG aims to address, and why are they significant?\n",
    "\n",
    "3. Describe the key components of a RAG system and their roles in the overall architecture.\n",
    "\n",
    "4. How do vector databases like ChromaDB contribute to the efficiency and effectiveness of RAG systems?\n",
    "\n",
    "5. Outline the fundamental principles of RAG and explain their importance in improving the quality of generated text.\n",
    "\n",
    "6. Compare and contrast RAG with traditional generative models, highlighting the advantages of using RAG.\n",
    "\n",
    "7. Explain how RAG solves the problem of limited knowledge scope in generative models and its effects for generating accurate and up-to-date content.\n",
    "\n",
    "8. What is the role of Maximum Marginal Relevance (MMR) search in RAG systems, and how does it enhance the diversity and relevance of retrieved information?\n",
    "\n",
    "9. Discuss the adaptability of RAG systems to various domains and use cases, and provide examples of how they can be customized to meet specific requirements.\n",
    "\n",
    "10. Outline the step-by-step process of building a RAG system using ChromaDB and LangChain, emphasizing the key considerations and best practices at each stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Answers are commented inside this cell`\n",
    "\n",
    "\n",
    "<!-- 1. Retrieval-Augmented Generation (RAG) is an AI framework that enhances traditional generative models by integrating information retrieval systems. It allows for the generation of text that is coherent, contextually relevant, accurate, and up-to-date by leveraging external knowledge sources during the generation process. RAG improves the quality and relevance of generated text by providing the model with access to a vast pool of information beyond its training data.\n",
    "\n",
    "2. RAG addresses several key challenges in generative AI, including limited knowledge scope, factual inaccuracy, contextual irrelevance, data sparsity, training limitations, inflexibility, and the need for real-time information retrieval. These challenges hinder the ability of generative models to produce high-quality, accurate, and relevant content. RAG enables the creation of more reliable, adaptable, and context-aware generative AI systems.\n",
    "\n",
    "3. A RAG system consists of two main components: a retriever and a generator. The retriever is responsible for searching and retrieving relevant information from an external knowledge source based on the input query. It uses techniques like semantic search and similarity matching to identify the most relevant information. The generator takes the retrieved information and the original query as input and produces the final output response by integrating the retrieved knowledge into the generation process.\n",
    "\n",
    "4. Vector databases like ChromaDB play a crucial role in RAG systems by efficiently storing and querying embedding data. Embeddings are dense vector representations of text that capture semantic meaning. ChromaDB allows RAG systems to quickly retrieve the most relevant information based on similarity metrics, such as cosine similarity, between the query and the stored embeddings. This enables the retrieval of highly relevant and accurate information, enhancing the quality of generated responses.\n",
    "\n",
    "5. The key principles of RAG include:\n",
    "- Retrieving relevant information from external knowledge bases to expand the model's knowledge scope.\n",
    "- Integrating retrieved information into the generation process to improve the accuracy and relevance of generated text.\n",
    "- Enhancing context awareness and factual accuracy by leveraging up-to-date and domain-specific knowledge.\n",
    "- Improving flexibility and scalability by allowing the model to adapt to new information without requiring retraining.\n",
    "- Providing real-time access to up-to-date information to generate current and relevant content.\n",
    "These principles collectively contribute to the creation of more reliable, adaptable, and high-quality generative AI systems.\n",
    "\n",
    "6. Compared to traditional generative models, RAG offers several advantages:\n",
    "- Enhanced factual accuracy: RAG incorporates external knowledge sources, reducing the reliance on the model's training data and improving the accuracy of generated facts.\n",
    "- Improved context awareness: By retrieving relevant information based on the input query, RAG generates text that is more contextually appropriate and coherent.\n",
    "- Reduced reliance on extensive training data: RAG can capitalize on external knowledge sources, reducing the need for large-scale training data and enabling the generation of diverse content.\n",
    "- Flexibility and adaptability: RAG systems can be easily adapted to different domains or updated with new information without requiring retraining of the entire model.\n",
    "\n",
    "7. RAG solves the problem of limited knowledge scope in generative models by incorporating an information retrieval component. This allows the model to fetch relevant, up-to-date information from external knowledge sources, expanding the knowledge base beyond the training data.\n",
    "\n",
    "8. Maximum Marginal Relevance (MMR) search is a technique used in RAG systems to enhance the diversity and relevance of retrieved information. MMR search aims to balance the relevance of retrieved documents to the query while also promoting diversity in the search results. It achieves this by considering both the similarity of documents to the query and the dissimilarity among the retrieved documents.\n",
    "\n",
    "9. RAG systems can be adapted to various domains and use cases by customizing the external knowledge source, chunking strategies, embedding models, and retrieval methods. For example, in a medical domain, the knowledge source can be a database of medical literature, and the chunking strategy can be tailored to extract relevant sections like abstracts or conclusions. The embedding model can be fine-tuned on medical text to capture domain-specific semantics. Similarly, for a legal use case, the knowledge source can be a collection of legal documents, and the retrieval methods can be adapted to handle legal jargon and citation styles.\n",
    "\n",
    "10. Building a RAG system with ChromaDB and LangChain involves the following steps:\n",
    "1. Define the LLM models: Select the appropriate language model(s) for text generation based on the specific requirements of the task.\n",
    "2. Load and prepare documents: Collect and preprocess the relevant documents that will serve as the external knowledge source for the RAG system.\n",
    "3. Chunk the text: Split the documents into manageable segments or chunks that can be efficiently stored and retrieved.\n",
    "4. Store chunks in ChromaDB: Create a ChromaDB instance and store the text chunks along with their embeddings for efficient retrieval.\n",
    "5. Build retrievers: Create retriever objects from the ChromaDB vector stores to enable fast and accurate retrieval of relevant chunks based on similarity metrics.\n",
    "6. Integrate retrievers with LLMs: Use LangChain's prompt templates and output parsers to integrate the retrievers with the selected LLM(s) and generate text based on the retrieved information.\n",
    "7. Fine-tune and optimize: Restate and fine-tune the RAG system by adjusting parameters, experimenting with different retrieval strategies, and optimizing the prompts and output parsing logic.\n",
    "8. Test and evaluate: Assess the performance of the RAG system using relevant evaluation metrics and gather feedback for further improvements. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
