{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG)\n",
    "## IMD1107 - Natural Language Processing\n",
    "### [Dr. Elias Jacob de Menezes Neto](htttps://docente.ufrn.br/elias.jacob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Keypoints\n",
    "\n",
    "- Retrieval-Augmented Generation (RAG) enhances traditional generative models by integrating information retrieval systems.\n",
    "\n",
    "- RAG addresses challenges like limited knowledge scope, factual inaccuracy, and contextual irrelevance in generative AI.\n",
    "\n",
    "- The RAG architecture consists of a retriever component to search external knowledge sources and a generator to produce responses.\n",
    "\n",
    "- Vector databases like ChromaDB are used to efficiently store and query embedding data for RAG systems.\n",
    "\n",
    "- Proper chunking of documents is crucial for effective storage and retrieval in RAG systems.\n",
    "\n",
    "- Different embedding models and LLMs can be combined to create varied RAG implementations.\n",
    "\n",
    "### Takeaways\n",
    "\n",
    "- RAG systems significantly improve the accuracy and relevance of AI-generated responses by utilizing external knowledge.\n",
    "\n",
    "- Careful consideration of chunking strategies, embedding models, and retrieval methods is essential for optimal RAG performance.\n",
    "\n",
    "- The choice of vector database and embedding model impacts the efficiency and effectiveness of information retrieval.\n",
    "\n",
    "- Integrating retrievers with LLMs using tools like LangChain enables flexible and powerful RAG implementations.\n",
    "\n",
    "- Maximum Marginal Relevance (MMR) search can enhance result diversity and reduce redundancy in retrieved information.\n",
    "\n",
    "- RAG systems can be adapted for various domains and use cases, making them versatile for knowledge-intensive AI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "## Definition and Concept\n",
    "Retrieval-Augmented Generation (RAG) is a powerful AI framework that enhances the capabilities of traditional generative models by integrating information retrieval systems. This combination allows RAG to generate text that is not only coherent and contextually relevant but also accurate and up-to-date. By using the strengths of both retrieval and generation, RAG provides a strong solution for various applications requiring precise and contextually enriched information.\n",
    "\n",
    "### Key Principles of RAG\n",
    "- Retrieval of relevant information from an external knowledge base\n",
    "- Assimilation of retrieved information into the generation process\n",
    "- Improved context awareness and factual accuracy in generated outputs\n",
    "- Enhanced flexibility and scalability through external knowledge sources\n",
    "- Real-time access to up-to-date information for dynamic applications\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What problems does RAG solve?\n",
    "\n",
    "Retrieval-Augmented Generation (RAG) addresses several key challenges in the field of natural language processing (NLP) and artificial intelligence (AI). Below are some of the primary problems that RAG aims to solve:\n",
    "\n",
    "1. Limited Knowledge Scope of Generative Models\n",
    "    - **Problem**: Traditional generative models (e.g., GPT-3) are limited by the static knowledge they acquired during their training phase. They cannot access or utilize information that was not included in their training data, making them less effective in providing up-to-date or domain-specific information.\n",
    "    - **RAG Solution**: RAG incorporates an information retrieval component that allows the model to fetch relevant, up-to-date information from external knowledge sources. This expands the knowledge base beyond the training data and enables the generation of more current and relevant content.\n",
    "\n",
    "2. Factual Inaccuracy\n",
    "    - **Problem**: Generative models can produce text that is grammatically correct and coherent but factually incorrect. This is particularly problematic in applications where accuracy is critical, such as healthcare, legal advice, and academic writing.\n",
    "    - **RAG Solution**: By retrieving factual information from reliable external sources and integrating it into the generation process, RAG enhances the factual accuracy of the generated text. This ensures that the responses are not only linguistically sound but also factually correct.\n",
    "\n",
    "3. Contextual Irrelevance\n",
    "    - **Problem**: Generative models often struggle with maintaining context, especially in multi-turn conversations or complex queries. They may provide responses that are contextually irrelevant or inconsistent with previous information.\n",
    "    - **RAG Solution**: The retrieval component of RAG allows the model to consider a broader and more relevant context, leading to more coherent and contextually appropriate responses. This is particularly beneficial for dialogue systems and complex question-answering tasks.\n",
    "\n",
    "4. Data Sparsity and Training Limitations\n",
    "    - **Problem**: Generative models require large amounts of diverse training data to perform well across different domains. However, gathering and curating such extensive datasets can be resource-intensive and time-consuming.\n",
    "    - **RAG Solution**: RAG reduces the reliance on extensive training data by using external knowledge bases. This means that even with less training data, RAG can still perform effectively across various topics and domains by retrieving and using relevant external information.\n",
    "\n",
    "5. Inflexibility and Scalability\n",
    "    - **Problem**: Traditional models need to be retrained to incorporate new information or adapt to different domains, which can be a costly and time-consuming process.\n",
    "    - **RAG Solution**: RAG systems can be easily updated by modifying the external knowledge source without requiring retraining of the entire model. This makes RAG more flexible and adaptable to new information and different domains, enhancing its scalability.\n",
    "\n",
    "6. Real-Time Information Retrieval\n",
    "    - **Problem**: Many applications require real-time access to the most current information. Traditional generative models, which rely solely on pre-trained data, cannot meet this demand effectively.\n",
    "    - **RAG Solution**: RAG's retrieval mechanism enables real-time access to the latest information, making it suitable for applications that require immediate and current responses, such as news generation or real-time customer support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages of RAG\n",
    "RAG offers several advantages over traditional generation methods:\n",
    "\n",
    "1. **Enhanced Factual Accuracy**: By retrieving relevant information from a reliable external source, RAG can generate responses that are more factually accurate and consistent with real-world knowledge.\n",
    "\n",
    "2. **Improved Context Awareness**: The retrieval component allows RAG to consider a wider range of contextual information, enabling it to generate more coherent and contextually appropriate responses.\n",
    "\n",
    "3. **Reduced Reliance on Training Data**: RAG can capitalize on external knowledge sources, reducing the need for extensive training data to cover various topics and domains.\n",
    "\n",
    "4. **Flexibility and Adaptability**: RAG systems can be easily adapted to different domains or updated with new knowledge by modifying the external knowledge source, without requiring retraining of the entire model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Use Cases and Applications\n",
    "RAG finds applications in various real-world scenarios where accurate and contextually relevant language generation is crucial:\n",
    "\n",
    "- **Question Answering**: RAG can retrieve relevant information to provide accurate and informative answers to user queries.\n",
    "\n",
    "- **Dialogue Systems**: RAG enables more engaging and contextually appropriate conversations in chatbots and virtual assistants.\n",
    "\n",
    "- **Content Generation**: RAG can assist in generating articles, summaries, or descriptions by retrieving relevant facts and details from external sources.\n",
    "\n",
    "- **Knowledge-Intensive Tasks**: RAG is particularly useful in domains that require access to a large amount of factual knowledge, such as healthcare, finance, or legal services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Architecture and Overview\n",
    "\n",
    "## Components of a RAG System\n",
    "A typical RAG system consists of two main components:\n",
    "\n",
    "1. **Retriever**: The retriever is responsible for searching and retrieving relevant information from an external knowledge source based on the input query or context. It uses techniques like similarity search or information retrieval to find the most relevant pieces of information.\n",
    "\n",
    "2. **Generator**: The generator is a language model that takes the retrieved information as input and generates the final output response. It integrates the retrieved knowledge into the generation process to produce informative and contextually appropriate responses.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"images/rag.webp\" alt=\"\" style=\"width: 50%; height: 50%\"/>\n",
    "</p>\n",
    " \n",
    "The diagram illustrates the components and workflow of a Retrieval-Augmented Generation (RAG) application. Here’s a detailed explanation of each component:\n",
    "\n",
    "### Data Preparation\n",
    "1. **Raw Data Sources (A)**: This is the initial stage where raw data is collected from various sources such as documents, PDFs, web pages, etc.\n",
    "\n",
    "2. **Information Extraction (B)**: This step involves extracting relevant information from the raw data. Techniques like Optical Character Recognition (OCR), PDF data extraction, and web crawlers are used to convert unstructured data into a structured format.\n",
    "\n",
    "3. **Chunking (C)**: The extracted information is then divided into smaller, manageable chunks. This process helps in handling large documents and ensures that the data can be processed efficiently.\n",
    "\n",
    "4. **Embedding (D)**: Each chunk of data is converted into a vector representation (embedding). This numerical representation captures the semantic meaning of the text, making it easier to compare and retrieve relevant information.\n",
    "\n",
    "### Retrieval-Augmented Generation (RAG) Workflow\n",
    "1. **Query (1)**: A user query is received, which initiates the RAG process.\n",
    "\n",
    "2. **Embedding (2)**: The query is also converted into an embedding (vector representation) to assist comparison with the stored data embeddings.\n",
    "\n",
    "3. **Vector Database**: Both the data embeddings and the query embedding are stored and managed in a vector database. This specialized database is optimized for handling and retrieving vector data.\n",
    "\n",
    "4. **Relevant Data (3)**: The vector database is queried to find the most relevant data chunks that match the query embedding. These relevant data chunks are then retrieved.\n",
    "\n",
    "5. **LLM(s) (4)**: The retrieved relevant data is fed into a Large Language Model (LLM). The LLM uses this data to generate a response that is contextually accurate and relevant to the query.\n",
    "\n",
    "6. **Response (5)**: Finally, the generated response is provided to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Flow in RAG\n",
    "The data flow in a RAG system follows these steps:\n",
    "\n",
    "1. The input query or context is provided to the retriever.\n",
    "2. The retriever searches the external knowledge source and retrieves the most relevant information based on the input.\n",
    "3. The retrieved information is passed to the generator along with the input query or context.\n",
    "4. The generator integrates the retrieved knowledge into the generation process and produces the final output response.\n",
    "\n",
    "## Incorporation with LLMs\n",
    "RAG can be integrated with existing Large Language Models (LLMs) to enhance their generation capabilities. The retriever component can be added as a preprocessing step before feeding the input to the LLM. The retrieved information can be concatenated with the input or used to condition the LLM's generation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Databases\n",
    "\n",
    "A vector database is a specialized database designed to efficiently store and query embedding data, extending the capabilities of traditional relational databases. The key distinguishing feature of a vector database is that query results are not exact matches to the query. Instead, using a specified similarity metric, the vector database returns embeddings that are similar to the query. This makes vector databases ideal for applications that involve comparing and retrieving embeddings based on their similarity rather than exact values.\n",
    "\n",
    "## Example Use Case\n",
    "\n",
    "Suppose you have stored some information about UFRN, like recent news and legislation that applies to our undergrad students. You can embed this information and store it in a vector database. When a user asks a question about UFRN, the query is embedded and compared to the stored embeddings. The vector database returns the most similar embeddings, which can then be used to generate a response. The vector database will accept a query like `Com quantos dias de antecedência um professor deve divulgar os resultados de uma prova antes de aplicar a próxima prova?` and embed the query (using the same embedding model as the one used to populate the database). It will then compare the embedded query to other embeddings in the vector database and return the documents that have embeddings most similar to the query embedding.\n",
    "\n",
    "The vector database will identify the document that had an embedding most similar to the query, likely based on the document's semantics. With that information, the LLM can generate a response that is contextually relevant to the user's query and factually accurate based on the retrieved document.\n",
    "\n",
    "## Fundamental Components of a Vector Database\n",
    "\n",
    "To make efficient storage and querying of embeddings possible, vector databases are equipped with features that balance the speed and accuracy of query results. Here are the central components you should know about:\n",
    "\n",
    "1. **Embedding Function**: When using a vector database, you often store and query data in its raw form rather than uploading embeddings directly. Internally, the vector database needs to know how to convert your data to embeddings, and you have to specify an embedding function for this. For text, you can use embedding functions from libraries like SentenceTransformers or OpenAI's embedding models (or any other function that maps raw text to vectors).\n",
    "\n",
    "2. **Similarity Metric**: To assess embedding similarity, you need a similarity metric such as cosine similarity, dot product, or Euclidean distance. Choosing the right similarity metric depends on your specific application.\n",
    "\n",
    "3. **Indexing**: When dealing with a large number of embeddings, comparing a query embedding to every stored embedding can be too slow. Vector databases employ indexing algorithms that group similar embeddings together. At query time, the query embedding is compared to a smaller subset of embeddings based on the index. This is called approximate nearest neighbor search, as the recommended embeddings aren't guaranteed to have the highest similarity to the query.\n",
    "\n",
    "4. **Metadata**: You can store metadata with each embedding to provide context and make query results more precise. Metadata can be filtered much like in a relational database. For example, you could store the publication year of a document as metadata and only search for similar documents published in a specific year.\n",
    "\n",
    "5. **Storage Location**: Vector databases can store embeddings and metadata both in memory and on disk. In-memory storage allows for faster reads and writes, while disk storage is important for data persistence.\n",
    "\n",
    "6. **CRUD Operations**: Most vector databases support create, read, update, and delete (CRUD) operations, allowing you to maintain and interact with data similar to a relational database.\n",
    "\n",
    "> While there is much more detail and complexity to explore with vector databases, these central concepts provide a solid foundation to get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ChromaDB](https://www.trychroma.com/): A Vector Database for Embeddings\n",
    "\n",
    "ChromaDB is a specialized vector database designed for storing and querying embeddings. Built upon SQLite, a renowned relational database, ChromaDB utilizes the SQLite engine to efficiently manage the storage and retrieval of embeddings. This system provides a straightforward and user-friendly interface for handling embeddings and querying similar vectors. Below are some key features and details about ChromaDB:\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Efficient Storage**: ChromaDB utilizes SQLite's sturdy storage mechanisms to store embeddings efficiently. This ensures that large volumes of data can be handled without significant performance degradation.\n",
    "\n",
    "- **Querying Capabilities**: The database is optimized for querying similar vectors, which is essential for tasks involving embeddings, such as nearest neighbor searches and similarity computations.\n",
    "\n",
    "- **User-Friendly Interface**: ChromaDB offers a simple and natural interface for managing embeddings, making it accessible for users with varying levels of database proficiency.\n",
    "\n",
    "\n",
    "### Running ChromaDB\n",
    "\n",
    "You can use ChromaDB in several ways:\n",
    "- Using a in-memory database, that will be lost when the program ends.\n",
    "- Using a file-based database, that will be persisted in a file.\n",
    "- Running as a server, that will allow you to query the database from other applications. For this, there are Docker images available.\n",
    "\n",
    "You can interact with ChromaDB using their Python library, their REST API or through LangChain, which has a built-in ChromaDB combination. For our class, we'll use a file-based database and LangChain to interact with ChromaDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building your RAG System with ChromaDB and LangChain\n",
    "\n",
    "We'll create a chatbot that has access to a knowledge base about UFRN. The chatbot will use a RAG system to retrieve information from the knowledge base and generate responses to user queries. We'll utilize ChromaDB to store and query embeddings of the knowledge base documents and LangChain to interact with ChromaDB and generate responses using a Large Language Model (LLM).\n",
    "\n",
    "For documents about UFRN, we'll use the following sources:\n",
    "- https://ufrn.br/imprensa/materias-especiais/80473/primeira-patente-da-ufrn-completa-uma-decada\n",
    "- https://ufrn.br/imprensa/materias-especiais/80657/design-de-aplicativo-na-escola\n",
    "- https://ufrn.br/imprensa/materias-especiais/80222/forro-na-ufrn-2\n",
    "- https://ufrn.br/imprensa/materias-especiais/79929/projeto-do-ceres-resgata-especies-nativas-da-caatinga\n",
    "- [Estatuto da UFRN](https://sigrh.ufrn.br/sigrh/public/colegiados/anexos/estatuto.pdf)\n",
    "- [Regulamento dos Cursos de Graduação](https://ufrn.br/resources/documentos/regulamentos/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf)\n",
    "- [Vídeo sobre o Restaurante Universitário](https://youtu.be/OHv-nx4ukZU?si=-uo5kd8OK_Zg7T9s)\n",
    "\n",
    "This way, we'll see how to use [LangChain Document Loaders](https://python.langchain.com/v0.2/docs/how_to/#document-loaders) to retrieve information from several types of sources and how to use ChromaDB to store and query embeddings of these documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Define our LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na Universidade Federal do Rio Grande do Norte (UFRN), o processo avaliativo pode ser organizado em até quatro avaliações, conforme as diretrizes estabelecidas pela instituição. Essas avaliações podem incluir provas, trabalhos, atividades práticas e outras formas de avaliação que o professor considerar adequadas para medir o aprendizado dos alunos. É sempre bom consultar o regulamento específico do curso ou as orientações do professor para detalhes mais precisos.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Load environment variables from a .env file into the environment\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the ChatOpenAI model with specific parameters\n",
    "# 'model' specifies the model to use, in this case 'gpt-4o-mini'\n",
    "# 'temperature' controls the randomness of the model's output, with 0 being deterministic\n",
    "model_openai = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Invoke the model with a specific prompt/question\n",
    "response = model_openai.invoke(\n",
    "    \"O processo avaliativo na UFRN pode ser organizado em até quantas avaliações?\"\n",
    ")\n",
    "\n",
    "# Print the content of the response from the model\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A resposta é 5.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the ChatOllama model with specific parameters\n",
    "\n",
    "model_llama = ChatOllama(\n",
    "    model=\"llama3.1\",  # 'model' specifies the model to use, in this case 'llama3.1'\n",
    "    temperature=0,  # 'temperature' controls the randomness of the model's output, with 0 being deterministic\n",
    "    base_url=\"http://localhost:11434\",  # 'base_url' specifies the base URL for the model's API endpoint\n",
    ")\n",
    "\n",
    "# Invoke the model with a specific prompt/question\n",
    "response = model_llama.invoke(\n",
    "    \"O processo avaliativo na UFRN pode ser organizado em até quantas avaliações?\"\n",
    ")\n",
    "\n",
    "# Print the content of the response from the model\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just wrong. According to article 100 of [this document](https://ufrn.br/resources/documentos/regulamentos/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf), the maximum number is 3.\n",
    "\n",
    ">> Art. 100. O processo avaliativo pode ser organizado em até 3 (três) unidades avaliativas\n",
    "\n",
    "OpenAI's model is very powerful, but doesn't really know the specifics of UFRN's regulations. That why it hallucinated a number that is not correct. We can use the LLM to generate the response, but we need to make sure the information is correct. This is one major advantage of using RAG systems.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Load the Documents\n",
    "\n",
    "To prepare the documents for use with ChromaDB, we need to follow these steps:\n",
    "\n",
    "- Downloading the Documents\n",
    "\n",
    "- Extracting Text from Documents\n",
    "\n",
    "- Splitting Text into Chunks\n",
    "- Determine an appropriate chunk size for your specific use case.\n",
    "- Consider factors like the desired granularity of information retrieval and the limitations of the basic storage system.\n",
    "- Carry Out a function to split the extracted text into smaller chunks based on the chosen chunk size.\n",
    "- Options include splitting by a fixed number of characters, sentences, or paragraphs.\n",
    "- Ensure that the chunks are meaningful and maintain coherence.\n",
    "- Store the resulting chunks in a list or any other suitable data structure.\n",
    "\n",
    "- Storing Chunks in ChromaDB\n",
    "- Initialize a connection to ChromaDB using the provided API or client library.\n",
    "- Create a new collection or database to store the text chunks.\n",
    "- Repeat over the list of text chunks and insert each chunk into ChromaDB.\n",
    "- Use appropriate methods provided by the ChromaDB library to insert the chunks efficiently.\n",
    "- Consider adding metadata or tags to each chunk if needed for better organization and retrieval.\n",
    "- Verify that the chunks are successfully stored in ChromaDB by querying the database.\n",
    "\n",
    "\n",
    "LangChain provides several [document loaders](https://python.langchain.com/v0.2/docs/integrations/document_loaders/) that can help you load data from various sources, such as URLs, files, and databases. You can use these loaders to extract text from different types of documents and prepare them for storage in ChromaDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Import PyPDFLoader from langchain_community.document_loaders to load and process PDF documents\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Initialize an empty list to store all documents\n",
    "all_documents = []\n",
    "\n",
    "\n",
    "# Function to download a PDF document from a given URL and save it with a specified filename\n",
    "def download_pdf(url, filename):\n",
    "    # Check if the file already exists to avoid re-downloading\n",
    "    if not os.path.exists(filename):\n",
    "        # Make a GET request to the URL to fetch the PDF content\n",
    "        r = requests.get(url)\n",
    "        # Open the file in write-binary mode and save the content\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "\n",
    "\n",
    "# Download the PDF document from the specified URL and save it to the 'data' directory\n",
    "download_pdf(\n",
    "    \"https://ufrn.br/resources/documentos/regulamentos/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf\",\n",
    "    \"data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf\",\n",
    ")\n",
    "\n",
    "# Initialize the PyPDFLoader with the path to the downloaded PDF document\n",
    "pdf_loader = PyPDFLoader(\"data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf\")\n",
    "\n",
    "# Load and split the PDF document into individual pages\n",
    "pages = pdf_loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='MINISTÉRIO DA EDUCAÇÃO \n",
      "UNIVERSIDADE FEDERAL DO RIO GRANDE DO NORTE \n",
      "                  \n",
      "       \n",
      " \n",
      "  \n",
      "RESOLUÇÃO Nº 016/2023-CONSEPE, de 04 de julho de 2023. \n",
      " \n",
      " \n",
      "Atualiza o Regulamento dos Cursos de Graduação da \n",
      "Universidade Federal do Rio Grande do Norte - UFRN. \n",
      " \n",
      " \n",
      "O VICE -REITOR DA UNIVERSIDADE FEDERAL DO RIO GRANDE DO NORTE faz saber que o \n",
      "Conselho de Ensino, Pesquisa e Extensão, no uso das atribuições que lhe confere o art. 17, Inciso III, do \n",
      "Estatuto da UFRN,  \n",
      " \n",
      "CONSIDERANDO o art. 207 da Constituição Federal ao d eterminar que as universidades gozam \n",
      "de autonomia didático -científica, administrativa e de gestão financeira e patrimonial, e obedecerão ao \n",
      "princípio de indissociabilidade entre ensino, pesquisa e extensão;  \n",
      " \n",
      "CONSIDERANDO a Lei nº 9.394/1996, que estabelec e as diretrizes e bases da educação \n",
      "nacional; \n",
      " \n",
      "CONSIDERANDO a necessidade de atualizar as normas relativas ao ensino de graduação, \n",
      "conforme determina o art. 359 da Resolução no 171/2013 - CONSEPE, de 5 de novembro de 2013, que \n",
      "aprovou o Regulamento dos Cursos Regulares de Graduação; e \n",
      " \n",
      "CONSIDERANDO o que consta no Processo nº 23077.066985/2023-42, \n",
      " \n",
      " \n",
      "RESOLVE: \n",
      " \n",
      "Art. 1º  Atualizar o Regulamento dos Cursos de Graduação da Universidade Federal do Rio \n",
      "Grande do Norte – UFRN. \n",
      " \n",
      "TÍTULO I \n",
      "DAS DISPOSIÇÕES PRELIMINARES \n",
      " \n",
      "Art. 2º Este Regulamento tem por finalidade normatizar o ensino de graduação da Universidade \n",
      "Federal do Rio Grande do Norte - UFRN. \n",
      " \n",
      "Parágrafo único.   Os cursos que não possuem oferta regular serão regidos, conforme suas \n",
      "especificidades, por este Regulamento e por legislação específica. \n",
      " \n",
      "TÍTULO II \n",
      "DA GESTÃO DAS ATIVIDADES ACADÊMICAS' metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2023-10-20T11:54:29-03:00', 'author': 'tamara', 'moddate': '2023-10-20T11:54:29-03:00', 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf', 'total_pages': 77, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "# Print the content of the first page of the PDF document\n",
    "# 'pages' is a list where each element represents a page of the PDF\n",
    "print(pages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents += pages\n",
    "pages = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Sumário\n",
      "TÍTULO I – DA INSTITUIÇÃO..............................................................5\n",
      "CAPÍTULO I – Da natureza jurídica..............................................5\n",
      "CAPÍTULO II – Dos princípios e dos objetivos........................... 6\n",
      "SEÇÃO I – Dos princípios....................................................... 6\n",
      "SEÇÃO II – Dos objetivos........................................................7\n",
      "CAPÍTULO III – Da constituição básica....................................... 9\n",
      "TÍTULO II – DA ADMINISTRAÇÃO UNIVERSITÁRIA....................14\n",
      "CAPÍTULO I – Dos Conselhos Superiores................................14\n",
      "SEÇÃO I – Do Conselho Universitário – CONSUNI......... 14\n",
      "SEÇÃO II – Da Assembleia Universitária........................... 17\n",
      "SEÇÃO III – Do Conselho de Ensino, Pesquisa e\n",
      "Extensão – CONSEPE....................................18\n",
      "SEÇÃO IV – Do Conselho de Administração –\n",
      "CONSAD.......................................................... 22\n",
      "SEÇÃO V – Do Conselho de Curadores– CONCURA...... 25\n",
      "CAPÍTULO II – Da Reitoria.......................................................... 28\n",
      "CAPÍTULO III – Da Administração Acadêmica.........................31\n",
      "SEÇÃO I – Dos Centros Acadêmicos................................. 32\n",
      "SEÇÃO II – Dos Conselhos de Centros\n",
      "Acadêmicos e de Unidades Acadêmicas\n",
      "Especializadas.................................................. 32' metadata={'producer': '', 'creator': 'WPS Writer', 'creationdate': '2019-08-27T11:29:45+14:29', 'author': 'Editora', 'comments': '', 'company': '', 'keywords': '', 'moddate': '2019-08-27T11:29:45+14:29', 'sourcemodified': \"D:20190827112945+14'29'\", 'subject': '', 'title': 'Estatuto UFRN.indd', 'trapped': 'False', 'source': 'data/estatuto.pdf', 'total_pages': 55, 'page': 2, 'page_label': '3'}\n"
     ]
    }
   ],
   "source": [
    "# Download the second PDF document from the specified URL and save it to the 'data' directory\n",
    "download_pdf(\n",
    "    \"https://sigrh.ufrn.br/sigrh/public/colegiados/anexos/estatuto.pdf\",\n",
    "    \"data/estatuto.pdf\",\n",
    ")\n",
    "\n",
    "# Initialize the PyPDFLoader with the path to the downloaded PDF document\n",
    "pdf_loader = PyPDFLoader(\"data/estatuto.pdf\")\n",
    "\n",
    "# Load and split the PDF document into individual pages\n",
    "pages = pdf_loader.load_and_split()\n",
    "\n",
    "# Print the content of the second page of the PDF document\n",
    "# 'pages' is a list where each element represents a page of the PDF\n",
    "print(pages[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents += pages\n",
    "pages = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading HTML from URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jacob/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Import the UnstructuredURLLoader class from the langchain_community.document_loaders module\n",
    "# This class is used to load and process content from URLs\n",
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "# Define a list of URLs to be loaded\n",
    "urls = [\n",
    "    \"https://portal.imd.ufrn.br/portal/noticias/7318/ufrn-associa-se-a-fiware-foundation-e-cria-ihub-em-cidades-inteligentes-no-imd\",\n",
    "    \"https://portal.imd.ufrn.br/portal/noticias/7338/equipes-ligadas-ao-imd-vencem-hackathon-inovar-2024\",\n",
    "    \"https://portal.imd.ufrn.br/portal/noticias/7319/projeto-do-imd-com-idosos-comemora-conclus%C3%A3o-da-primeira-turma\",\n",
    "]\n",
    "\n",
    "# Initialize the UnstructuredURLLoader with the list of URLs\n",
    "# This loader will fetch and process the content from the provided URLs\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "\n",
    "# Load the content from the URLs\n",
    "# 'pages' will be a list where each element contains the content of one URL\n",
    "pages = loader.load()\n",
    "\n",
    "# Note: For pages where the content is created dynamically (e.g., using JavaScript), there are other loaders that can be used with Selenium and PlayWright.\n",
    "# You can learn more about them on the Document Loaders Page of Langchain Community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Mais notícias\n",
      "\n",
      "UFRN associa-se a FIWARE Foundation e cria iHUB em Cidades Inteligentes no IMD\n",
      "\n",
      "UFRN associa-se a FIWARE Foundation e cria iHUB em Cidades Inteligentes no IMD\n",
      "\n",
      "Iniciativa visa tornar cidades brasileiras mais inteligentes, sustentáveis e integradas\n",
      "\n",
      "27-06-2024 / ASCOM\n",
      "\n",
      "Cidades Inteligentes Smart Metropolis\n",
      "\n",
      "\n",
      "\n",
      "Após assinar um associação com a Fundação FIWARE, organização internacional que promove o desenvolvimento de soluções inteligentes em todo o mundo, a Universidade Federal do Rio Grande do Norte (UFRN) prevê a criação de um novo espaço (iHUB) para desenvolvimento de pesquisas, estudantes e iniciativas na área de Cidades Inteligentes.\n",
      "\n",
      "Durante o Summit Cidades, evento nacional que aconteceu em Florianópolis (SC) na última terça-feira, 25, o Instituto Metrópole Digital (IMD/UFRN), representado pelo professor Frederico Lopes, oficializou o acordo, que marcou o início da criação do iHUB e de uma série de ações possibilitam a disseminação de tecnologias open-source, responsáveis por tornar as cidades brasileiras mais inteligentes, sustentáveis e integradas.\n",
      "\n",
      "\n",
      "\n",
      "O novo espaço será sediado no próprio IMD, com apoio do seu Parque Tecnológico Metrópole Digital (Metrópole Parque), e estará atrelado ao Smart Metrópolis – laboratório do IMD especializado em Cidades Inteligentes – o qual também dá nome ao espaço: Smart Metrópolis iHUB FIWARE.\n",
      "\n",
      "1ª do Brasil\n",
      "\n",
      "O acordo, assinado pelo reitor da UFRN, professor Daniel Diniz Melo, classifica a Universidade como a primeira do Brasil a contar com um iHUB Fiware. Essa iniciativa existe em diferentes países ao redor do mundo, empenhados com o surgimento de soluções inteligentes para tornar cidades integradas e mais funcionais para seus moradores.\n",
      "\n",
      "Localizado na sala B424 do IMD, o novo iHUB ofertará uma série de serviços, como treinamentos para prefeituras e empresas na área de Cidades Inteligentes, além de análise de dados e auxílio em tomadas de decisões no campo das políticas públicas.\n",
      "\n",
      "Também nesse ambiente, com articulação de professores e alunos de graduação e pós-graduação, serão conduzidas turmas de nível superior sobre Cidades Inteligentes e uso da tecnologia FIWARE.\n",
      "\n",
      "“Nossa proposta é contemplar projetos de pesquisa, desenvolvimento e inovação com a plataforma FIWARE, envolvendo tecnologias como Internet das Coisas, Inteligência Artificial, blockchain, computação em nuvem, dados abertos, engenharia de software, entre outras áreas”, comenta Frederico Lopes.\n",
      "\n",
      "Outras Notícias\n",
      "\n",
      "\n",
      "\n",
      "IMD celebra colação de grau de 79 novos profissionais de TI\n",
      "\n",
      "Evento de formatura aconteceu na noite dessa terça-feira, no Ginásio Poliesportivo da UFRN\n",
      "\n",
      "\n",
      "\n",
      "IMD faz seleção com 10 vagas para bolsistas de graduação e pesquisadores\n",
      "\n",
      "Bolsas são de até R$ 4 mil e inscrições seguem abertas até o dia 23 de março' metadata={'source': 'https://portal.imd.ufrn.br/portal/noticias/7318/ufrn-associa-se-a-fiware-foundation-e-cria-ihub-em-cidades-inteligentes-no-imd'}\n"
     ]
    }
   ],
   "source": [
    "print(pages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents += pages\n",
    "pages = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Arbitrary Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbitrary_text = \"\"\"\n",
    "Fortalecer a atuação do Poder Judiciário na proteção do meio ambiente com uso de Inteligência Artificial (IA): esse é um dos objetivos de projeto realizado pelo Programa das Nações Unidas para o Desenvolvimento (Pnud), o Conselho Nacional de Justiça (CNJ) e a Universidade Federal do Rio Grande do Norte (UFRN). A iniciativa utilizará IA e técnicas da ciência de dados para extrair informações úteis dos textos processuais, a fim de realizar análises e previsões em ações judiciais do assunto Direito Ambiental.  \n",
    "\n",
    "Segundo explica Rafael Leite, juiz auxiliar da Presidência do CNJ, o projeto visa usar IA, técnicas de processamento de linguagem natural e análise dos dados do processo e do conteúdo textual de suas peças para obter informações sobre a atuação do Judiciário na área do meio ambiente. “A IA é importante ferramenta para dar suporte à atuação dos magistrados e aumentar a efetividade da jurisdição – por exemplo, identificando padrões de conduta, impacto em biomas específicos e efeitos cumulativos de determinadas atividades –, além de melhor orientar ações de fiscalização de combate ao desmatamento ilegal e outros crimes ambientais”, afirma o magistrado.  \n",
    "\n",
    "O CNJ já realiza acompanhamento de ações judiciais nos assuntos de Direito Ambiental por meio do Painel Interativo SireneJud, que reúne informações, por exemplo, sobre Terras Indígenas e áreas de desmatamento. O painel consome dados de diferentes fontes, como o DataJud – Base Nacional de Dados do Poder Judiciário, o Instituto Nacional de Pesquisas Espaciais (Inpe) e o Instituto Brasileiro de Geografia e Estatística (IBGE). \n",
    "\n",
    "A UFRN irá colocar à disposição do SireneJud as APIs (Application Programming Interfaces) desenvolvidas de modo a agregar novas informações ao painel interativo. As APIs permitem que os sistemas se comuniquem e os dados sejam integrados. \n",
    "\n",
    "Arquitetura\n",
    "No projeto, a arquitetura definida para desenvolver as soluções insere-se na linguística computacional, que usa redes neurais e outros métodos para “extrair sentido de texto”, explica Elias Jacob, professor da UFRN. “A IA nada mais é do que uma representação do mundo a partir dos dados que foram passados para ela. O que ela faz? Detecta padrões”, descreve Jacob. \n",
    "\n",
    "A Plataforma Codex proverá o conjunto de dados que serão utilizados pelos analistas e desenvolvedores na construção dos modelos de IA e demais soluções. “O Codex importa as informações dos diversos sistemas processuais eletrônicos utilizados pelos tribunais. Ele extrai tanto os metadados do processo, como número e nome das partes, quanto o teor dos textos que estão lá”, explica o professor. \n",
    "\n",
    "De acordo com o Painel de Monitoramento de Implantação do Codex, o sistema tem extraído informações de 141 fontes de dados vinculadas a sistemas processuais dos tribunais brasileiros. “Todo o projeto tem a função de detectar padrões para extrair informação – que antes era inacessível – para que o humano possa tomar as decisões necessárias”, diz Jacob.  \n",
    "\n",
    "Uso de IA no Poder Judiciário\n",
    "Elias Jacob também propõe desmistificar a ideia de que modelos de IA promoveriam uma espécie de robotização do trabalho de juízes e juízas. “O que precisa ficar claro é que são ferramentas que nos ajudam a fazer algo, e não que vieram substituir o trabalho humano”, diz. \n",
    "\n",
    "Ele ressalta que a demanda social pelo serviço prestado pela jurisdição é elevada e, mesmo com a digitalização do processo judicial e a alta produtividade de magistrados e servidores, o Poder Judiciário enfrenta problemas de congestionamento processual. Nesse sentido, a IA é um caminho: “no Brasil, um juiz julga mais de 9 mil processos por ano. Existem várias formas de melhorar o atendimento dessa demanda. Uma delas é o desenvolvimento de ferramentas de IA”. \n",
    "\n",
    "O projeto com a UFRN é realizado no âmbito do Programa Justiça 4.0. A iniciativa busca fortalecer a atuação do Judiciário na tutela do meio ambiente, considerando que a Justiça brasileira dispõe de um conjunto de informações e dados relevantes sobre conflitos e crimes ambientais, explica Jacob. “Os problemas da sociedade recaem no Judiciário, que, em tese, é a melhor fonte de conhecimento sobre os problemas que assolam o país; na questão ambiental, não seria diferente”, argumenta o professor. \n",
    "\n",
    "Conheça os produtos previstos na parceria entre CNJ, PNUD e UFRN:\n",
    "Solução de IA capaz de recomendar aos magistrados precedentes na área ambiental, buscando situações similares e permitindo maior uniformização dos julgamentos; \n",
    "Dados tratados contendo o recorte de causas ambientais que já tramitaram no Brasil;  \n",
    "Ferramenta para identificar os maiores réus em causas ambientais e poluidores em geral a partir de dados retirados da Base Nacional de Dados do Poder Judiciário (DataJud);   \n",
    "Solução de IA capaz de ler textos jurídicos e identificar elementos importantes, como o tipo de crime cometido, o dano causado, o bioma envolvido, o valor da condenação e o uso da legislação nacional e internacional; e\n",
    "Solução de IA para prever os resultados de processos judiciais na área ambiental. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'title': 'IA e ciência de dados vão auxiliar o Judiciário na proteção do meio ambiente', 'author': 'Conselho Nacional de Justiça', 'source': 'https://www.cnj.jus.br/ia-e-ciencia-de-dados-vao-auxiliar-o-judiciario-na-protecao-do-meio-ambiente/'}, page_content='\\nFortalecer a atuação do Poder Judiciário na proteção do meio ambiente com uso de Inteligência Artificial (IA): esse é um dos objetivos de projeto realizado pelo Programa das Nações Unidas para o Desenvolvimento (Pnud), o Conselho Nacional de Justiça (CNJ) e a Universidade Federal do Rio Grande do Norte (UFRN). A iniciativa utilizará IA e técnicas da ciência de dados para extrair informações úteis dos textos processuais, a fim de realizar análises e previsões em ações judiciais do assunto Direito Ambiental.  \\n\\nSegundo explica Rafael Leite, juiz auxiliar da Presidência do CNJ, o projeto visa usar IA, técnicas de processamento de linguagem natural e análise dos dados do processo e do conteúdo textual de suas peças para obter informações sobre a atuação do Judiciário na área do meio ambiente. “A IA é importante ferramenta para dar suporte à atuação dos magistrados e aumentar a efetividade da jurisdição – por exemplo, identificando padrões de conduta, impacto em biomas específicos e efeitos cumulativos de determinadas atividades –, além de melhor orientar ações de fiscalização de combate ao desmatamento ilegal e outros crimes ambientais”, afirma o magistrado.  \\n\\nO CNJ já realiza acompanhamento de ações judiciais nos assuntos de Direito Ambiental por meio do Painel Interativo SireneJud, que reúne informações, por exemplo, sobre Terras Indígenas e áreas de desmatamento. O painel consome dados de diferentes fontes, como o DataJud – Base Nacional de Dados do Poder Judiciário, o Instituto Nacional de Pesquisas Espaciais (Inpe) e o Instituto Brasileiro de Geografia e Estatística (IBGE). \\n\\nA UFRN irá colocar à disposição do SireneJud as APIs (Application Programming Interfaces) desenvolvidas de modo a agregar novas informações ao painel interativo. As APIs permitem que os sistemas se comuniquem e os dados sejam integrados. \\n\\nArquitetura\\nNo projeto, a arquitetura definida para desenvolver as soluções insere-se na linguística computacional, que usa redes neurais e outros métodos para “extrair sentido de texto”, explica Elias Jacob, professor da UFRN. “A IA nada mais é do que uma representação do mundo a partir dos dados que foram passados para ela. O que ela faz? Detecta padrões”, descreve Jacob. \\n\\nA Plataforma Codex proverá o conjunto de dados que serão utilizados pelos analistas e desenvolvedores na construção dos modelos de IA e demais soluções. “O Codex importa as informações dos diversos sistemas processuais eletrônicos utilizados pelos tribunais. Ele extrai tanto os metadados do processo, como número e nome das partes, quanto o teor dos textos que estão lá”, explica o professor. \\n\\nDe acordo com o Painel de Monitoramento de Implantação do Codex, o sistema tem extraído informações de 141 fontes de dados vinculadas a sistemas processuais dos tribunais brasileiros. “Todo o projeto tem a função de detectar padrões para extrair informação – que antes era inacessível – para que o humano possa tomar as decisões necessárias”, diz Jacob.  \\n\\nUso de IA no Poder Judiciário\\nElias Jacob também propõe desmistificar a ideia de que modelos de IA promoveriam uma espécie de robotização do trabalho de juízes e juízas. “O que precisa ficar claro é que são ferramentas que nos ajudam a fazer algo, e não que vieram substituir o trabalho humano”, diz. \\n\\nEle ressalta que a demanda social pelo serviço prestado pela jurisdição é elevada e, mesmo com a digitalização do processo judicial e a alta produtividade de magistrados e servidores, o Poder Judiciário enfrenta problemas de congestionamento processual. Nesse sentido, a IA é um caminho: “no Brasil, um juiz julga mais de 9 mil processos por ano. Existem várias formas de melhorar o atendimento dessa demanda. Uma delas é o desenvolvimento de ferramentas de IA”. \\n\\nO projeto com a UFRN é realizado no âmbito do Programa Justiça 4.0. A iniciativa busca fortalecer a atuação do Judiciário na tutela do meio ambiente, considerando que a Justiça brasileira dispõe de um conjunto de informações e dados relevantes sobre conflitos e crimes ambientais, explica Jacob. “Os problemas da sociedade recaem no Judiciário, que, em tese, é a melhor fonte de conhecimento sobre os problemas que assolam o país; na questão ambiental, não seria diferente”, argumenta o professor. \\n\\nConheça os produtos previstos na parceria entre CNJ, PNUD e UFRN:\\nSolução de IA capaz de recomendar aos magistrados precedentes na área ambiental, buscando situações similares e permitindo maior uniformização dos julgamentos; \\nDados tratados contendo o recorte de causas ambientais que já tramitaram no Brasil;  \\nFerramenta para identificar os maiores réus em causas ambientais e poluidores em geral a partir de dados retirados da Base Nacional de Dados do Poder Judiciário (DataJud);   \\nSolução de IA capaz de ler textos jurídicos e identificar elementos importantes, como o tipo de crime cometido, o dano causado, o bioma envolvido, o valor da condenação e o uso da legislação nacional e internacional; e\\nSolução de IA para prever os resultados de processos judiciais na área ambiental. \\n')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Document class from the langchain_core.documents module\n",
    "# This class is used to create and manage document objects\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Create a Document object with specified content and metadata\n",
    "# 'page_content' is the main content of the document, which is stored in the variable 'arbitrary_text'\n",
    "# 'metadata' is a dictionary containing additional information about the document\n",
    "# 'title' specifies the title of the document\n",
    "# 'author' specifies the author of the document\n",
    "# 'source' specifies the source URL of the document\n",
    "doc = Document(\n",
    "    page_content=arbitrary_text,\n",
    "    metadata={\n",
    "        \"title\": \"IA e ciência de dados vão auxiliar o Judiciário na proteção do meio ambiente\",\n",
    "        \"author\": \"Conselho Nacional de Justiça\",\n",
    "        \"source\": \"https://www.cnj.jus.br/ia-e-ciencia-de-dados-vao-auxiliar-o-judiciario-na-protecao-do-meio-ambiente/\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Display the Document object\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Breaking Down the Text into Manageable Segments\n",
    "\n",
    "When working with dense, information-rich texts, it's crucial to divide them into smaller, more manageable segments for efficient storage and retrieval. This process, known as **chunking**, breaks the information into smaller pieces, making it easier to store and more meaningful. Chunking enables more relevant information retrieval in response to specific queries and reduces costs by including only a portion of a document in the LLM prompt instead of the entire document.\n",
    "\n",
    "### Chunking Strategies\n",
    "\n",
    "The following chunking techniques typically use two main parameters:\n",
    "\n",
    "- **chunk_size**: Determines the size of each text segment.\n",
    "- **chunk_overlap**: Controls how much text overlaps between one segment and the next.\n",
    "\n",
    "#### Character Chunking\n",
    "\n",
    "Character Chunking is the simplest strategy, dividing the text into segments based on a fixed number of characters. While straightforward, this method can sometimes disrupt the flow of text by breaking sentences or words unexpectedly. Despite its limitations, it serves as a good starting point for more advanced methods.\n",
    "\n",
    "#### Recursive Character Chunking\n",
    "\n",
    "Recursive Character Chunking builds on the basic concept of Character Chunking by dividing the text into segments until a specific condition, such as a minimum chunk size, is met. This method ensures that the chunking process aligns with the text's structure, preserving more meaning. Its adaptability makes it suitable for texts with varied structures.\n",
    "\n",
    "#### Document Specific Chunking\n",
    "\n",
    "Document Specific Chunking respects the document's innate structure by creating segments that align with the logical sections of the document, such as paragraphs or subsections, instead of using a fixed number of characters or a recursive process. This approach maintains the original organization of the content, making the retrieved information more relevant and useful, especially for structured documents with clearly defined sections.\n",
    "\n",
    "#### Token-based Chunking\n",
    "\n",
    "When dividing your text into segments, it's advisable to count the number of tokens to ensure compliance with the token limit of the language model being used. To ensure accuracy, use the same tokenizer for counting tokens as the one used in the language model.\n",
    "\n",
    "#### Semantic Chunking\n",
    "\n",
    "Semantic Chunking considers the relationships within the text, dividing it into meaningful, semantically complete segments. This approach ensures the integrity of the information during retrieval, leading to more accurate and contextually appropriate outcomes. The process involves:\n",
    "\n",
    "1. Taking the embeddings of every sentence in the document.\n",
    "2. Comparing the similarity of all sentences with each other.\n",
    "3. Grouping sentences with the most similar embeddings together.\n",
    "\n",
    "By focusing on the text's meaning and context, Semantic Chunking significantly enhances the quality of retrieval. It's an excellent choice when maintaining the semantic integrity of the text is crucial. However, this method requires more effort and is slower than the previous ones.\n",
    "\n",
    "#### Agent Chunking\n",
    "\n",
    "Agent Chunking mimics how humans might process a new document:\n",
    "\n",
    "1. Start at the top of the document, treating the first part as a segment.\n",
    "2. Continue down the document, deciding if a new sentence or piece of information belongs with the first segment or should start a new one.\n",
    "3. Repeat this process until reaching the end of the document.\n",
    "\n",
    "### Choosing the Right Chunking Strategy\n",
    "\n",
    "Each chunking strategy has its strengths and weaknesses, and the choice of method depends on the specific requirements of the text and the intended use. Consider the following factors when selecting a chunking strategy:\n",
    "\n",
    "- **Text structure**: For well-structured documents with clearly defined sections, Document Specific Chunking may be the most appropriate choice.\n",
    "- **Semantic integrity**: If maintaining the semantic integrity of the text is crucial, Semantic Chunking is the best option, despite being more time-consuming and effort-intensive.\n",
    "- **Simplicity**: Character Chunking and Recursive Character Chunking are straightforward and easy to carry out, making them suitable for quick experimentation or when the text structure is less important.\n",
    "- **Language model compatibility**: Token-based Chunking ensures compliance with the token limit of the language model being used, making it a reliable choice when working with LLMs.\n",
    "\n",
    "\n",
    "### Applying Token-based Chunking for Our Class\n",
    "\n",
    "For our class, we'll use a simple, token-based chunking strategy to divide the text into manageable segments. This approach ensures that the generated responses are concise and aligned with the token limits of the language model. Because different language models have varying token limits and tokenization methods, it's essential to consider these factors when designing your chunking strategy.\n",
    "\n",
    "### Comparing Embedding Models and Adjusting Chunk Size\n",
    "\n",
    "Later, we'll purposely use two different strategies to generate the embeddings for the documents:\n",
    "\n",
    "1. Using a Sentence Transformer to generate the embeddings.\n",
    "2. Using OpenAI embedding models.\n",
    "\n",
    "This will allow us to compare the results and see how different embedding models can impact the performance of the RAG system. However, there's a difference between the two strategies that we'll need to address:\n",
    "\n",
    "> Our Sentence-Transformer has a 512 token limit, while OpenAI's model has an 8192 token limit.\n",
    "\n",
    "This means that we'll need to adjust the chunk size for the OpenAI embeddings to make sure they fit within the token limit. This is a common challenge when working with different embedding models and language models, and it's essential to consider these limitations during the design of your RAG system. Note that, because they are two different models, the tokens generated by each model may not be directly comparable.\n",
    "\n",
    "Let's dive into [LangChain Text Splitters](https://python.langchain.com/v0.2/docs/concepts/#text-splitters) to see how we can apply token-based chunking for our class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RecursiveCharacterTextSplitter class from langchain_text_splitters\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Import the AutoTokenizer class from transformers\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load a pre-trained Hugging Face tokenizer from the specified path\n",
    "hf_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"outputs/sentence_transformers/sentence-transformer\"\n",
    ")\n",
    "\n",
    "# Create a RecursiveCharacterTextSplitter instance using OpenAI's tiktoken encoder\n",
    "splitter_openai = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",  # Specify the encoding name\n",
    "    chunk_size=8191,  # Define the maximum size of each chunk\n",
    "    chunk_overlap=0,  # Define the overlap between chunks\n",
    "    separators=[\n",
    "        \"\\n\\n\",\n",
    "        \"\\n\",\n",
    "        \".\",\n",
    "        \",\",\n",
    "        \" \",\n",
    "        \"\",\n",
    "    ],  # Define the separators to use for splitting\n",
    ")\n",
    "\n",
    "# Create a RecursiveCharacterTextSplitter instance using the Hugging Face tokenizer\n",
    "splitter_sentence_transformers = (\n",
    "    RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "        tokenizer=hf_tokenizer,  # Pass the loaded Hugging Face tokenizer\n",
    "        chunk_size=512,  # Define the maximum size of each chunk\n",
    "        chunk_overlap=0,  # Define the overlap between chunks\n",
    "        separators=[\n",
    "            \"\\n\\n\",\n",
    "            \"\\n\",\n",
    "            \".\",\n",
    "            \",\",\n",
    "            \" \",\n",
    "            \"\",\n",
    "        ],  # Define the separators to use for splitting\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splitter_sentence_transformers.split_text(arbitrary_text)), len(\n",
    "    splitter_openai.split_text(arbitrary_text)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "chunked_documents_openai = splitter_openai.split_documents(all_documents)\n",
    "chunked_documents_sentence_transformers = (\n",
    "    splitter_sentence_transformers.split_documents(all_documents)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 219)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunked_documents_openai), len(chunked_documents_sentence_transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Storing Chunks in ChromaDB\n",
    "\n",
    "After splitting the text into manageable segments, the next step is to store these chunks in ChromaDB for efficient retrieval during the RAG (Retrieval-Augmented Generation) process. ChromaDB is a powerful database designed for storing and querying vector embeddings, making it an ideal choice for this task. Let's dive into the details of storing chunks in ChromaDB.\n",
    "\n",
    "### Establishing a Connection\n",
    "\n",
    "To interact with ChromaDB, you first need to establish a connection to your ChromaDB instance. This is typically done using the provided API or client library specific to your programming language. It's essential to ensure that you have the necessary credentials and permissions to access the database securely. Proper authentication and authorization mechanisms should be in place to protect your data and maintain the integrity of your ChromaDB instance.\n",
    "\n",
    "### Creating a Collection\n",
    "\n",
    "Once you have successfully connected to ChromaDB, the next step is to create a collection or database to store your text chunks. Collections serve as logical containers for organizing and grouping related data. By creating a dedicated collection for your text chunks, you can easily manage and query them later. When naming your collection, choose a meaningful and descriptive name that reflects the nature of the data it holds. This will make it easier to identify and work with the collection throughout your RAG process.\n",
    "\n",
    "### Inserting Chunks into ChromaDB\n",
    "\n",
    "With the collection created, you can now proceed to insert the text chunks into ChromaDB. This involves iterating over the list of chunks and using the appropriate methods provided by the ChromaDB library to store each chunk efficiently. During the insertion process, consider adding metadata or tags to each chunk. Metadata can include relevant information such as the source of the text, the date of creation, or specific keywords associated with the chunk. By attaching metadata, you enhance the organizational structure and enable more targeted queries and analysis later on.\n",
    "\n",
    "### Verifying Data Insertion\n",
    "\n",
    "After inserting the chunks into ChromaDB, it's crucial to verify that the data has been successfully stored. You can accomplish this by running test queries against the database and examining the results. Perform queries that retrieve specific chunks based on their content or metadata to ensure that the data is accessible and matches your expectations. This verification step helps confirm the integrity and reliability of your stored data, giving you confidence in the subsequent stages of your RAG process.\n",
    "\n",
    "> **Important Note:**\n",
    "> When working with embeddings, it's vital to [remember this](https://www.youtube.com/watch?v=ulD7IsecPbU). So, keep in mind that embeddings are only comparable within the same model. If you use different models to generate embeddings for your text chunks and queries, the embeddings will not be directly comparable. To ensure compatibility and accurate retrieval, make sure to use the same embedding model consistently throughout your RAG system. This includes embedding the user queries using the same model that was used to embed the documents stored in ChromaDB.\n",
    "\n",
    "\n",
    "> We will save local files with ChromaDb, but you can also use the Chroma in [Client/Server Mode](https://docs.trychroma.com/guides#running-chroma-in-client/server-mode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you have installed the necessary packages:\n",
    "# pip install langchain_chroma chromadb langchain-huggingface\n",
    "\n",
    "# Import the Chroma class from the langchain_chroma module\n",
    "# This class is used for managing and querying embeddings with Chroma\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Import the HuggingFaceEmbeddings class from the langchain_huggingface module\n",
    "# This class is used to generate embeddings using Hugging Face models\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Import the OpenAIEmbeddings class from the langchain_openai module\n",
    "# This class is used to generate embeddings using OpenAI models\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Initialize the HuggingFaceEmbeddings with a specified model\n",
    "# 'model_name' specifies the path to the pre-trained Sentence Transformers model\n",
    "# 'show_progress=True' enables the display of progress during embedding generation\n",
    "# 'model_kwargs' is a dictionary of additional arguments for the model, here specifying to use the CPU\n",
    "embedding_function_sentence_transformers = HuggingFaceEmbeddings(\n",
    "    model_name=\"outputs/sentence_transformers/sentence-transformer\",\n",
    "    show_progress=True,\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f006eaf07b740bcac98fac6bc16f838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a ChromaDB instance and save it to a specified directory\n",
    "# 'db_sentence_transformers' will store the ChromaDB instance created from the documents and embeddings\n",
    "\n",
    "# Initialize the ChromaDB instance using the 'from_documents' method\n",
    "# 'documents' is a list of chunked documents that will be stored in the database\n",
    "# 'embedding' is the embedding function used to generate embeddings for the documents\n",
    "# 'persist_directory' specifies the directory where the ChromaDB instance will be saved\n",
    "db_sentence_transformers = Chroma.from_documents(\n",
    "    documents=chunked_documents_sentence_transformers,\n",
    "    embedding=embedding_function_sentence_transformers,\n",
    "    persist_directory=\"/tmp/chroma_db_sentence_transformer\",\n",
    ")\n",
    "\n",
    "# The ChromaDB instance 'db_sentence_transformers' is now created and saved to '/tmp/chroma_db_sentence_transformer'\n",
    "# This instance can be used for querying and managing document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAIEmbeddings with a specified model\n",
    "# 'model' specifies the OpenAI model to be used for generating embeddings\n",
    "embedding_function_openai = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Create a ChromaDB instance using the OpenAI embeddings and save it to a specified directory\n",
    "# 'db_openai' will store the ChromaDB instance created from the documents and embeddings\n",
    "\n",
    "# Initialize the ChromaDB instance using the 'from_documents' method\n",
    "# 'documents' is a list of chunked documents that will be stored in the database\n",
    "# 'embedding' is the embedding function used to generate embeddings for the documents\n",
    "# 'persist_directory' specifies the directory where the ChromaDB instance will be saved\n",
    "db_openai = Chroma.from_documents(\n",
    "    documents=chunked_documents_openai,\n",
    "    embedding=embedding_function_openai,\n",
    "    persist_directory=\"/tmp/chroma_db_openai\",\n",
    ")\n",
    "\n",
    "# The ChromaDB instance 'db_openai' is now created and saved to '/tmp/chroma_db_openai'\n",
    "# This instance can be used for querying and managing document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can reload the ChromaDB instances from the saved files at any time by specifying the persist_directory\n",
    "\n",
    "# Reload the ChromaDB instance for Sentence Transformers embeddings\n",
    "# 'persist_directory' specifies the directory where the ChromaDB instance was previously saved\n",
    "# 'embedding_function' specifies the embedding function used to generate embeddings for the documents\n",
    "db_sentence_transformers = Chroma(\n",
    "    persist_directory=\"/tmp/chroma_db_sentence_transformer\",\n",
    "    embedding_function=embedding_function_sentence_transformers,\n",
    ")\n",
    "\n",
    "# Reload the ChromaDB instance for OpenAI embeddings\n",
    "# 'persist_directory' specifies the directory where the ChromaDB instance was previously saved\n",
    "# 'embedding_function' specifies the embedding function used to generate embeddings for the documents\n",
    "db_openai = Chroma(\n",
    "    persist_directory=\"/tmp/chroma_db_openai\",\n",
    "    embedding_function=embedding_function_openai,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af0a9b42ed643599e3daf0bf11d39c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the query string to search for relevant documents\n",
    "query = \"O processo avaliativo na UFRN pode ser organizado em até quantas avaliações?\"\n",
    "\n",
    "# Perform a similarity search using the ChromaDB instance with Sentence Transformers embeddings\n",
    "# 'docs1' will store the documents that are most similar to the query based on Sentence Transformers embeddings\n",
    "docs1 = db_sentence_transformers.similarity_search(query)\n",
    "\n",
    "# Perform a similarity search using the ChromaDB instance with OpenAI embeddings\n",
    "# 'docs2' will store the documents that are most similar to the query based on OpenAI embeddings\n",
    "docs2 = db_openai.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='24972478-c695-462d-8000-ec3fd5886848', metadata={'author': 'tamara', 'creationdate': '2023-10-20T11:54:29-03:00', 'creator': 'Microsoft® Office Word 2007', 'moddate': '2023-10-20T11:54:29-03:00', 'page': 24, 'page_label': '25', 'producer': 'Microsoft® Office Word 2007', 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf', 'total_pages': 77}, page_content='das unidades, é obrigatória a realização de uma avaliação escrita, individual e presencial.  \\n \\n§4º  A unidade de vinculação do componen te curricular poderá, excepcionalmente, dispensar a \\nobrigatoriedade estabelecida no §3º  deste artigo. \\n \\nArt. 101.  O rendimento acadêmico de cada unidade avaliativa é calculado a partir dos \\nresultados obtidos nos instrumentos avaliativos utilizados na unidade. \\n \\nParágrafo único.  A quantidade de instrumentos avaliativos por unidade é definida previamente \\npelo docente e divulgada no plano de ensino da turma. \\n \\nArt. 102.   O rendimento acadêmico parcial (média parcial) é calculado pela média aritmética \\ndos rendimentos acadêmicos obtidos em cada unidade avaliativa. \\n \\nParágrafo único.  Em cada unidade avaliativa, o estudante deve atender o critério de'), Document(id='08e7b972-2d65-4a9f-a624-fab9c544dff5', metadata={'author': 'tamara', 'creationdate': '2023-10-20T11:54:29-03:00', 'creator': 'Microsoft® Office Word 2007', 'moddate': '2023-10-20T11:54:29-03:00', 'page': 11, 'page_label': '12', 'producer': 'Microsoft® Office Word 2007', 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf', 'total_pages': 77}, page_content='momentos presenciais destinados a avaliações da aprendizagem e atividades práticas de ensino , que \\ndevem ser realizadas no polo de apoio presencial ou no campus de funcionamento do curso.  \\n \\nArt. 44.  Ementa é a descrição sumária do conteúdo a ser desenvolvido no componente \\ncurricular, podendo ser alterada, desde que aprovada em órgão colegiado da unidade acadêmica ao \\nqual o componente curricular está vinculado. \\n \\nParágrafo único.  As alterações nas ementas são registradas, no sistema de gestão acadêmica, \\npela PROGRAD e apensadas ao Projeto Pedagógico de Curso. \\n \\nArt. 45.  Os componentes curriculares podem ser do tipo: \\n \\nI - disciplina; \\n \\nII - bloco; ou'), Document(id='84ee6725-9df5-4388-ac9a-03d2d47438a8', metadata={'author': 'tamara', 'creationdate': '2023-10-20T11:54:29-03:00', 'creator': 'Microsoft® Office Word 2007', 'moddate': '2023-10-20T11:54:29-03:00', 'page': 43, 'page_label': '44', 'producer': 'Microsoft® Office Word 2007', 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf', 'total_pages': 77}, page_content='e o valor acrescentado ao perfil inicial é descontado do prazo máximo para conclusão do curso. \\n \\nCAPÍTULO III \\nDA CRIAÇÃO DE TURMAS \\n \\nArt. 195.   No prazo estabelecido no Calendário Universitário, as coordenações de curso devem \\nsolicitar às unidades acadêmicas de vinculação dos componentes curriculares a criação das turmas para \\no período letivo regular subsequente, indicando a mo dalidade de oferta da turma, o horário pretendido \\ne o número de vagas desejado para cada turno e ênfase ou habilitação. \\n \\n§1º  A solicitação de turmas ocorre por meio do sistema de gestão acadêmica.'), Document(id='b2931d36-0bd0-4def-8de5-b32e51282e37', metadata={'author': 'tamara', 'creationdate': '2023-10-20T11:54:29-03:00', 'creator': 'Microsoft® Office Word 2007', 'moddate': '2023-10-20T11:54:29-03:00', 'page': 23, 'page_label': '24', 'producer': 'Microsoft® Office Word 2007', 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf', 'total_pages': 77}, page_content='estudante, bem como a análise dos registros produzidos ao longo do processo para fins de atribuição do \\nrendimento acadêmico. \\n \\nParágrafo único.  De modo complementar, os resultados do processo de avaliação devem \\nsubsidiar a reflexão e, caso necessário, o redimensionamento da prática pedagógica docente. \\n \\nArt. 97.   A avaliação da aprendizagem deve verificar a apropriação dos conhecimentos por \\nparte dos estudantes, considerando os objetivos, conteúdos propostos no programa do componente \\ncurricular e o perfil do egresso estabelecido pelas Diretrizes Curriculares Nacionais e Projeto Pedagógico \\nde Curso.')]\n"
     ]
    }
   ],
   "source": [
    "print(docs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='bbb09d51-066b-4195-9d8b-7d039e1ebbd2', metadata={'author': 'tamara', 'creationdate': '2023-10-20T11:54:29-03:00', 'creator': 'Microsoft® Office Word 2007', 'moddate': '2023-10-20T11:54:29-03:00', 'page': 23, 'page_label': '24', 'producer': 'Microsoft® Office Word 2007', 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf', 'total_pages': 77}, page_content='datas relativas a procedimentos regulares previstos neste regulamento. \\n \\nArt. 94.   Os cursos de graduação se desenvolvem anualmente em dois períodos letivos \\nregulares estabelecidos no Calendário Universitário. \\n \\n§1º  Os períodos letivos regulares têm duração de, no mínimo, 18 (dezoito) semanas de aulas. \\n \\n§2º  Adicionalmente, a critério da instituição, pode ser realizado período letivo especial de \\nférias. \\n \\n§3º  O período letivo especial de férias deve ter duração mínima de 4 (quatro) semanas. \\n \\nArt. 95.  As aulas presenciais semanais da UFRN são ministradas: \\n \\nI - de segunda-feira a sábado, conforme o Calendário Universitário; \\n \\nII - em três turnos diários: matutino, vespertino e noturno; \\n \\nIII -  com duração de 50 (cinquenta) minutos de atividades; e \\n \\nIV - conforme distribuição semanal dos horários  de aulas apresentada no Anexo I deste \\nRegulamento. \\n \\n§1º  Deve ser ministrada a quantidade de aulas necessária para o cumprimento total da carga \\nhorária dos componentes curriculares no período letivo. \\n \\n§2º  Quando necessário o docente deverá ministrar aula  de reposição para cumprir o que \\nestabelece o §1º  deste artigo. \\n \\n§3º  As unidades de ensino do interior do estado podem estabelecer horários noturnos \\ndistintos dos definidos no Anexo I deste Regulamento, sem prejuízo de atendimento aos incisos I, II e III  \\ndeste artigo, mediante aprovação da Câmara de Graduação.  \\n \\nTÍTULO VI \\nDA AVALIAÇÃO DE APRENDIZAGEM \\n \\nArt. 96.   A avaliação da aprendizagem, processo mediado pelo docente, compreende o \\ndiagnóstico e o acompanhamento do desenvolvimento de conhecimentos, habil idades e atitudes pelo \\nestudante, bem como a análise dos registros produzidos ao longo do processo para fins de atribuição do \\nrendimento acadêmico. \\n \\nParágrafo único.  De modo complementar, os resultados do processo de avaliação devem \\nsubsidiar a reflexão e, caso necessário, o redimensionamento da prática pedagógica docente. \\n \\nArt. 97.   A avaliação da aprendizagem deve verificar a apropriação dos conhecimentos por \\nparte dos estudantes, considerando os objetivos, conteúdos propostos no programa do componente \\ncurricular e o perfil do egresso estabelecido pelas Diretrizes Curriculares Nacionais e Projeto Pedagógico \\nde Curso.'), Document(id='68216672-e09a-4f17-8236-04f67603ffe3', metadata={'author': 'tamara', 'creationdate': '2023-10-20T11:54:29-03:00', 'creator': 'Microsoft® Office Word 2007', 'moddate': '2023-10-20T11:54:29-03:00', 'page': 24, 'page_label': '25', 'producer': 'Microsoft® Office Word 2007', 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf', 'total_pages': 77}, page_content='Parágrafo único.   Os critérios utilizados na avaliação devem ser divulgados pelo docente e \\nconstar no plano de ensino, conforme art. 47 deste Regulamento. \\n \\nArt. 98.   Os instrumentos para avaliação da aprendizagem devem considerar as concepções \\nformativas definidas no Projeto Pedagógico do Curso. \\n \\nParágrafo único.  Os Estudantes com Necessidades Educacionais Específicas - NEE poderão ter \\nmecanismos de avaliação diferenciados de acordo com as suas necessidades, mediante parecer da \\nSecretaria de Inclusão e Acessibilidade - SIA. \\n \\nArt. 99.   O rendimento acadêmico é o resultado obtido pelo estudante nos instrumentos \\navaliativos adotados em cada componente curricular. \\n \\n§1º  O rendimento acadêmico dos estudantes matriculados na turma é divulgado por meio de \\nnota ou situação final de aprovação ou reprovação, conforme §2º, do art. 59. \\n \\n§2º  Ao estudante que não participa de uma atividade avaliativa é atribuída a nota 0 (zero). \\n \\n§3º É facultado aos departamentos ou unidades acadêmicas especializadas estabelecer a \\naferição do rendimento de componentes curriculares por meio da situação de aprovação e reprovação, \\ndevendo esta característica constar no Projeto Pedagógico do Curso. \\n \\n§4º  Na hipótese descrita no §3º deste artigo o rendimento não será contabilizado para o \\ncálculo dos índices acadêmicos dos estudantes, devendo ser atendidos os critérios de assiduidade. \\n \\nArt. 100.  O processo avaliativo pode ser organizado em até 3 (três) unidades avaliativas. \\n \\n§1º  Cada unidade avaliativa pode ser composta por um ou mais instrumentos de avaliação. \\n \\n§2º  O número de unidades avaliativas é definido pela unidade de vinculação do componente \\ncurricular no momento de criação do componente curricular. \\n \\n§3º  Para os componentes curriculares com 3 (três) unidades avaliativas, em pelo menos uma \\ndas unidades, é obrigatória a realização de uma avaliação escrita, individual e presencial.  \\n \\n§4º  A unidade de vinculação do componen te curricular poderá, excepcionalmente, dispensar a \\nobrigatoriedade estabelecida no §3º  deste artigo. \\n \\nArt. 101.  O rendimento acadêmico de cada unidade avaliativa é calculado a partir dos \\nresultados obtidos nos instrumentos avaliativos utilizados na unidade. \\n \\nParágrafo único.  A quantidade de instrumentos avaliativos por unidade é definida previamente \\npelo docente e divulgada no plano de ensino da turma. \\n \\nArt. 102.   O rendimento acadêmico parcial (média parcial) é calculado pela média aritmética \\ndos rendimentos acadêmicos obtidos em cada unidade avaliativa. \\n \\nParágrafo único.  Em cada unidade avaliativa, o estudante deve atender o critério de'), Document(id='642d6a29-496d-4101-b87b-23c1d9fd94f0', metadata={'author': 'tamara', 'creationdate': '2023-10-20T11:54:29-03:00', 'creator': 'Microsoft® Office Word 2007', 'moddate': '2023-10-20T11:54:29-03:00', 'page': 27, 'page_label': '28', 'producer': 'Microsoft® Office Word 2007', 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf', 'total_pages': 77}, page_content='I - prova substitutiva a ser realizada em data alternativa, no turno de estudo do estudante ou \\nem outro horário agendado com sua anuência expressa; ou \\n \\nII - trabalho escrito ou outra modalidade de atividade de pesquisa com tema, objetivo e data de \\nentrega definidos pelo docente responsável. \\n \\nParágrafo único.  O estudante que em virtude de escusa de consciência solicitar a rep osição da \\natividade avaliativa, deverá comprovar, no momento da solicitação, que pertence à instituição religiosa \\nconforme estabelecido no caput deste artigo.  \\n  \\nCAPÍTULO I \\nDA AVALIAÇÃO DA APRENDIZAGEM EM DISCIPLINAS \\n \\nArt. 113.  O rendimento acadêmico nas disciplinas que têm previsão de nota deve ser expresso \\nem valores numéricos de 0 (zero) a 10 (dez), variando até a primeira casa decimal. \\n \\nArt. 114.  É considerado aprovado, quanto à avaliação do rendimento acadêmico, o estudante \\nque tem média parcial igua l ou superior a 6,0 (seis), com rendimento acadêmico igual ou superior a 4,0 \\n(quatro) em todas as unidades.  \\n \\nParágrafo único. A média final para os estudantes aprovados, de acordo com os critérios \\nestabelecidos neste artigo, é igual à média parcial, fican do o estudante dispensado da atividade de \\nreposição. \\n \\nArt. 115.   O estudante que não atinge os critérios de aprovação definidos no art. 114 tem \\ndireito à realização de uma avaliação de reposição se todas as seguintes condições forem atendidas: \\n \\nI - o critério de assiduidade é satisfeito; e \\n \\nII - o estudante tem média parcial igual ou superior a 3,0 (três). \\n \\n§1º  O estudante que não atinge os critérios de aprovação definidos no art. 114 e que não pode \\nrealizar avaliação de reposição é considerado reprovado, com média final igual à média parcial. \\n \\n§2º  O estudante que atinge os critérios de aprovação definidos no art. 114, não tem direito a \\nrealizar avaliação de reposição. \\n \\n§3º  Caso o estudante não realize alguma atividade avaliativa, porém atinja os critério s de \\naprovação definidos art. 114, não terá direito a realizar avaliação de reposição. \\n \\n§4º  Nos casos de turmas que contenham apenas uma unidade avaliativa fica dispensada a \\nexigência do critério estabelecido no inciso II deste artigo. \\n \\nArt. 116.  Para o estudante que realiza avaliação de reposição, o rendimento acadêmico obtido \\nnesta avaliação substitui o menor rendimento acadêmico obtido em uma das unidades avaliativas. \\n \\n§1º  A avaliação de reposição substitui a nota de somente uma das unidades avaliativas.'), Document(id='97d90b19-cddf-4f3b-bab5-e2e733cea19e', metadata={'author': 'tamara', 'creationdate': '2023-10-20T11:54:29-03:00', 'creator': 'Microsoft® Office Word 2007', 'moddate': '2023-10-20T11:54:29-03:00', 'page': 28, 'page_label': '29', 'producer': 'Microsoft® Office Word 2007', 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf', 'total_pages': 77}, page_content='§2º  É facultado ao docente utilizar um instrumento de avaliação único para todos os \\nestudantes que fazem avaliação de reposição ou adotar instrumentos de avaliação distintos \\nrelacionados aos conteúdos de cada uma das unidades. \\n \\n§3º  Não há mecanismo de reposição de nota para o estudante que não comparece à avaliação \\nde reposição. \\n \\nArt. 117.   O estudante que realiza avaliação de reposição é considerado aprovado, quanto à \\navaliação do rendimento acadêmico, caso obtenha média final igual ou superior a 5, 0 (cinco), com \\nrendimento acadêmico igual ou superior a 4,0 (quatro) na avaliação de reposição. \\n \\nArt. 118.   O prazo para realização da avaliação de reposição é de, no mínimo, 3 (três) dias \\nletivos, contados a partir da divulgação da média parcial e da freq uência do estudante no sistema de \\ngestão acadêmica. \\n \\nArt. 119.  Não deve ser realizada avaliação de reposição sem que a média parcial e a frequência \\ndos estudantes tenham sido cadastradas no sistema de gestão acadêmica, sob pena de a referida \\navaliação ser anulada. \\n \\n§1º  O pedido de anulação da avaliação pode ser realizado por qualquer estudante da turma, \\ndevendo ser protocolado na unidade acadêmica a qual o componente curricular é vinculado, no prazo \\nmáximo de até 1 (um) dia útil após a realização da atividade. \\n \\n§2º  Compete à chefia da unidade acadêmica avaliar o pedido de anulação da atividade e, \\nsendo constatado que as condições previstas no caput deste artigo não tenham sido cumpridas, \\ndeterminar a anulação da atividade e a publicação imediata da média parcial e da frequência dos \\nestudantes. \\n \\nArt. 120.  O critério de assiduidade  em uma disciplina presencial é satisfeito quando o \\nestudante cumpre a frequência mínima correspondente a 75% (setenta e cinco por cento) da carga \\nhorária do componente curricular, considerando o rendimento acadêmico exigido. \\n \\nArt. 121.  É permitido ao estudante, mediante requerimento fundamentado, solicitar revisão do \\nregistro de frequência em uma unidade avaliativa.   \\n \\nParágrafo único.  A revisão do registro de frequência segue p rocedimentos similares aos da \\nrevisão de rendimento acadêmico previstos no art. 107. \\n \\nCAPÍTULO II \\nDA AVALIAÇÃO DE APRENDIZAGEM EM BLOCOS \\n \\nArt. 122.  Para aprovação em um bloco, o estudante deve ser aprovado em cada um de seus \\nsub-blocos, satisfazendo os critérios de aprovação tanto na avaliação do rendimento acadêmico quanto \\nna assiduidade, nos termos dos art. 114 e 120.  \\n \\n§1º  A média final do bloco será a média ponderada dos resultados obtidos nos sub -blocos, \\nconsiderando como pesos suas respectivas cargas horárias.')]\n"
     ]
    }
   ],
   "source": [
    "print(docs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a Retriever from a Vector Store\n",
    "\n",
    "A vector store can be transformed into a retriever using its built-in method. This retriever object is designed to perform efficient similarity searches by comparing the embeddings of the search query with those of stored documents. This process allows the system to fetch documents that are closely related to the query content.\n",
    "\n",
    "#### Maximum Marginal Relevance (MMR) Retrieval\n",
    "\n",
    "MMR retrieval is an alternative approach that goes beyond traditional similarity search. Instead of focusing solely on how similar each document is to the query, MMR also considers the similarity among the retrieved documents themselves. This approach seeks to achieve a balance between relevance and diversity.\n",
    "\n",
    "- **Relevance vs. Diversity Trade-Off**:  \n",
    "  In basic similarity search, documents are selected based solely on their similarity to the query. However, this technique might select several documents that offer very similar perspectives or overlapping information. In contrast, MMR aims to reduce redundancy by favoring documents that, while still relevant, provide complementary or different insights.  \n",
    "\n",
    "  A common formulation of this trade-off is:\n",
    "  \n",
    "  $$\n",
    "  \\text{score}(d) = \\lambda \\cdot \\text{sim}(q, d) - (1 - \\lambda) \\cdot \\max_{d' \\in S} \\text{sim}(d, d')\n",
    "  $$\n",
    "  \n",
    "  Here,  \n",
    "  - $ \\text{sim}(q, d) $ measures the similarity between the query $ q $ and the document $ d $.  \n",
    "  - $ \\max_{d' \\in S} \\text{sim}(d, d') $ represents the maximum similarity between $ d $ and any document $ d' $ already selected in the set $ S $.  \n",
    "  - $ \\lambda $ is a parameter (with $ 0 \\leq \\lambda \\leq 1 $) that controls the balance between choosing documents that are highly similar to the query and those that are more diverse compared to the current set.  \n",
    "\n",
    "- **Practical Benefits of MMR**:  \n",
    "  1. **Enhanced Diversity**: By intentionally selecting documents that are not only relevant but also distinct from each other, MMR ensures that different facets of the topic are represented.  \n",
    "  2. **Reduced Redundancy**: With similarity-based methods, many documents containing overlapping information may be retrieved. MMR minimizes this problem by preferring documents that contribute new information.  \n",
    "  3. **Broader Information Coverage**: A diverse set of results can expose users to various aspects of the topic, which is especially useful when a single document cannot fully satisfy the user's information need.  \n",
    "  4. **Improved User Experience**: Presenting a varied set of results helps users gain a more complete understanding of the subject matter without having to manually filter out duplicate or near-duplicate insights.\n",
    "\n",
    "#### Considerations When Using MMR\n",
    "\n",
    "- **Document Quality and Diversity**:  \n",
    "  The effectiveness of MMR relies on having a vector store with a high-quality and varied set of documents. If the fundamental documents lack diversity, even MMR may not be able to produce a rich set of results.\n",
    "\n",
    "- **Tuning the MMR Parameters**:  \n",
    "  The performance of the MMR retrieval method is influenced by the choice of parameters, especially the value of $ \\lambda $. Fine-tuning this parameter is essential to reach the desired balance between relevance and diversity for different use cases.\n",
    "\n",
    "> **Note:** The choice between using traditional similarity search and MMR-based search should be based on the specific needs of the application. When redundancy is a concern and a broad overview is desired, MMR presents a beneficial alternative.\n",
    "\n",
    "This extensive treatment of MMR retrieval methods helps clarify how this approach can be used to enhance the variety of results while still maintaining strong relevance to query terms, leading to a more effective and satisfying search experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the ChromaDB instance with OpenAI embeddings into a retriever\n",
    "# 'as_retriever' method converts the ChromaDB instance into a retriever object\n",
    "# 'search_type='mmr'' specifies that the retriever should use Maximal Marginal Relevance (MMR) for search\n",
    "# MMR helps in diversifying the search results by balancing relevance and diversity\n",
    "retriever_openai = db_openai.as_retriever(search_type=\"mmr\")\n",
    "\n",
    "# Convert the ChromaDB instance with Sentence Transformers embeddings into a retriever\n",
    "# Similar to the above, this converts the ChromaDB instance into a retriever object using MMR\n",
    "retriever_sentence_transformers = db_sentence_transformers.as_retriever(\n",
    "    search_type=\"mmr\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='bbb09d51-066b-4195-9d8b-7d039e1ebbd2', metadata={'author': 'tamara', 'creationdate': '2023-10-20T11:54:29-03:00', 'creator': 'Microsoft® Office Word 2007', 'moddate': '2023-10-20T11:54:29-03:00', 'page': 23, 'page_label': '24', 'producer': 'Microsoft® Office Word 2007', 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf', 'total_pages': 77}, page_content='datas relativas a procedimentos regulares previstos neste regulamento. \\n \\nArt. 94.   Os cursos de graduação se desenvolvem anualmente em dois períodos letivos \\nregulares estabelecidos no Calendário Universitário. \\n \\n§1º  Os períodos letivos regulares têm duração de, no mínimo, 18 (dezoito) semanas de aulas. \\n \\n§2º  Adicionalmente, a critério da instituição, pode ser realizado período letivo especial de \\nférias. \\n \\n§3º  O período letivo especial de férias deve ter duração mínima de 4 (quatro) semanas. \\n \\nArt. 95.  As aulas presenciais semanais da UFRN são ministradas: \\n \\nI - de segunda-feira a sábado, conforme o Calendário Universitário; \\n \\nII - em três turnos diários: matutino, vespertino e noturno; \\n \\nIII -  com duração de 50 (cinquenta) minutos de atividades; e \\n \\nIV - conforme distribuição semanal dos horários  de aulas apresentada no Anexo I deste \\nRegulamento. \\n \\n§1º  Deve ser ministrada a quantidade de aulas necessária para o cumprimento total da carga \\nhorária dos componentes curriculares no período letivo. \\n \\n§2º  Quando necessário o docente deverá ministrar aula  de reposição para cumprir o que \\nestabelece o §1º  deste artigo. \\n \\n§3º  As unidades de ensino do interior do estado podem estabelecer horários noturnos \\ndistintos dos definidos no Anexo I deste Regulamento, sem prejuízo de atendimento aos incisos I, II e III  \\ndeste artigo, mediante aprovação da Câmara de Graduação.  \\n \\nTÍTULO VI \\nDA AVALIAÇÃO DE APRENDIZAGEM \\n \\nArt. 96.   A avaliação da aprendizagem, processo mediado pelo docente, compreende o \\ndiagnóstico e o acompanhamento do desenvolvimento de conhecimentos, habil idades e atitudes pelo \\nestudante, bem como a análise dos registros produzidos ao longo do processo para fins de atribuição do \\nrendimento acadêmico. \\n \\nParágrafo único.  De modo complementar, os resultados do processo de avaliação devem \\nsubsidiar a reflexão e, caso necessário, o redimensionamento da prática pedagógica docente. \\n \\nArt. 97.   A avaliação da aprendizagem deve verificar a apropriação dos conhecimentos por \\nparte dos estudantes, considerando os objetivos, conteúdos propostos no programa do componente \\ncurricular e o perfil do egresso estabelecido pelas Diretrizes Curriculares Nacionais e Projeto Pedagógico \\nde Curso.'), Document(id='97d90b19-cddf-4f3b-bab5-e2e733cea19e', metadata={'author': 'tamara', 'creationdate': '2023-10-20T11:54:29-03:00', 'creator': 'Microsoft® Office Word 2007', 'moddate': '2023-10-20T11:54:29-03:00', 'page': 28, 'page_label': '29', 'producer': 'Microsoft® Office Word 2007', 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf', 'total_pages': 77}, page_content='§2º  É facultado ao docente utilizar um instrumento de avaliação único para todos os \\nestudantes que fazem avaliação de reposição ou adotar instrumentos de avaliação distintos \\nrelacionados aos conteúdos de cada uma das unidades. \\n \\n§3º  Não há mecanismo de reposição de nota para o estudante que não comparece à avaliação \\nde reposição. \\n \\nArt. 117.   O estudante que realiza avaliação de reposição é considerado aprovado, quanto à \\navaliação do rendimento acadêmico, caso obtenha média final igual ou superior a 5, 0 (cinco), com \\nrendimento acadêmico igual ou superior a 4,0 (quatro) na avaliação de reposição. \\n \\nArt. 118.   O prazo para realização da avaliação de reposição é de, no mínimo, 3 (três) dias \\nletivos, contados a partir da divulgação da média parcial e da freq uência do estudante no sistema de \\ngestão acadêmica. \\n \\nArt. 119.  Não deve ser realizada avaliação de reposição sem que a média parcial e a frequência \\ndos estudantes tenham sido cadastradas no sistema de gestão acadêmica, sob pena de a referida \\navaliação ser anulada. \\n \\n§1º  O pedido de anulação da avaliação pode ser realizado por qualquer estudante da turma, \\ndevendo ser protocolado na unidade acadêmica a qual o componente curricular é vinculado, no prazo \\nmáximo de até 1 (um) dia útil após a realização da atividade. \\n \\n§2º  Compete à chefia da unidade acadêmica avaliar o pedido de anulação da atividade e, \\nsendo constatado que as condições previstas no caput deste artigo não tenham sido cumpridas, \\ndeterminar a anulação da atividade e a publicação imediata da média parcial e da frequência dos \\nestudantes. \\n \\nArt. 120.  O critério de assiduidade  em uma disciplina presencial é satisfeito quando o \\nestudante cumpre a frequência mínima correspondente a 75% (setenta e cinco por cento) da carga \\nhorária do componente curricular, considerando o rendimento acadêmico exigido. \\n \\nArt. 121.  É permitido ao estudante, mediante requerimento fundamentado, solicitar revisão do \\nregistro de frequência em uma unidade avaliativa.   \\n \\nParágrafo único.  A revisão do registro de frequência segue p rocedimentos similares aos da \\nrevisão de rendimento acadêmico previstos no art. 107. \\n \\nCAPÍTULO II \\nDA AVALIAÇÃO DE APRENDIZAGEM EM BLOCOS \\n \\nArt. 122.  Para aprovação em um bloco, o estudante deve ser aprovado em cada um de seus \\nsub-blocos, satisfazendo os critérios de aprovação tanto na avaliação do rendimento acadêmico quanto \\nna assiduidade, nos termos dos art. 114 e 120.  \\n \\n§1º  A média final do bloco será a média ponderada dos resultados obtidos nos sub -blocos, \\nconsiderando como pesos suas respectivas cargas horárias.'), Document(id='f8106d99-bb92-4033-aff7-25b5069fa2f5', metadata={'author': 'tamara', 'creationdate': '2023-10-20T11:54:29-03:00', 'creator': 'Microsoft® Office Word 2007', 'moddate': '2023-10-20T11:54:29-03:00', 'page': 54, 'page_label': '55', 'producer': 'Microsoft® Office Word 2007', 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf', 'total_pages': 77}, page_content='Art. 248.   Os estudos realizados por estudantes em Instituições de Ensino Superior - IES, \\nnacionais ou estrangeiras, em cursos de educação profissional técnica de nível médio, de graduação e de \\npós-graduação stricto sensu, podem ser aproveitados na UFRN, nos cursos de graduação, nos termos \\ndeste regulamento. \\n \\n §1º  O aproveitamento somente pode ocorr er para componentes curriculares cursados nos 15 \\n(quinze) anos anteriores ao ingresso do estudante no curso atual na UFRN, com aprovação pela \\ninstituição de origem.  \\n \\n§ 2º   Os cursos nacionais de educação profissional técnica de nível médio, de graduação o u \\npós-graduação a que se refere o caput deste artigo devem ser legalmente reconhecidos ou autorizados \\npara que se proceda o aproveitamento. \\n \\n§ 3º  Não pode haver aproveitamento de atividades acadêmicas, exceto para as atividades \\ncoletivas. \\n \\nArt. 249.  O requerimento do interessado, solicitando aproveitamento de estudos, deverá ser \\ninstruído com: \\n \\nI - histórico escolar original atualizado, no qual constem os componentes curriculares cursados \\ncom suas respectivas cargas horárias e resultados obtidos; \\n \\nII - programa dos componentes curriculares objetos da solicitação; \\n \\nIII - comprovante de autorização ou reconhecimento do curso, quando realizado no Brasil; e \\n \\nIV - documento emitido por órgão competente do país de origem que comprove a regularidade \\nda instituição, em caso de estudo realizado no exterior. \\n \\n§1º  Quando se tratar de documento emitido em língua estrangeira, é obrigatória a tradução \\noficial juramentada em português, autenticada pelo representante diplomático brasileiro do país em \\nque foi expedido. \\n \\n§2º  O disposto no §1º  deste artigo não se aplica às línguas francas utilizadas no ambiente de \\nformação acadêmica e de produção de conhecimento universitário, que são o inglês, o francês e o \\nespanhol. \\n \\nArt. 250.  A solicitação de aproveitamento de estudos é  apreciada pelo coordenador do curso e \\nhomologada pelo respectivo colegiado. \\n \\n§1º  O aproveitamento somente é permitido quando o programa do componente curricular \\ncursado na instituição de origem corresponde a 75% (setenta e cinco por cento) ou mais do conteúdo do \\ncomponente curricular da UFRN. \\n \\n§2º  O cumprimento do percentual previsto no §1º  deste artigo não garante o aproveitamento \\ndo componente curricular. \\n \\n§3º  É permitida a combinação de mais de um componente curricular cursado na instituição de'), Document(id='6e54ef0f-f77a-408d-9bc9-159c08badd37', metadata={'author': 'tamara', 'creationdate': '2023-10-20T11:54:29-03:00', 'creator': 'Microsoft® Office Word 2007', 'moddate': '2023-10-20T11:54:29-03:00', 'page': 65, 'page_label': '66', 'producer': 'Microsoft® Office Word 2007', 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf', 'total_pages': 77}, page_content='VI - efetivação de novo cadastro; \\n \\nVII - decisão administrativa; ou \\n \\nVIII - falecimento do estudante. \\n \\nParágrafo único.  Nos casos dos incisos IV e V, o cancelamento de curso não é efetivado se o \\nestudante estiver respondendo a Processo Administrativo Disciplinar Discente - PADD. \\n \\nArt. 295.   O cancelamento de curso não isenta o estudante do cumprimento de obrigações \\neventualmente adquiridas no sistema de bibliotecas e outros serviços da UFRN. \\n \\nArt. 296.  O estudante cancelado pode solicitar reativação de cadastro à Câmara de Graduação \\npor meio de justificativa fundamentada e comprovada por documentos. \\n \\nSeção I \\nDo abandono de curso \\n \\nArt. 297.  O vínculo do estudante é cancelado por abandono de curso em uma das seguintes \\nsituações: \\n \\nI - não efetivação de matrícula em componentes curriculares, conforme art. 209, parágrafo \\núnico; ou \\n \\nII - nenhuma integralização de carga horária em 2 (dois) períodos letivos regulares \\nconsecutivos.  \\n \\n§1º  O cancelamento a que se refere o inciso I é realizado após o término do prazo estabelecido \\nno Calendário Universitário para suspensão de curso. \\n \\n§2º  O cancelamento a que se refere o inciso II é realizado no prazo estabelecido no Calendário \\nUniversitário. \\n \\n§3º  O estudante que incorre na situação prevista no inciso II é notificado, por meio do sistema \\nde gestão acadêmica, para apresentar justifi cativa fundamentada e comprovada por documentos para \\nanálise pela PROGRAD. \\n \\nSeção II \\nDo decurso de prazo para conclusão de curso \\n \\nArt. 298.  O vínculo do estudante será cancelado por decurso de prazo quando não concluir o \\ncurso até o prazo máximo para inte gralização curricular, estabelecido no Projeto Pedagógico do Curso \\nao qual está vinculado. \\n \\n§1º  O cancelamento por decurso de prazo é realizado após o término do último período letivo \\nregular que corresponde ao prazo máximo para integralização curricular. \\n \\n§2º  Na situação prevista no §1º deste artigo, será permitido ao estudante que esteja com')]\n"
     ]
    }
   ],
   "source": [
    "# Print the results of invoking the retriever with the specified query\n",
    "# 'retriever_openai' is the retriever object created from the ChromaDB instance with OpenAI embeddings\n",
    "# 'invoke(query)' method performs the search using the query and returns the most relevant documents\n",
    "print(retriever_openai.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b27bb4cbe0747679d458d6ee362f010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='24972478-c695-462d-8000-ec3fd5886848', metadata={'author': 'tamara', 'creationdate': '2023-10-20T11:54:29-03:00', 'creator': 'Microsoft® Office Word 2007', 'moddate': '2023-10-20T11:54:29-03:00', 'page': 24, 'page_label': '25', 'producer': 'Microsoft® Office Word 2007', 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf', 'total_pages': 77}, page_content='das unidades, é obrigatória a realização de uma avaliação escrita, individual e presencial.  \\n \\n§4º  A unidade de vinculação do componen te curricular poderá, excepcionalmente, dispensar a \\nobrigatoriedade estabelecida no §3º  deste artigo. \\n \\nArt. 101.  O rendimento acadêmico de cada unidade avaliativa é calculado a partir dos \\nresultados obtidos nos instrumentos avaliativos utilizados na unidade. \\n \\nParágrafo único.  A quantidade de instrumentos avaliativos por unidade é definida previamente \\npelo docente e divulgada no plano de ensino da turma. \\n \\nArt. 102.   O rendimento acadêmico parcial (média parcial) é calculado pela média aritmética \\ndos rendimentos acadêmicos obtidos em cada unidade avaliativa. \\n \\nParágrafo único.  Em cada unidade avaliativa, o estudante deve atender o critério de'), Document(id='45fbbb0a-afe4-47fa-88a3-ef88f193301c', metadata={'author': 'tamara', 'creationdate': '2023-10-20T11:54:29-03:00', 'creator': 'Microsoft® Office Word 2007', 'moddate': '2023-10-20T11:54:29-03:00', 'page': 30, 'page_label': '31', 'producer': 'Microsoft® Office Word 2007', 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf', 'total_pages': 77}, page_content='Art. 132.  As formas regulares de ingresso nos cursos de graduação da UFRN são: \\n \\nI - Sistema de Seleção Unificada - SiSU;  \\n \\nII - Processo Seletivo Específico - PSE; \\n \\nIII - Reingresso Específico;'), Document(id='99fd971a-3710-4faf-ac58-8aa1a6efa9e2', metadata={'author': 'tamara', 'creationdate': '2023-10-20T11:54:29-03:00', 'creator': 'Microsoft® Office Word 2007', 'moddate': '2023-10-20T11:54:29-03:00', 'page': 13, 'page_label': '14', 'producer': 'Microsoft® Office Word 2007', 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf', 'total_pages': 77}, page_content='denominadas de sub-blocos articulados e interdependentes entre si, funcionando, no que couber, como \\ndisciplina. \\n \\n§1º  O código dos sub-blocos deriva do código do bloco. \\n \\n§2º  A carga h orária do bloco é a soma das cargas horárias dos sub -blocos e sua caracterização \\nengloba as ementas dos sub-blocos. \\n \\n§3º  Para ser aprovado no bloco é necessária a aprovação em todos os sub -blocos do \\ncomponente curricular.'), Document(id='67adc191-d8ce-450b-8005-6a1ea7ec6f36', metadata={'author': 'tamara', 'creationdate': '2023-10-20T11:54:29-03:00', 'creator': 'Microsoft® Office Word 2007', 'moddate': '2023-10-20T11:54:29-03:00', 'page': 29, 'page_label': '30', 'producer': 'Microsoft® Office Word 2007', 'source': 'data/regulamento-dos-cursos-de-graduacao-da-UFRN-2024.pdf', 'total_pages': 77}, page_content='estudantes nos cursos de graduação, contribuindo com a sua inserção e permanência, com êxito na vida \\nacadêmica. \\n \\nArt. 128.   As a tividades de orientação acadêmica são realizadas por docentes atuantes no \\ncurso, indicados pelos colegiados de curso, com anuência dos departamentos ou unidades acadêmicas \\nespecializadas de lotação dos docentes. \\n \\n§1º  A designação do orientador acadêmico é  registrada no sistema de gestão acadêmica pela \\ncoordenação do curso.')]\n"
     ]
    }
   ],
   "source": [
    "# Print the results of invoking the retriever with the specified query\n",
    "# 'retriever_sentence_transformers' is the retriever object created from the ChromaDB instance with Sentence Transformers embeddings\n",
    "# 'invoke(query)' method performs the search using the query and returns the most relevant documents\n",
    "print(retriever_sentence_transformers.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Define the chat prompt template with a series of messages\n",
    "# 'from_messages' method creates a ChatPromptTemplate from a list of message tuples\n",
    "# Each tuple contains a message type and the message content\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # System message to establish the assistant's role\n",
    "        # This message sets the context for the assistant, instructing it to answer questions about UFRN\n",
    "        # If the assistant doesn't know the answer, it should say so\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Você é um assistente de alunos que responde a dúvidas sobre a UFRN. Use as informações fornecidas para responder às perguntas dos alunos. Se você não souber a resposta, apenas diga que não sabe.\",\n",
    "        ),\n",
    "        # Placeholder for chat history to maintain context\n",
    "        # This placeholder will be replaced with the actual chat history during execution\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        # Human message placeholder for user input\n",
    "        # This placeholder will be replaced with the user's question and context during execution\n",
    "        (\"human\", \"\\nCONTEXTO: {context} \\n\\nPERGUNTA: {question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to format retrieved documents\n",
    "# 'docs' is a list of document objects\n",
    "# The function joins the page content of each document with four newline characters in between\n",
    "def format_retrieved_documents(docs):\n",
    "    return \"\\n\\n\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a base runnable for the Sentence Transformers retriever\n",
    "# This runnable will handle the context and question for the chat prompt\n",
    "base_runnable_sentence_transformers = (\n",
    "    {\n",
    "        # 'context' key will use the retriever to get relevant documents and format them\n",
    "        # 'retriever_sentence_transformers' retrieves relevant documents based on the query\n",
    "        # 'format_retrieved_documents' formats the retrieved documents for the chat prompt\n",
    "        \"context\": retriever_sentence_transformers | format_retrieved_documents,\n",
    "        # 'question' key will pass the question directly to the retriever without modification\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    # Combine the context and question with the chat prompt template\n",
    "    | prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a base runnable for the OpenAI retriever\n",
    "# This runnable will handle the context and question for the chat prompt\n",
    "base_runnable_openai = (\n",
    "    {\n",
    "        # 'context' key will use the retriever to get relevant documents and format them\n",
    "        # 'retriever_openai' retrieves relevant documents based on the query\n",
    "        # 'format_retrieved_documents' formats the retrieved documents for the chat prompt\n",
    "        \"context\": retriever_openai | format_retrieved_documents,\n",
    "        # 'question' key will pass the question directly to the retriever without modification\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    # Combine the context and question with the chat prompt template\n",
    "    | prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an output parser to parse the string output of the chat\n",
    "# 'StrOutputParser' is used to parse the output of the chat into a string format\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RAG (Retrieval-Augmented Generation) chain using Sentence Transformers embeddings and OpenAI model\n",
    "# 'base_runnable_sentence_transformers' handles the context and question for the chat prompt using Sentence Transformers embeddings\n",
    "# 'model_openai' is the OpenAI model used to generate responses based on the retrieved context and question\n",
    "# 'output_parser' parses the output of the OpenAI model into a string format\n",
    "\n",
    "rag_chain_sentence_transformers_openai = (\n",
    "    base_runnable_sentence_transformers  # Use the base runnable with Sentence Transformers embeddings\n",
    "    | model_openai  # Pass the result to the OpenAI model for response generation\n",
    "    | output_parser  # Parse the model's output into a string format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RAG (Retrieval-Augmented Generation) chain using Sentence Transformers embeddings and Llama 3.1 model\n",
    "\n",
    "rag_chain_sentence_transformers_llama = (\n",
    "    base_runnable_sentence_transformers  # Use the base runnable with Sentence Transformers embeddings\n",
    "    | model_llama  # Pass the result to the Llama 3.1 model for response generation\n",
    "    | output_parser  # Parse the model's output into a string format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RAG (Retrieval-Augmented Generation) chain using OpenAI embeddings and OpenAI model\n",
    "\n",
    "rag_chain_openai_openai = (\n",
    "    base_runnable_openai  # Use the base runnable with OpenAI embeddings\n",
    "    | model_openai  # Pass the result to the OpenAI model for response generation\n",
    "    | output_parser  # Parse the model's output into a string format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RAG (Retrieval-Augmented Generation) chain using OpenAI embeddings and Llama 3.1 model\n",
    "rag_chain_openai_llama = (\n",
    "    base_runnable_openai  # Use the base runnable with OpenAI embeddings\n",
    "    | model_llama  # Pass the result to the Llama 3.1 model for response generation\n",
    "    | output_parser  # Parse the model's output into a string format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"O que significa uma disciplina optativa?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb57e8ffd7e48bb94ac042b8228c3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Uma disciplina optativa é um componente curricular que o estudante pode escolher cursar, ao invés de ser obrigado a fazê-lo. Essas disciplinas permitem que os alunos personalizem sua formação acadêmica, escolhendo matérias que complementem ou ampliem seus conhecimentos em áreas de interesse. Na UFRN, a carga horária das disciplinas optativas deve ser, no mínimo, 50% superior à carga horária mínima que o aluno deve cumprir nesse grupo.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_sentence_transformers_openai.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5629ba4716443259ad5d13713283022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Uma disciplina optativa é um componente curricular que não é obrigatório para os alunos, mas pode ser escolhido por eles como parte de sua carga horária acadêmica. Isso significa que os alunos têm a liberdade de decidir se querem ou não incluir essa disciplina em seu plano de estudos.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_sentence_transformers_llama.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Uma disciplina optativa é um componente curricular que faz parte de um rol de opções disponibilizado na estrutura curricular de um curso. O estudante deve escolher cursar uma carga horária mínima de disciplinas optativas para a integralização curricular, conforme estabelecido no Projeto Pedagógico de Curso. Essas disciplinas não são obrigatórias, mas oferecem ao estudante a oportunidade de diversificar sua formação acadêmica.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_openai_openai.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Uma disciplina optativa é uma opção oferecida aos estudantes para complementar seu currículo acadêmico, geralmente não sendo obrigatória para a conclusão de um curso ou programa específico. Elas permitem aos alunos explorarem áreas de interesse pessoal ou profissional que não estejam diretamente relacionadas ao seu plano de estudos principal.\\n\\nDisciplinas optativas podem ser oferecidas em uma variedade de formatos, desde cursos teóricos até práticas, como aulas, seminários, workshops, ou até mesmo atividades extracurriculares. Elas fornecem aos estudantes a oportunidade de desenvolver habilidades específicas, explorar novos interesses ou profundos conhecimentos em áreas que não estejam cobertas pelo seu currículo principal.\\n\\nA inclusão de disciplinas optativas no currículo acadêmico pode ser benéfica para os alunos por várias razões. Elas permitem aos estudantes:\\n\\n- **Desenvolver habilidades específicas**: Disciplinas optativas podem oferecer treinamento em áreas como programação, design gráfico, ou idiomas, que são valiosas no mercado de trabalho.\\n- **Explorar novos interesses**: Além de desenvolver habilidades práticas, as disciplinas optativas permitem aos alunos explorarem áreas acadêmicas e profissionais que não estejam diretamente relacionadas ao seu campo principal de estudo.\\n- **Melhorar a flexibilidade**: A inclusão de disciplinas optativas no currículo pode fornecer aos estudantes uma maior flexibilidade em relação à sua formação, permitindo-lhes personalizar seu plano de estudos para atender às suas necessidades e interesses específicos.\\n\\nEm resumo, as disciplinas optativas são cursos ou atividades que os alunos podem escolher participar, geralmente não sendo obrigatórias para a conclusão do curso. Elas permitem aos estudantes explorarem áreas de interesse pessoal ou profissional, desenvolver habilidades específicas e melhorar sua flexibilidade em relação à formação acadêmica.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_openai_llama.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b340adbac2944b08ec9c4e5d6c3062d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb9f5b715444971944b65584972aff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Embedding: sentence_transformers\n",
      "LLM: openai\n",
      "Response: O projeto de IA para o Judiciário com foco em proteção ambiental está sendo realizado em parceria com a UFRN, sob a coordenação do professor Elias Jacob.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Embedding: sentence_transformers\n",
      "LLM: llama\n",
      "Response: O professor Elias Jacob está fazendo o projeto de IA para o Judiciário com foco na proteção ambiental, no âmbito do Programa Justiça 4.0, em parceria com a UFRN (Universidade Federal do Rio Grande do Norte).\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Embedding: openai\n",
      "LLM: openai\n",
      "Response: O projeto de IA para o Judiciário com foco em proteção ambiental está sendo realizado pelo Programa das Nações Unidas para o Desenvolvimento (Pnud), o Conselho Nacional de Justiça (CNJ) e a Universidade Federal do Rio Grande do Norte (UFRN).\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Embedding: openai\n",
      "LLM: llama\n",
      "Response: O projeto de IA para o Judiciário com foco em proteção ambiental está sendo feito pela Universidade.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_response_all_models(query):\n",
    "    # Dictionary to store responses from different RAG chains\n",
    "    result = {\n",
    "        \"sentence_transformers-openai\": rag_chain_sentence_transformers_openai.invoke(\n",
    "            query\n",
    "        ),\n",
    "        \"sentence_transformers-llama\": rag_chain_sentence_transformers_llama.invoke(\n",
    "            query\n",
    "        ),\n",
    "        \"openai-openai\": rag_chain_openai_openai.invoke(query),\n",
    "        \"openai-llama\": rag_chain_openai_llama.invoke(query),\n",
    "    }\n",
    "\n",
    "    # Iterate over the results and print them in a formatted manner\n",
    "    for k, v in result.items():\n",
    "        print(\"-\" * 50)  # Separator for readability\n",
    "        print(f\"Embedding: {k.split('-')[0]}\")  # Display the embedding type\n",
    "        print(f\"LLM: {k.split('-')[1]}\")  # Display the language model used\n",
    "        print(f\"Response: {v}\")  # Display the response\n",
    "        print(\"-\" * 50)  # Separator for readability\n",
    "        print(\"\\n\")  # Newline for better formatting\n",
    "\n",
    "    return result  # Return the dictionary with all responses\n",
    "\n",
    "\n",
    "# Example query to test the function\n",
    "result = get_response_all_models(\n",
    "    \"Quem está fazendo o projeto de IA para o Judiciário como foco em proteção ambiental?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929a3a260bfb495cae8be31f880b2b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79afbca763084ebda0bc1ffc9988efe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Embedding: sentence_transformers\n",
      "LLM: openai\n",
      "Response: Não sei.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Embedding: sentence_transformers\n",
      "LLM: llama\n",
      "Response: Desculpe, mas não há informações disponíveis sobre a frequência mínima exigida para aprovação em uma disciplina na UFRN. As informações fornecidas parecem se concentrar mais em regulamentos e procedimentos administrativos da instituição, como matrícula, avaliação e certificação de estudantes, mas não mencionam especificamente a frequência mínima exigida para aprovação em uma disciplina.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Embedding: openai\n",
      "LLM: openai\n",
      "Response: A frequência mínima exigida de um aluno para ser aprovado em uma disciplina na UFRN é de 75% (setenta e cinco por cento) da carga horária do componente curricular.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Embedding: openai\n",
      "LLM: llama\n",
      "Response: De acordo com o texto, a frequência mínima exigida de um aluno para ser aprovado em uma disciplina presencial é 75% da carga horária do componente curricular.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = get_response_all_models(\n",
    "    \"Qual é a frequência mínima exigida de um aluno para ser aprovado em uma disciplina na UFRN?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final suggestion - [BGE-M3](https://arxiv.org/pdf/2402.03216)\n",
    "\n",
    "\n",
    "The BGE-M3 model, developed by the Beijing Academy of Artificial Intelligence (BAAI), is designed for advanced retrieval-augmented generation (RAG) tasks. It is particularly effective for applications that require multilingual support and the manipulation of large volumes of text data.\n",
    "\n",
    "### Key Concepts and Features\n",
    "\n",
    "- **Multilingual Capabilities**:  \n",
    "  The model supports 100 languages, making it suitable for systems operating in diverse linguistic contexts. This capability ensures that semantic representations are reliable regardless of the language of the input text.\n",
    "\n",
    "- **Flexible Input Length**:  \n",
    "  BGE-M3 can process texts ranging from short sentences to full-length documents with up to 8,192 tokens. The ability to handle varying input lengths is useful in scenarios where the retrieval and subsequent generation of responses depend on extensive context. \n",
    "\n",
    "- **High-Quality Embeddings**:  \n",
    "  The quality of the embeddings generated by the model ensures that semantic information is captured accurately. These embeddings represent the key meaning of text and act as the foundation for effective retrieval and subsequent text generation. High-quality embeddings reduce the risk of retrieving irrelevant data during RAG processes.\n",
    "\n",
    "### Practical Advantages in RAG Systems\n",
    "\n",
    "- **Enhanced Multilingual Processing**:\n",
    "  - With support for 100 languages, systems carrying out BGE-M3 can perform well in environments with multilingual data, ensuring that the retrieval and generation components work seamlessly across different languages.\n",
    "  \n",
    "- **Reliable Handling of Long Documents**:\n",
    "  - The capability to process documents containing up to 8,192 tokens allows practitioners to work with detailed and extensive texts. This is particularly valuable in tasks where larger contexts lead to more precise and coherent responses.\n",
    "\n",
    "- **Increased Retrieval Accuracy**:\n",
    "  - By generating semantically rich embeddings, the model improves the accuracy and relevance of retrieved information. This precision is essential for generating responses that are both accurate and context-aware.\n",
    "\n",
    "\n",
    "### Accessing BGE-M3 through Ollama\n",
    "\n",
    "To use the BGE-M3 model in your RAG system, you can use the Ollama library. You'll need to pull from their hub using the following command:\n",
    "\n",
    "```bash\n",
    "(base) jacob@schrodinger ~ % ollama pull bge-m3\n",
    "pulling manifest\n",
    "pulling daec91ffb5dd... 100% ▕████████████████▏ 1.2 GB\n",
    "pulling a406579cd136... 100% ▕████████████████▏ 1.1 KB\n",
    "pulling 0c4c9c2a325f... 100% ▕████████████████▏ 337 B\n",
    "verifying sha256 digest\n",
    "writing manifest\n",
    "removing any unused layers\n",
    "success\n",
    "```\n",
    "\n",
    "This will download and set up the BGE-M3 model, making it readily available for embedding generation in your RAG system.\n",
    "\n",
    "and, best of all... it's `free`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"bge-m3\",  # 'model' specifies the model to use, in this case 'bge-m3'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Eu gostaria de saber mais sobre o processo avaliativo na UFRN.\",\n",
    "    \"Qual é a frequência mínima exigida de um aluno para ser aprovado em uma disciplina na UFRN?\",\n",
    "    \"Como funcionam os trabalhos na educação superior de uma Universidade federal brasileira?\",\n",
    "    \"Cachorros são fofos\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = embeddings.embed_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.67352188 0.58537433 0.30498869]\n",
      " [0.67352188 1.         0.55499701 0.23583424]\n",
      " [0.58537433 0.55499701 1.         0.28292264]\n",
      " [0.30498869 0.23583424 0.28292264 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the cosine similarity between all documents\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate the cosine similarity between all pairs of vectors\n",
    "cosine_sim = cosine_similarity(vectors, vectors)\n",
    "\n",
    "# Print the cosine similarity matrix\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between document 0 and document 1: 0.6735218770434315\n",
      "Similarity between document 0 and document 2: 0.5853743252493536\n",
      "Similarity between document 0 and document 3: 0.30498868606644847\n",
      "Similarity between document 1 and document 2: 0.5549970108342849\n",
      "Similarity between document 1 and document 3: 0.23583424154118882\n",
      "Similarity between document 2 and document 3: 0.2829226353452491\n"
     ]
    }
   ],
   "source": [
    "# Print the similarity between all pairs of documents\n",
    "for i in range(len(texts)):\n",
    "    for j in range(i + 1, len(texts)):\n",
    "        print(f\"Similarity between document {i} and document {j}: {cosine_sim[i][j]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "1. What is Retrieval-Augmented Generation (RAG), and how does it enhance traditional generative models?\n",
    "\n",
    "2. What are the main challenges in generative AI that RAG aims to address, and why are they significant?\n",
    "\n",
    "3. Describe the key components of a RAG system and their roles in the overall architecture.\n",
    "\n",
    "4. How do vector databases like ChromaDB contribute to the efficiency and effectiveness of RAG systems?\n",
    "\n",
    "5. Outline the fundamental principles of RAG and explain their importance in improving the quality of generated text.\n",
    "\n",
    "6. Compare and contrast RAG with traditional generative models, highlighting the advantages of using RAG.\n",
    "\n",
    "7. Explain how RAG solves the problem of limited knowledge scope in generative models and its effects for generating accurate and up-to-date content.\n",
    "\n",
    "8. What is the role of Maximum Marginal Relevance (MMR) search in RAG systems, and how does it enhance the diversity and relevance of retrieved information?\n",
    "\n",
    "9. Discuss the adaptability of RAG systems to various domains and use cases, and provide examples of how they can be customized to meet specific requirements.\n",
    "\n",
    "10. Outline the step-by-step process of building a RAG system using ChromaDB and LangChain, emphasizing the key considerations and best practices at each stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Answers are commented inside this cell`\n",
    "\n",
    "\n",
    "<!-- 1. Retrieval-Augmented Generation (RAG) is an AI framework that enhances traditional generative models by integrating information retrieval systems. It allows for the generation of text that is coherent, contextually relevant, accurate, and up-to-date by employing external knowledge sources during the generation process. RAG improves the quality and relevance of generated text by providing the model with access to a vast pool of information beyond its training data.\n",
    "\n",
    "2. RAG addresses several key challenges in generative AI, including limited knowledge scope, factual inaccuracy, contextual irrelevance, data sparsity, training limitations, inflexibility, and the need for real-time information retrieval. These challenges hinder the ability of generative models to produce high-quality, accurate, and relevant content. RAG enables the creation of more reliable, adaptable, and context-aware generative AI systems.\n",
    "\n",
    "3. A RAG system consists of two main components: a retriever and a generator. The retriever is responsible for searching and retrieving relevant information from an external knowledge source based on the input query. It uses techniques like semantic search and similarity matching to identify the most relevant information. The generator takes the retrieved information and the original query as input and produces the final output response by integrating the retrieved knowledge into the generation process.\n",
    "\n",
    "4. Vector databases like ChromaDB play a crucial role in RAG systems by efficiently storing and querying embedding data. Embeddings are dense vector representations of text that capture semantic meaning. ChromaDB allows RAG systems to quickly retrieve the most relevant information based on similarity metrics, such as cosine similarity, between the query and the stored embeddings. This enables the retrieval of highly relevant and accurate information, enhancing the quality of generated responses.\n",
    "\n",
    "5. The key principles of RAG include:\n",
    "- Retrieving relevant information from external knowledge bases to expand the model's knowledge scope.\n",
    "- Integrating retrieved information into the generation process to improve the accuracy and relevance of generated text.\n",
    "- Enhancing context awareness and factual accuracy by using up-to-date and domain-specific knowledge.\n",
    "- Improving flexibility and scalability by allowing the model to adapt to new information without requiring retraining.\n",
    "- Providing real-time access to up-to-date information to generate current and relevant content.\n",
    "These principles collectively contribute to the creation of more reliable, adaptable, and high-quality generative AI systems.\n",
    "\n",
    "6. Compared to traditional generative models, RAG offers several advantages:\n",
    "- Enhanced factual accuracy: RAG incorporates external knowledge sources, reducing the reliance on the model's training data and improving the accuracy of generated facts.\n",
    "- Improved context awareness: By retrieving relevant information based on the input query, RAG generates text that is more contextually appropriate and coherent.\n",
    "- Reduced reliance on extensive training data: RAG can capitalize on external knowledge sources, reducing the need for large-scale training data and enabling the generation of diverse content.\n",
    "- Flexibility and adaptability: RAG systems can be easily adapted to different domains or updated with new information without requiring retraining of the entire model.\n",
    "\n",
    "7. RAG solves the problem of limited knowledge scope in generative models by incorporating an information retrieval component. This allows the model to fetch relevant, up-to-date information from external knowledge sources, expanding the knowledge base beyond the training data.\n",
    "\n",
    "8. Maximum Marginal Relevance (MMR) search is a technique used in RAG systems to enhance the diversity and relevance of retrieved information. MMR search aims to balance the relevance of retrieved documents to the query while also promoting diversity in the search results. It achieves this by considering both the similarity of documents to the query and the dissimilarity among the retrieved documents.\n",
    "\n",
    "9. RAG systems can be adapted to various domains and use cases by customizing the external knowledge source, chunking strategies, embedding models, and retrieval methods. For example, in a medical domain, the knowledge source can be a database of medical literature, and the chunking strategy can be tailored to extract relevant sections like abstracts or conclusions. The embedding model can be fine-tuned on medical text to capture domain-specific semantics. Similarly, for a legal use case, the knowledge source can be a collection of legal documents, and the retrieval methods can be adapted to handle legal jargon and citation styles.\n",
    "\n",
    "10. Building a RAG system with ChromaDB and LangChain involves the following steps:\n",
    "1. Define the LLM models: Select the appropriate language model(s) for text generation based on the specific requirements of the task.\n",
    "2. Load and prepare documents: Collect and preprocess the relevant documents that will serve as the external knowledge source for the RAG system.\n",
    "3. Chunk the text: Split the documents into manageable segments or chunks that can be efficiently stored and retrieved.\n",
    "4. Store chunks in ChromaDB: Create a ChromaDB instance and store the text chunks along with their embeddings for efficient retrieval.\n",
    "5. Build retrievers: Create retriever objects from the ChromaDB vector stores to enable fast and accurate retrieval of relevant chunks based on similarity metrics.\n",
    "6. Integrate retrievers with LLMs: Use LangChain's prompt templates and output parsers to integrate the retrievers with the selected LLM(s) and generate text based on the retrieved information.\n",
    "7. Fine-tune and enhance: Restate and fine-tune the RAG system by adjusting parameters, experimenting with different retrieval strategies, and improving the prompts and output parsing logic.\n",
    "8. Test and evaluate: Assess the performance of the RAG system using relevant evaluation metrics and gather feedback for further improvements. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imd1107-nlp-1oxVnwDa-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
