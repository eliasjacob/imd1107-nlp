{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/.cache/pypoetry/virtualenvs/imd1107-nlp-V6lLOcpZ-py3.12/lib/python3.12/site-packages/PyPDF2/__init__.py:21: DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.\n",
      "  warnings.warn(\n",
      "/home/jacob/.cache/pypoetry/virtualenvs/imd1107-nlp-V6lLOcpZ-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "<frozen importlib._bootstrap>:488: DeprecationWarning: Type google._upb._message.MessageMapContainer uses PyType_Spec with a metaclass that has custom tp_new. This is deprecated and will no longer be allowed in Python 3.14.\n",
      "<frozen importlib._bootstrap>:488: DeprecationWarning: Type google._upb._message.ScalarMapContainer uses PyType_Spec with a metaclass that has custom tp_new. This is deprecated and will no longer be allowed in Python 3.14.\n",
      "/home/jacob/.cache/pypoetry/virtualenvs/imd1107-nlp-V6lLOcpZ-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import gc\n",
    "import glob\n",
    "import json\n",
    "import math\n",
    "import operator\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import unicodedata\n",
    "import warnings\n",
    "from collections import Counter  # Import Counter to count occurrences of n-grams\n",
    "from datetime import datetime, timedelta\n",
    "from functools import partial\n",
    "from glob import glob\n",
    "from multiprocessing import cpu_count\n",
    "from pathlib import Path\n",
    "from typing import (\n",
    "    Annotated,\n",
    "    Any,\n",
    "    Dict,\n",
    "    List,\n",
    "    Literal,\n",
    "    Optional,\n",
    "    Sequence,\n",
    "    Tuple,\n",
    "    TypedDict,\n",
    ")\n",
    "\n",
    "import datasets\n",
    "import evaluate\n",
    "import fasttext\n",
    "import gensim\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt  # For plotting graphs\n",
    "import nbformat\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.graph_objs as go  # Import Plotly for creating visualizations\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import PyPDF2\n",
    "import requests  # Import the requests library to make HTTP requests\n",
    "import scipy.sparse\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import umap\n",
    "# from bertopic import BERTopic\n",
    "# from bertopic.representation import MaximalMarginalRelevance\n",
    "# from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bs4 import BeautifulSoup  # Import BeautifulSoup to parse HTML content\n",
    "from datasets import Dataset, load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain.chat_models import ChatOllama, ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.document_loaders import (\n",
    "    PyPDFLoader,\n",
    "    UnstructuredURLLoader,\n",
    "    YoutubeLoader,\n",
    ")\n",
    "from langchain_community.document_loaders.youtube import YoutubeLoader\n",
    "from langchain_core.chat_history import (\n",
    "    BaseChatMessageHistory,\n",
    "    InMemoryChatMessageHistory,\n",
    ")\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables.graph import CurveStyle\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.tools import StructuredTool\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_openai import ChatOpenAI, OpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.prebuilt import ToolExecutor, ToolInvocation\n",
    "from lightgbm import LGBMClassifier\n",
    "from nltk import word_tokenize  # Import word_tokenize to split text into words\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.util import ngrams  # Import ngrams to generate n-grams from text\n",
    "from sentence_transformers import (\n",
    "    InputExample,\n",
    "    SentenceTransformer,\n",
    "    evaluation,\n",
    "    losses,\n",
    "    models,\n",
    ")\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs, make_classification, make_regression\n",
    "from sklearn.decomposition import NMF, PCA, TruncatedSVD\n",
    "from sklearn.ensemble import (\n",
    "    ExtraTreesClassifier,\n",
    "    RandomForestClassifier,\n",
    "    StackingClassifier,\n",
    ")\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\n",
    "from sklearn.manifold import TSNE  # Import t-SNE from scikit-learn\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    calinski_harabasz_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    matthews_corrcoef,\n",
    "    silhouette_score,\n",
    ")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    KFold,\n",
    "    RandomizedSearchCV,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import (\n",
    "    Pipeline,  # Pipeline applies a list of transforms sequentially. You can also add an estimator at the end.  # Pipeline applies a list of transforms. You can also add an estimator at the end, so it will be completely encapsulated.\n",
    "    make_pipeline,\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    FunctionTransformer,  # FunctionTransformer allows applying an arbitrary function to the data, useful for custom transformations.  # FunctionTransformer allows to apply an arbitrary function to the data, so we can use it in the pipeline\n",
    ")\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from spacy import displacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training.example import Example\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext import data\n",
    "from torchtext.data import TabularDataset\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    BertConfig,\n",
    "    BertForSequenceClassification,\n",
    "    BertModel,\n",
    "    BertTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorForTokenClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    Pipeline,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    ")\n",
    "from wordcloud import WordCloud\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from helpers.text import (\n",
    "    remove_accented_characters,\n",
    "    remove_excessive_spaces,\n",
    "    remove_numbers_punctuation_from_text,\n",
    "    remove_short_words,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imd1107-nlp-V6lLOcpZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
