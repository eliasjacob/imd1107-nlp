{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training ML models for supervised NLP tasks\n",
    "## IMD1107 - Natural Language Processing\n",
    "### [Dr. Elias Jacob de Menezes Neto](https://docente.ufrn.br/elias.jacob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "## Keypoints\n",
    "- Common Natural Language Processing (NLP) pipelines consists of three main steps: text processing (normalization, tokenization, numericalization), feature extraction, and model training.\n",
    "\n",
    "- Hyperparameter optimization techniques include Grid Search, Random Search, and Bayesian Optimization, each with its own advantages and use cases.\n",
    "\n",
    "- The \"60 iterations rule\" in Random Search states that 60 iterations can find the best 5% set of parameters 95% of the time, regardless of the grid size.\n",
    "\n",
    "- Bayesian Optimization uses a surrogate model, objective function, and acquisition function to efficiently navigate the hyperparameter space.\n",
    "\n",
    "- Ensemble methods like StackingClassifier can improve model performance by combining multiple base classifiers with a meta-classifier.\n",
    "\n",
    "- Chronological data splitting is crucial for legal ruling analysis to prevent temporal leakage and maintain the integrity of legal precedents.\n",
    "\n",
    "## Takeaways\n",
    "- Proper data preprocessing and feature extraction are essential for effective NLP tasks, especially in specialized domains like legal text analysis.\n",
    "\n",
    "- Choosing the right hyperparameter optimization technique depends on the problem complexity, computational resources, and desired balance between exploration and exploitation.\n",
    "\n",
    "- Ensemble methods can significantly enhance model performance by leveraging the strengths of multiple classifiers, but may increase computational cost and reduce interpretability.\n",
    "\n",
    "- When working with time-sensitive data like legal rulings, it's crucial to consider the temporal nature of the data in both preprocessing and model evaluation stages.\n",
    "\n",
    "- Evaluation metrics should be chosen carefully based on the specific problem and domain; in this case, Matthews Correlation Coefficient (MCC) was emphasized for its effectiveness in imbalanced classification tasks.\n",
    "\n",
    "- Balancing model performance with interpretability and computational efficiency is a key consideration in practical machine learning applications, especially in sensitive domains like legal prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding The Natural Language Processing (NLP) Pipeline\n",
    "\n",
    "The NLP pipeline is a series of structured steps that help transform raw text into a format that machines can understand and use to make decisions or predictions. Here we explore each step for a complete understanding.\n",
    "\n",
    "## 1. Data Collection\n",
    "\n",
    "Data collection is the first and crucial step in the pipeline, where we gather raw text data from various sources. The quality and quantity of this data can significantly impact the effectiveness of your NLP model.\n",
    "\n",
    "## 2. Text Cleaning\n",
    "\n",
    "In this stage, we clean the collected data by removing noise such as HTML tags, emojis, punctuation marks, etc., which do not contribute to understanding the actual content. This cleaned-up data will improve the model's performance and save computational resources.\n",
    "\n",
    "## 3. Preprocessing\n",
    "\n",
    "Preprocessing involves transformation to ready the data for feature extraction, including tasks like tokenization (splitting text into words or phrases), stemming/lemmatization (reducing words to their base/root form), and removing stop words (common words like 'is', 'an', 'the' that don't carry much meaning).\n",
    "\n",
    "## 4. Feature Extraction\n",
    "\n",
    "This stage involves converting preprocessed data into a format that can be understood by machine learning algorithms. Techniques like Bag-of-Words or TF-IDF (Term Frequency-Inverse Document Frequency) are employed here to create numerical representations of the text.\n",
    "\n",
    "`The points above were already addressed on Notebook 4.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`During this class, we'll cover:`\n",
    "\n",
    "## 5. Modeling\n",
    "\n",
    "Once the features are extracted and in proper format, we use them to build and train our NLP model. Depending on the end-goal, different models can be used, like Naive Bayes for classification, or LSTM (Long Short Term Memory) for sequence prediction.\n",
    "\n",
    "## 6. Evaluation\n",
    "\n",
    "After the model has been trained, it must be evaluated to ascertain its performance. Metrics like precision, recall, accuracy, and F1-score are typically considered. Also, the model might be tested with new data to validate its performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "`What we won't cover in this class (I'll leave that to your MLOps professor):`\n",
    "\n",
    "## 7. Deployment\n",
    "\n",
    "Once satisfied with the model's performance, the next step is to deploy it for practical use. This can range from integrating within an existing system or application, to deploying on a server for production use.\n",
    "\n",
    "## 8. Maintenance and Monitoring\n",
    "\n",
    "Post-deployment, continuous monitoring is essential to ensure the model's performance doesn't degrade over time, due to changes in data patterns. Periodic retraining and tuning may be necessary to keep the model up-to-date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the BrCAD-5 Dataset\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "The dataset we're working with is a sample from the [BrCAD-5](https://www.kaggle.com/datasets/eliasjacob/brcad5), a comprehensive collection of legal rulings from Brazilian Federal Small Claims Courts (FSCC). This dataset was specifically curated for academic purposes, with the primary goal of developing AI models capable of predicting appeal outcomes within the jurisdiction of the 5th Regional Federal Court (TRF5).\n",
    "\n",
    "## Key Features of the Dataset\n",
    "\n",
    "- **Sample Size**: Our sample contains over 40,000 legal rulings, providing a robust foundation for analysis.\n",
    "- **Jurisdiction**: All cases are from the 5th Regional Federal Court (TRF5) jurisdiction in Brazil.\n",
    "- **Case Types**: The dataset includes rulings from both federal courts and appellate panels.\n",
    "\n",
    "## Dataset Structure\n",
    "\n",
    "The dataset is composed of three main columns:\n",
    "\n",
    "1. **`case_number`**: \n",
    "   - A unique identifier for each legal ruling\n",
    "   - Ensures each case can be distinctly referenced and tracked\n",
    "\n",
    "2. **`ruling_type`**: \n",
    "   - Indicates the type of legal ruling\n",
    "   - Two categories:\n",
    "     - ACÓRDÃO (Judgment): Typically refers to decisions made by appellate panels\n",
    "     - SENTENÇA (Sentence): Usually refers to decisions made by a single judge in a lower court\n",
    "\n",
    "3. **`outcome`**: \n",
    "   - Represents the result of the legal ruling\n",
    "   - Multiple possible outcomes:\n",
    "     - PROVIMENTO: Appeal granted\n",
    "     - PROVIMENTO PARCIAL: Appeal partially granted\n",
    "     - NÃO PROVIMENTO: Appeal denied\n",
    "     - IMPROCEDENTE: Claim dismissed\n",
    "     - PROCEDENTE: Claim upheld\n",
    "     - PARCIALMENTE PROCEDENTE: Claim partially upheld\n",
    "     - EXTINTO SEM MÉRITO: Case dismissed without judgment on merits\n",
    "     - HOMOLOGADA TRANSAÇÃO: Settlement agreement approved\n",
    "\n",
    "## Significance of the Dataset\n",
    "\n",
    "1. **AI in Legal Prediction**: This dataset serves as a valuable resource for developing machine learning models that can predict legal outcomes, potentially revolutionizing legal research and case preparation.\n",
    "\n",
    "2. **Understanding Brazilian Legal System**: It offers insights into the decision-making patterns within Brazilian Federal Small Claims Courts, which could be useful for comparative legal studies.\n",
    "\n",
    "3. **Natural Language Processing (NLP) Applications**: While not explicitly mentioned, such datasets often include text data that can be used for NLP tasks like legal document classification or summarization.\n",
    "\n",
    "## Considerations for Analysis\n",
    "\n",
    "- **Balanced Representation**: It's important to check if all outcome categories are adequately represented in the sample to ensure unbiased analysis.\n",
    "- **Temporal Aspects**: Consider whether the rulings span a specific time period, as legal trends may change over time.\n",
    "- **Contextual Factors**: While not provided in this dataset, factors like the judge's identity, case subject matter, or regional variations could be influential in outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our data.\n",
    "import pandas as pd\n",
    "\n",
    "df_texts = pd.read_parquet('data/brcad5/texts_sample.parquet.gz')\n",
    "df_meta = pd.read_parquet('data/brcad5/metadata_sample.parquet.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_number</th>\n",
       "      <th>text</th>\n",
       "      <th>outcome</th>\n",
       "      <th>ruling_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0515165-56.2018.4.05.8202</td>\n",
       "      <td>SENTENÇA I - RELATÓRIO Dispensada a feitura do...</td>\n",
       "      <td>IMPROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0506287-42.2018.4.05.8300</td>\n",
       "      <td>SENTENÇA I - RELATÓRIO Dispensado, nos termos ...</td>\n",
       "      <td>PARCIALMENTE PROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0513000-08.2019.4.05.8103</td>\n",
       "      <td>RECURSO INOMINADO CONTRA SENTENÇA DE EXTINÇÃO ...</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ACÓRDÃO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0503661-32.2018.4.05.8015</td>\n",
       "      <td>PROCESSO No 0503661-32.2018.4.05.8015 RECORREN...</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ACÓRDÃO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0516813-86.2018.4.05.8100</td>\n",
       "      <td>AMPARO SOCIAL (LOAS). REQUISITOS NÃO PREENCHID...</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ACÓRDÃO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  case_number  \\\n",
       "2   0515165-56.2018.4.05.8202   \n",
       "11  0506287-42.2018.4.05.8300   \n",
       "15  0513000-08.2019.4.05.8103   \n",
       "18  0503661-32.2018.4.05.8015   \n",
       "19  0516813-86.2018.4.05.8100   \n",
       "\n",
       "                                                 text  \\\n",
       "2   SENTENÇA I - RELATÓRIO Dispensada a feitura do...   \n",
       "11  SENTENÇA I - RELATÓRIO Dispensado, nos termos ...   \n",
       "15  RECURSO INOMINADO CONTRA SENTENÇA DE EXTINÇÃO ...   \n",
       "18  PROCESSO No 0503661-32.2018.4.05.8015 RECORREN...   \n",
       "19  AMPARO SOCIAL (LOAS). REQUISITOS NÃO PREENCHID...   \n",
       "\n",
       "                    outcome ruling_type  \n",
       "2              IMPROCEDENTE    SENTENÇA  \n",
       "11  PARCIALMENTE PROCEDENTE    SENTENÇA  \n",
       "15           NÃO PROVIMENTO     ACÓRDÃO  \n",
       "18           NÃO PROVIMENTO     ACÓRDÃO  \n",
       "19           NÃO PROVIMENTO     ACÓRDÃO  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ruling_type  outcome                \n",
       "ACÓRDÃO      NÃO PROVIMENTO             15581\n",
       "             PROVIMENTO                  3004\n",
       "             PROVIMENTO PARCIAL          1415\n",
       "SENTENÇA     IMPROCEDENTE               11550\n",
       "             PROCEDENTE                  5253\n",
       "             PARCIALMENTE PROCEDENTE     2403\n",
       "             EXTINTO SEM MÉRITO           791\n",
       "             HOMOLOGADA TRANSAÇÃO           3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_texts.groupby('ruling_type').outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_number</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>defendant_normalized</th>\n",
       "      <th>date_first_instance_ruling</th>\n",
       "      <th>date_appeal_panel_ruling</th>\n",
       "      <th>case_topic_code</th>\n",
       "      <th>case_topic_1st_level</th>\n",
       "      <th>case_topic_2nd_level</th>\n",
       "      <th>case_topic_3rd_level</th>\n",
       "      <th>court_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0510491-75.2017.4.05.8103</td>\n",
       "      <td>2017-10-11 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2018-01-16 11:16:19</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>6095</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Aposentadoria por Invalidez</td>\n",
       "      <td>19-CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0509917-52.2017.4.05.8103</td>\n",
       "      <td>2017-09-26 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2018-01-15 18:07:55</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>6101</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Auxílio-Doença Previdenciário</td>\n",
       "      <td>31-CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0501051-55.2017.4.05.8103</td>\n",
       "      <td>2017-02-03 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2017-11-21 11:44:40</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>6103</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Salário-Maternidade (Art. 71/73)</td>\n",
       "      <td>31-CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0511681-76.2017.4.05.8102</td>\n",
       "      <td>2017-09-27 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2017-12-29 02:18:24</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>6104</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Pensão por Morte (Art. 74/9)</td>\n",
       "      <td>30-CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0500777-79.2017.4.05.8107</td>\n",
       "      <td>2017-02-23 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2017-11-27 17:58:46</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>6103</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Salário-Maternidade (Art. 71/73)</td>\n",
       "      <td>25-CE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  case_number          filing_date defendant_normalized  \\\n",
       "11  0510491-75.2017.4.05.8103  2017-10-11 00:00:00                 INSS   \n",
       "16  0509917-52.2017.4.05.8103  2017-09-26 00:00:00                 INSS   \n",
       "19  0501051-55.2017.4.05.8103  2017-02-03 00:00:00                 INSS   \n",
       "23  0511681-76.2017.4.05.8102  2017-09-27 00:00:00                 INSS   \n",
       "33  0500777-79.2017.4.05.8107  2017-02-23 00:00:00                 INSS   \n",
       "\n",
       "   date_first_instance_ruling date_appeal_panel_ruling  case_topic_code  \\\n",
       "11        2018-01-16 11:16:19      2018-03-26 17:07:16             6095   \n",
       "16        2018-01-15 18:07:55      2018-03-26 17:07:16             6101   \n",
       "19        2017-11-21 11:44:40      2018-03-26 17:07:16             6103   \n",
       "23        2017-12-29 02:18:24      2018-03-26 17:07:16             6104   \n",
       "33        2017-11-27 17:58:46      2018-03-26 17:07:16             6103   \n",
       "\n",
       "      case_topic_1st_level   case_topic_2nd_level  \\\n",
       "11  Direito Previdenciário  Benefícios em Espécie   \n",
       "16  Direito Previdenciário  Benefícios em Espécie   \n",
       "19  Direito Previdenciário  Benefícios em Espécie   \n",
       "23  Direito Previdenciário  Benefícios em Espécie   \n",
       "33  Direito Previdenciário  Benefícios em Espécie   \n",
       "\n",
       "                case_topic_3rd_level court_id  \n",
       "11       Aposentadoria por Invalidez    19-CE  \n",
       "16     Auxílio-Doença Previdenciário    31-CE  \n",
       "19  Salário-Maternidade (Art. 71/73)    31-CE  \n",
       "23      Pensão por Morte (Art. 74/9)    30-CE  \n",
       "33  Salário-Maternidade (Art. 71/73)    25-CE  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case_number', 'filing_date', 'defendant_normalized',\n",
       "       'date_first_instance_ruling', 'date_appeal_panel_ruling',\n",
       "       'case_topic_code', 'case_topic_1st_level', 'case_topic_2nd_level',\n",
       "       'case_topic_3rd_level', 'court_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case_number', 'text', 'outcome', 'ruling_type'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_texts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_texts.case_number.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Next Steps\n",
    "\n",
    "As we proceed with our analysis, we'll need to:\n",
    "1. Load the data into our working environment\n",
    "2. Perform initial exploratory data analysis to understand the distribution of ruling types and outcomes\n",
    "3. Consider any necessary data preprocessing steps, such as handling missing values or encoding categorical variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement 1 - Classifying \"Acórdãos\"\n",
    "\n",
    "When a legal case is adjudicated by a judge, the involved parties have the option to appeal the decision to a higher court. This appellate court then reviews the case and issues a document called an **\"Acórdão\"**. The \"Acórdão\" details the court's decision and the reasoning behind it, playing a crucial role in the judicial process. \n",
    "\n",
    "### Purpose and Importance of \"Acórdãos\"\n",
    "\n",
    "The \"Acórdão\" can either:\n",
    "- **Uphold** the original decision made by the lower court.\n",
    "- **Overturn** the decision, leading to a different outcome.\n",
    "\n",
    "These documents are invaluable for understanding the application of laws in various contexts. They offer insights into:\n",
    "- **Judicial reasoning**: How judges interpret and apply the law.\n",
    "- **Legal precedents**: Past decisions that influence future cases.\n",
    "\n",
    "### Challenges in Analyzing \"Acórdãos\"\n",
    "\n",
    "Despite their importance, \"Acórdãos\" are written in natural language, which poses challenges for systematic analysis:\n",
    "1. **Complexity of Legal Language**: Legal terminology and reasoning can be intricate and difficult to parse for those without legal training.\n",
    "2. **Volume of Data**: The sheer number of \"Acórdãos\" can be overwhelming, making manual analysis impractical.\n",
    "\n",
    "To address these challenges, automated classification techniques can be employed to categorize and extract meaningful insights from these documents. By training machine learning models on labeled \"Acórdãos,\" we can develop systems that classify the outcome of an appeal based on the content of the document.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement 2 - Predicting the Time to Issue an \"Acórdão\"\n",
    "\n",
    "Once a case has been tried by a judge, the appellate court issues the \"Acórdão\" after a certain period. The duration between the initial trial and the issuance of the \"Acórdão\" can vary significantly, ranging from a few days to several months.\n",
    "\n",
    "### Implications of the Time Frame\n",
    "\n",
    "The time it takes to issue an \"Acórdão\" has significant implications for the parties involved:\n",
    "- **Closure**: If the \"Acórdão\" supports the original decision, parties can find closure and move forward.\n",
    "- **Uncertainty**: If the \"Acórdão\" overrules the initial decision, the parties may face prolonged uncertainty, potentially lasting months or years.\n",
    "\n",
    "### Calculating the Time Frame\n",
    "\n",
    "In the dataset, the time it takes to issue the \"Acórdão\" can be derived by calculating the difference between two columns:\n",
    "- `date_first_instance_ruling`: The date when the initial trial decision was made.\n",
    "- `date_appeal_panel_ruling`: The date when the appellate court issued the \"Acórdão\".\n",
    "\n",
    "This calculation will provide an accurate representation of the time duration between the trial and the issuance of the \"Acórdão\".\n",
    "\n",
    "> **Note**: When developing predictive models, it is essential to use only the data available at the time of prediction. Therefore, the `date_appeal_panel_ruling` column cannot be used as an input for the model since it is only available after the trial is completed. This prevents data leakage and ensures the model's practical utility.\n",
    "\n",
    "### Potential Predictive Features\n",
    "\n",
    "To predict the duration between the trial and the issuance of the \"Acórdão,\" consider using features available at the time of the initial trial, such as:\n",
    "- **Case characteristics**: Type of case, complexity, involved parties.\n",
    "- **Court attributes**: Location, workload, historical averages.\n",
    "- **Judge information**: Identity, workload, historical performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - Classifying \"Acórdãos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 4 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   case_number               20000 non-null  object        \n",
      " 1   text                      20000 non-null  object        \n",
      " 2   outcome                   20000 non-null  object        \n",
      " 3   date_appeal_panel_ruling  20000 non-null  datetime64[us]\n",
      "dtypes: datetime64[us](1), object(3)\n",
      "memory usage: 625.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Filter the dataframe to include only rows where the ruling type is \"ACÓRDÃO\"\n",
    "# Select only the columns 'case_number', 'text', and 'outcome'\n",
    "df = df_texts.query('ruling_type == \"ACÓRDÃO\"')[['case_number', 'text', 'outcome']].copy()\n",
    "\n",
    "# Merge the filtered dataframe with another dataframe containing metadata\n",
    "# Specifically, we are adding the 'date_appeal_panel_ruling' column based on 'case_number'\n",
    "df = df.merge(df_meta[['case_number', 'date_appeal_panel_ruling']], on='case_number', how='left')\n",
    "\n",
    "# Display the summary information of the resulting dataframe\n",
    "# This includes the number of entries, column names, non-null counts, and data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome\n",
       "NÃO PROVIMENTO        0.77905\n",
       "PROVIMENTO            0.15020\n",
       "PROVIMENTO PARCIAL    0.07075\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.outcome.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome_int\n",
       "0    15581\n",
       "1     3004\n",
       "2     1415\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the 'outcome' column to a categorical type and then to integer codes\n",
    "# This is useful for machine learning models that require numerical input\n",
    "df['outcome_int'] = df.outcome.astype('category').cat.codes\n",
    "\n",
    "# Display the count of each unique integer code in the 'outcome_int' column\n",
    "# This helps to understand the distribution of different outcomes in the dataset\n",
    "df.outcome_int.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Split the data into training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 5), (2000, 5), (2000, 5))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataframe into training and testing sets\n",
    "# Use stratified sampling based on the 'outcome' column to ensure balanced classes\n",
    "# Set aside 20% of the data for testing\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=271828, stratify=df.outcome)\n",
    "\n",
    "# Further split the testing set into validation and testing sets\n",
    "# Use stratified sampling based on the 'outcome' column to ensure balanced classes\n",
    "# Set aside 50% of the testing set for validation, resulting in 10% of the original data\n",
    "df_test, df_val = train_test_split(df_test, test_size=0.5, random_state=271828, stratify=df_test.outcome)\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "# This helps to verify the sizes of the training, testing, and validation sets\n",
    "df_train.shape, df_test.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Importance of Proper Data Splitting in Legal Ruling Analysis\n",
    "\n",
    "When working with datasets containing legal rulings, it's crucial to recognize the inherent temporal nature of the data. Legal cases and their corresponding rulings typically follow a chronological order, often organized by case number or date. This temporal aspect introduces unique challenges and considerations for data analysis and model training.\n",
    "\n",
    "### Pitfalls of Random Data Splitting\n",
    "\n",
    "Randomly splitting legal ruling data can lead to several significant issues:\n",
    "\n",
    "1. **Temporal Leakage**: This is the primary concern when randomly splitting time-ordered data. Temporal leakage occurs when a model is inadvertently trained on future information, leading to:\n",
    "   - Overly optimistic performance estimates\n",
    "   - Models that fail to generalize well to truly unseen data\n",
    "   - Unrealistic predictions based on future knowledge\n",
    "\n",
    "2. **Disruption of Legal Precedent**: Legal systems often rely on precedent, where earlier rulings influence later ones. Random splitting can break these important temporal relationships.\n",
    "\n",
    "3. **Misrepresentation of Legal Trends**: Laws and their interpretations evolve over time. Random splitting may obscure these trends, leading to a model that doesn't accurately capture the current legal landscape.\n",
    "\n",
    "### Best Practices for Splitting Legal Ruling Data\n",
    "\n",
    "To address these challenges, consider the following approach:\n",
    "\n",
    "1. **Chronological Splitting**: Divide the dataset based on the date of the rulings:\n",
    "   - Training Set: Earlier rulings\n",
    "   - Validation Set: Intermediate rulings\n",
    "   - Test Set: Most recent rulings\n",
    "\n",
    "2. **Preserving Temporal Order**: This method maintains the natural progression of legal precedents and trends.\n",
    "\n",
    "3. **Realistic Model Evaluation**: By testing on the most recent data, you can better assess how well your model will perform on truly future cases.\n",
    "\n",
    "### Benefits of Proper Data Splitting\n",
    "\n",
    "1. **Improved Model Generalization**: Your model learns from historical patterns and is tested on more recent, unseen data, better mimicking real-world applications.\n",
    "\n",
    "2. **Accurate Performance Assessment**: Evaluating on chronologically later data provides a more realistic measure of model performance.\n",
    "\n",
    "\n",
    "### Considerations for Implementation\n",
    "\n",
    "- **Time Window Selection**: Carefully consider the time spans for each split to ensure sufficient data in each set while maintaining temporal integrity.\n",
    "- **Handling Landmark Cases**: Be aware of significant legal changes or landmark cases that might dramatically shift legal interpretations.\n",
    "- **Regular Retraining**: In rapidly evolving legal areas, consider implementing a system for regular model retraining with the most up-to-date data.\n",
    "\n",
    "> **Key Takeaway**: In the analysis of legal rulings, chronological data splitting is not just a best practice—it's essential for creating reliable, ethical, and practically applicable models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 5), (2000, 5), (2000, 5))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of rows for the training set (80% of the total dataframe length)\n",
    "train_length = int(0.8 * len(df))\n",
    "\n",
    "# Calculate the number of rows for the validation set (10% of the total dataframe length)\n",
    "validation_length = int(0.1 * len(df))\n",
    "\n",
    "# Sort the dataframe by the 'date_appeal_panel_ruling' column in ascending order\n",
    "# This ensures that the data is split chronologically, which can be important for time series data\n",
    "df = df.sort_values(by='date_appeal_panel_ruling', ascending=True)\n",
    "\n",
    "# Split the dataframe into training, validation, and testing sets based on the calculated lengths\n",
    "# The training set includes the first 80% of the rows\n",
    "df_train = df.iloc[:train_length].copy()\n",
    "\n",
    "# The validation set includes the next 10% of the rows\n",
    "df_val = df.iloc[train_length:train_length + validation_length].copy()\n",
    "\n",
    "# The testing set includes the remaining 10% of the rows\n",
    "df_test = df.iloc[train_length + validation_length:].copy()\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "# This helps to verify the sizes of the training, validation, and testing sets\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2018-03-26 17:02:45'), Timestamp('2019-09-30 17:20:24'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.date_appeal_panel_ruling.min(), df_train.date_appeal_panel_ruling.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2019-09-30 17:20:24'), Timestamp('2019-12-11 14:57:02'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.date_appeal_panel_ruling.min(), df_val.date_appeal_panel_ruling.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2019-12-11 14:57:02'), Timestamp('2020-04-01 11:24:06'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.date_appeal_panel_ruling.min(), df_test.date_appeal_panel_ruling.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Text Processing and vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary functions from the 'helpers.text' module\n",
    "from helpers.text import remove_accented_characters, remove_numbers_punctuation_from_text, remove_excessive_spaces, remove_short_words\n",
    "\n",
    "# Apply the cleaning functions to the 'text' column of each dataframe\n",
    "for dataframe in [df_train, df_val, df_test]:\n",
    "    dataframe['clean_text'] = dataframe.text.apply(remove_accented_characters)\n",
    "    dataframe['clean_text'] = dataframe.clean_text.apply(remove_numbers_punctuation_from_text)\n",
    "    dataframe['clean_text'] = dataframe.clean_text.apply(remove_excessive_spaces)\n",
    "    dataframe['clean_text'] = dataframe.clean_text.apply(remove_short_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RELATORIO Trata recurso interposto pela parte autora face sentenca que julgou improcedente pedido reajuste beneficio com base Indice Precos Consumidor Terceira Idade IPC Instituto Brasileiro Economia Fundacao Getulio Vargas FGV IBRE substituicao Indice Nacional Precos Consumidor INPC Instituto Brasileiro Geografia Estatistica IBGE alegando que este indice aplicado pelo INSS nao preservaria carater permanente valor real dos beneficios previdenciarios que afrontaria comando art VOTO Conforme bem fundamenta sentenca recorrida preservacao valor real dos beneficios assegurada pela aplicacao dos indices estabelecidos pela propria legislacao previdenciaria nao cabendo poder judiciario substituir indice eleito pelo legislador fato forma indices reajustes que devem ser aplicados aos beneficios previdenciarios concedidos apos sao aqueles estabelecidos pela Lei uma vez que Carta Magna remeteu legislador ordinario definicao dos indices serem aplicados aos reajustes dos beneficios para preservacao seu valor real art paragrafo redacao dada pela antigo art paragrafo com identico teor Limita Previdencia Social aplicar legislacao vigor suposta defasagem alegada pela apelante nao decorreu criterio administrativo que procurasse diminuir despesas com custeio dos beneficios Sendo assim correcao possivel injustica escapa aos limites controle Poder Judiciario que pode agir apenas como legislador negativo nao lhe sendo permitido editar dispositivo legal que possa restituir aos beneficiarios diferencas que decorreram exclusivamente aplicacao indices previstos nas proprias normas previdenciarias Desse modo evidencia que preservacao valor real dos beneficios previdenciarios assegurada pela aplicacao dos indices estabelecidos pela propria legislacao previdenciaria seja INPC IRSM IPC IGP outros previstos ordenamento juridico TRF DJE Data Pagina Nesse mesmo sentido Supremo Tribunal Federal julgamento firmou entendimento que criterio reajuste dos beneficios previdenciarios forma preservar lhes valor real art definido pelo legislador ordinario que restou concretizado com Lei sendo vedado reajustamento com base outros criterios Assim analisando atentamente sentenca recorrida constata que Juizo quo formou seu convencimento luz uma analise adequada dos fatos aplicando corretamente normas regencia Por tal razao deve julgado ser mantido todos seus termos pelos proprios fundamentos forma prevista art Lei Tem por expressamente prequestionadas todas questoes constitucionais suscitadas uma vez que para fins prequestionamento desnecessaria indicacao expressa artigos paragrafos Constituicao Federal afigurando suficiente sejam regras neles contidas fundamento decisum objeto discussao como caso ora sob exame AgR Relator Min GILMAR MENDES Segunda Turma Ante exposto NEGO PROVIMENTO recurso para confirmar sentenca que julgou improcedente pedido formulado inicial Condenacao recorrente honorarios advocaticios fixados dez por cento sobre valor corrigido causa art Lei suspensa execucao desta parcela enquanto litigar sob palio gratuidade judiciaria ACORDAO Decide Segunda Turma Recursal Secao Judiciaria Ceara unanimidade negar provimento recurso nos termos voto relator manifestacoes gravadas Participaram julgamento Exmos Srs Juizes Federais Gustavo Melo Barbosa Paula Emilia Moura Aragao Sousa Brasil Dartanhan Vercingetorix Araujo Rocha Fortaleza GUSTAVO MELO BARBOSA JUIZ FEDERAL RELATORIA'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[0]['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load Portuguese stopwords from NLTK\n",
    "stopwords_nltk = stopwords.words('portuguese')\n",
    "\n",
    "# Create a TF-IDF vectorizer with specific parameters:\n",
    "# - stop_words: remove common Portuguese stopwords\n",
    "# - max_features: limit the number of features to 1000\n",
    "# - ngram_range: consider unigrams and bigrams\n",
    "# - min_df: ignore terms that appear in fewer than 5 documents\n",
    "# - max_df: ignore terms that appear in more than 80% of documents\n",
    "# - lowercase: convert all text to lowercase\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=stopwords_nltk, \n",
    "    max_features=1000, \n",
    "    ngram_range=(1, 2), \n",
    "    min_df=5, \n",
    "    max_df=0.8, \n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "# Fit the vectorizer using only the training data\n",
    "# This ensures that the model does not have access to the validation or test data during training\n",
    "vectorizer.fit(df_train.clean_text)\n",
    "\n",
    "# Transform the text data into TF-IDF vectors\n",
    "# This converts the text data into numerical form suitable for machine learning models\n",
    "X_train = vectorizer.transform(df_train.clean_text)\n",
    "X_val = vectorizer.transform(df_val.clean_text)\n",
    "X_test = vectorizer.transform(df_test.clean_text)\n",
    "\n",
    "# Extract the target labels for training, validation, and testing sets\n",
    "# These labels will be used to train and evaluate the machine learning model\n",
    "y_train = df_train.outcome_int\n",
    "y_val = df_val.outcome_int\n",
    "y_test = df_test.outcome_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>outcome_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13171</th>\n",
       "      <td>EMENTA PREVIDENCIARIO AUXILIO DOENCA LAUDO DES...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3344</th>\n",
       "      <td>EMENTA PREVIDENCIARIO BENEFICIO ASSISTENCIAL L...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>VOTO Dispensado relatorio nos termos art Lei a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17639</th>\n",
       "      <td>PROCESSO EMENTA PROCESSO CIVIL ASSISTENCIA SOC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17063</th>\n",
       "      <td>PROCESSO EMENTA ADMINISTRATIVO SERVIDOR PUBLIC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15959</th>\n",
       "      <td>EMENTA PREVIDENCIARIO AUXILIO DOENCA APOSENTAD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>RECURSO INOMINADO DIREITO PREVIDENCIARIO PEDID...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4637</th>\n",
       "      <td>RECURSO INOMINADO DIREITO ADMINISTRATIVO SEGUR...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19977</th>\n",
       "      <td>VOTO EMENTA PREVIDENCIARIO BENEFICIO PREVIDENC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>PROCESSO RECORRENTE MARIA LOURDES CONCEICAO RE...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_text  outcome_int\n",
       "13171  EMENTA PREVIDENCIARIO AUXILIO DOENCA LAUDO DES...            1\n",
       "3344   EMENTA PREVIDENCIARIO BENEFICIO ASSISTENCIAL L...            0\n",
       "2508   VOTO Dispensado relatorio nos termos art Lei a...            0\n",
       "17639  PROCESSO EMENTA PROCESSO CIVIL ASSISTENCIA SOC...            0\n",
       "17063  PROCESSO EMENTA ADMINISTRATIVO SERVIDOR PUBLIC...            0\n",
       "15959  EMENTA PREVIDENCIARIO AUXILIO DOENCA APOSENTAD...            0\n",
       "668    RECURSO INOMINADO DIREITO PREVIDENCIARIO PEDID...            0\n",
       "4637   RECURSO INOMINADO DIREITO ADMINISTRATIVO SEGUR...            1\n",
       "19977  VOTO EMENTA PREVIDENCIARIO BENEFICIO PREVIDENC...            0\n",
       "1950   PROCESSO RECORRENTE MARIA LOURDES CONCEICAO RE...            0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['clean_text', 'outcome_int']].sample(10, random_state=271828)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 1000), (2000, 1000), (2000, 1000))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000,), (2000,), (2000,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 244 stored elements and shape (1, 1000)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.toarray()\n",
    "X_val = X_val.toarray()\n",
    "X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.05059559, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.0465296 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0376958 , 0.        ,\n",
       "       0.02821556, 0.03924224, 0.04661888, 0.04740649, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.04219101, 0.04322569,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.05352028, 0.        ,\n",
       "       0.03443451, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.03712143, 0.04413272, 0.        , 0.        ,\n",
       "       0.        , 0.03417699, 0.        , 0.12682283, 0.05464034,\n",
       "       0.        , 0.04136232, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.044617  , 0.04745553, 0.        ,\n",
       "       0.05451618, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05227756,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.09059519, 0.        , 0.03219794,\n",
       "       0.        , 0.0246106 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.33517606, 0.06283665, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.05406567, 0.        , 0.        ,\n",
       "       0.        , 0.06429373, 0.        , 0.        , 0.        ,\n",
       "       0.04702323, 0.        , 0.03097571, 0.04962608, 0.0404588 ,\n",
       "       0.04128996, 0.0328678 , 0.03925528, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0299464 , 0.05591626,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02944388, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.05533349, 0.04347378, 0.04735268, 0.        , 0.03589797,\n",
       "       0.03724208, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.04559522, 0.04742119, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.0493922 , 0.        , 0.04427468, 0.        ,\n",
       "       0.05531895, 0.05426459, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.12709299, 0.05378103, 0.        , 0.        ,\n",
       "       0.        , 0.04390106, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.040228  , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.04587916, 0.0474408 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.04406625, 0.0474408 , 0.        , 0.        , 0.        ,\n",
       "       0.04701843, 0.05456323, 0.03916088, 0.        , 0.        ,\n",
       "       0.        , 0.02735704, 0.04705208, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03435256, 0.03592006,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04458293, 0.04742119, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.06040159, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.0382157 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.04731852,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.04512636, 0.        ,\n",
       "       0.03574673, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.03388275,\n",
       "       0.04740649, 0.04882179, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.04361925, 0.0449176 ,\n",
       "       0.        , 0.        , 0.03571935, 0.05289896, 0.04246481,\n",
       "       0.04740649, 0.04107803, 0.04730877, 0.        , 0.0339628 ,\n",
       "       0.03884511, 0.        , 0.        , 0.        , 0.03843689,\n",
       "       0.        , 0.04601123, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.02544722, 0.        , 0.        , 0.04740159,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.03212691,\n",
       "       0.04516575, 0.05356683, 0.        , 0.        , 0.        ,\n",
       "       0.03530776, 0.04837479, 0.        , 0.08468056, 0.        ,\n",
       "       0.04108875, 0.        , 0.        , 0.        , 0.03744081,\n",
       "       0.04743099, 0.03508917, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.04559075, 0.04566695,\n",
       "       0.        , 0.04269587, 0.04885861, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.02824381, 0.04343758,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07136763, 0.07911548, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.04291395, 0.04734292,\n",
       "       0.19713738, 0.        , 0.29932971, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.04286702,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.11732665, 0.03549626, 0.11204264, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.0314743 , 0.04252233, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.05756893, 0.1128022 , 0.06816717, 0.03297966, 0.04612119,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.03124095,\n",
       "       0.04130803, 0.        , 0.03292484, 0.05575968, 0.        ,\n",
       "       0.02936998, 0.        , 0.        , 0.        , 0.04365985,\n",
       "       0.05814232, 0.0796423 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.04546586,\n",
       "       0.14345159, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.049081  , 0.        , 0.        , 0.0561345 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.08924252, 0.        , 0.        , 0.04539484, 0.04793251,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03360261, 0.04977434,\n",
       "       0.        , 0.        , 0.        , 0.03813222, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03967402, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.02834964,\n",
       "       0.02885624, 0.04623175, 0.04654367, 0.        , 0.04735268,\n",
       "       0.04743099, 0.04142766, 0.05184519, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.10054191,\n",
       "       0.        , 0.        , 0.        , 0.04109233, 0.04736734,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03658304, 0.04717275,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07978351, 0.        , 0.        , 0.        ,\n",
       "       0.09539514, 0.04589278, 0.04747518, 0.        , 0.        ,\n",
       "       0.06098081, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04236932, 0.04271525, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.04997372, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.05495893, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.03562382,\n",
       "       0.        , 0.        , 0.1085154 , 0.12097201, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.04396697, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04727468, 0.04733803, 0.04348989,\n",
       "       0.04748993, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05400433,\n",
       "       0.05586393, 0.10274828, 0.        , 0.        , 0.        ,\n",
       "       0.25453707, 0.        , 0.04776727, 0.05330884, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.08484548, 0.        , 0.03798773,\n",
       "       0.03873989, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.04399588,\n",
       "       0.04736246, 0.05166876, 0.02993614, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.02539155, 0.0520973 ,\n",
       "       0.        , 0.08137054, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.04096046, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04443455, 0.        , 0.03603646,\n",
       "       0.        , 0.04592915, 0.05031054, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05384168,\n",
       "       0.        , 0.        , 0.        , 0.04170223, 0.04747518,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.0512006 , 0.03794795, 0.        ,\n",
       "       0.        , 0.04975781, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.0476926 , 0.        , 0.05818834, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03702485, 0.        , 0.03038618, 0.03284171, 0.        ,\n",
       "       0.        , 0.        , 0.07300076, 0.07485778, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.0868961 , 0.        , 0.06242942, 0.        ,\n",
       "       0.08673873, 0.        , 0.03570841, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.05779808, 0.04641272, 0.02544066, 0.03106446,\n",
       "       0.        , 0.03645776, 0.        , 0.        , 0.04261084,\n",
       "       0.04351408, 0.        , 0.        , 0.        , 0.06963947,\n",
       "       0.06711995, 0.03441912, 0.04746044, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.04801817, 0.04813465, 0.04713406, 0.04752931, 0.03941252,\n",
       "       0.        , 0.03429387, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.04553713, 0.        , 0.        , 0.05331541, 0.        ,\n",
       "       0.        , 0.        , 0.02849227, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.03815074, 0.04733803, 0.        ,\n",
       "       0.        , 0.03504415, 0.05122547, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03110137, 0.03687939, 0.        , 0.        , 0.        ,\n",
       "       0.06407899, 0.0379663 , 0.04808899, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.03139695, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.15181088, 0.        ,\n",
       "       0.        , 0.        , 0.06515272, 0.        , 0.        ,\n",
       "       0.        , 0.05557078, 0.04733803, 0.        , 0.        ,\n",
       "       0.        , 0.06348092, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03302745, 0.        ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['incapacidade', 'beneficio', 'doenca', 'auxilio', 'atividade',\n",
       "       'auxilio doenca', 'aposentadoria', 'segurado', 'laudo',\n",
       "       'concessao', 'prova', 'especial', 'rural', 'fgts', 'anexo',\n",
       "       'autor', 'monetaria', 'inss', 'periodo', 'pericial', 'invalidez',\n",
       "       'correcao', 'trabalho', 'anos', 'tempo', 'aposentadoria invalidez',\n",
       "       'social', 'prazo', 'carencia', 'direito'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_top_ngrams(X_train: np.ndarray, vectorizer: TfidfVectorizer, top_n: int = 30) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get the top n most frequent n-grams from the vectorized text data.\n",
    "\n",
    "    Args:\n",
    "        X_train (np.ndarray): The vectorized text data.\n",
    "        vectorizer (TfidfVectorizer): The vectorizer used to transform the text data.\n",
    "        top_n (int, optional): The number of top n-grams to return. Defaults to 30.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: An array of the top n most frequent n-grams.\n",
    "    \"\"\"\n",
    "    # Sum all the columns to get the total frequency of each n-gram\n",
    "    total_ngram_frequencies = np.sum(X_train, axis=0)\n",
    "\n",
    "    # Sort the n-grams by their total frequency\n",
    "    sorted_ngrams_indices = np.argsort(total_ngram_frequencies)[::-1]\n",
    "\n",
    "    # Get the indices of the top n most frequent n-grams\n",
    "    top_ngrams_indices = sorted_ngrams_indices[:top_n]\n",
    "\n",
    "    # Get the names of the n-grams corresponding to the top n indices\n",
    "    ngram_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "    return ngram_names[top_ngrams_indices]\n",
    "\n",
    "# Use the function to get the top 30 n-grams from the training data\n",
    "top_ngrams = get_top_ngrams(X_train, vectorizer, top_n=30)\n",
    "top_ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Import various classifiers and utilities from scikit-learn and other libraries\n",
    "\n",
    "# LightGBM classifier, a gradient boosting framework that uses tree-based learning algorithms\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# CalibratedClassifierCV for probability calibration of classifiers\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Ensemble classifiers from scikit-learn\n",
    "# ExtraTreesClassifier and RandomForestClassifier are ensemble methods that use multiple decision trees\n",
    "# StackingClassifier allows combining multiple classifiers to improve performance\n",
    "from sklearn.ensemble import (ExtraTreesClassifier, RandomForestClassifier, StackingClassifier)\n",
    "\n",
    "# Linear models from scikit-learn\n",
    "# LogisticRegression is a linear model for binary classification\n",
    "# SGDClassifier is a linear classifier using stochastic gradient descent\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "\n",
    "# Metrics for evaluating classification performance\n",
    "# accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix, f1_score, matthews_corrcoef\n",
    "from sklearn.metrics import (accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix, f1_score, matthews_corrcoef)\n",
    "\n",
    "# Naive Bayes classifier for multinomially distributed data\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# K-Nearest Neighbors classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Neural network-based classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Support Vector Machine classifiers\n",
    "# SVC is a support vector classifier with a non-linear kernel\n",
    "# LinearSVC is a support vector classifier with a linear kernel\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "# Decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# XGBoost classifier, an optimized distributed gradient boosting library\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Guide to Classifiers\n",
    "\n",
    "This section provides a systematic and detailed explanation of various classifiers commonly used in machine learning, focusing on their working principles and typical use cases. \n",
    "\n",
    "#### 1. Calibrated-LSVC: CalibratedClassifierCV with LinearSVC\n",
    "\n",
    "* **LinearSVC:** A linear Support Vector Machine (SVM) classifier that seeks to find the optimal hyperplane separating different classes in a high-dimensional space. This hyperplane maximizes the margin between data points belonging to different classes.\n",
    "\n",
    "* **CalibratedClassifierCV:** A method used to calibrate the output of classifiers that do not inherently provide well-calibrated probabilities.  Since `LinearSVC` primarily focuses on separating classes without directly estimating probabilities, `CalibratedClassifierCV` is employed to obtain more reliable probability estimates. This combination results in a calibrated SVM model.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/linear_svm.png\" alt=\"\" style=\"width: 40%; height: 40%\"/>\n",
    "</p>\n",
    "\n",
    "#### 2. LR: Logistic Regression \n",
    "\n",
    "Logistic Regression is a widely used classification algorithm that predicts the probability of an instance belonging to a particular class. Unlike its name might suggest, it's not used for regression but for classification tasks. Here's how it works:\n",
    "\n",
    "* **Logistic Function (Sigmoid):**  It utilizes a sigmoid function to map the output of a linear combination of input features to a probability value between 0 and 1. \n",
    "* **Decision Boundary:** Based on the calculated probability, the instance is assigned to the class with a probability greater than 0.5.  The point at which the probability equals 0.5 defines the decision boundary separating the classes.\n",
    "* **Use Cases:** Known for its simplicity and efficiency, Logistic Regression finds applications in various domains, especially in binary classification problems but also extendable to multi-class scenarios using techniques like one-vs-rest or softmax.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/logistic_regression.png\" alt=\"\" style=\"width: 40%; height: 40%\"/>\n",
    "</p>\n",
    "\n",
    "#### 3. RF: Random Forest Classifier\n",
    "\n",
    "Random Forest is a powerful ensemble learning method that operates by constructing a multitude of decision trees during training.\n",
    "\n",
    "* **Ensemble Approach:**  Instead of relying on a single decision tree, Random Forest leverages the power of multiple trees to make predictions. Each tree is trained on a different random subset of the training data (bootstrapping) and potentially a random subset of features. This randomness helps to reduce overfitting and improve generalization.\n",
    "* **Prediction:**  To classify a new instance, the Random Forest combines the predictions from all its individual trees. It employs a voting mechanism, where the class receiving the most votes from the trees is chosen as the final prediction. \n",
    "* **Advantages:** This ensemble approach results in a classifier that is more robust, accurate, and less prone to overfitting compared to individual decision trees.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/random_forest.png\" alt=\"\" style=\"width: 40%; height: 40%\"/>\n",
    "</p>\n",
    "\n",
    "#### 4. LGBM: Light Gradient Boosting Machine Classifier\n",
    "#### 5. XGB: XGBoost Classifier\n",
    "#### 13. CatBoost: CatBoost Classifier\n",
    "\n",
    "These three classifiers (LGBMClassifier, XGBClassifier, CatBoostClassifier) belong to the family of **gradient boosting algorithms** and share core principles while differing in specific implementation details and optimizations:\n",
    "\n",
    "* **Gradient Boosting Framework:** They are ensemble methods that sequentially build an ensemble of weak learners, typically decision trees, to create a strong classifier. Each tree attempts to correct the errors made by the previous trees.\n",
    "* **Tree-Based Learning:** These algorithms leverage tree-based learning algorithms, making them suitable for both numerical and categorical features. \n",
    "* **Efficiency and Scalability:** They are designed to be efficient and scalable, handling large datasets and high-dimensional feature spaces effectively.\n",
    "\n",
    "Here's a breakdown of their key characteristics:\n",
    "\n",
    "* **LGBM (LightGBM):** Prioritizes speed and memory efficiency. It uses a novel technique called Gradient-based One-Side Sampling (GOSS) and Exclusive Feature Bundling (EFB) to improve efficiency without sacrificing accuracy.\n",
    "* **XGBoost:**  Widely recognized for its speed and performance enhancements. It utilizes regularization techniques to prevent overfitting and leverages parallel processing for faster training.\n",
    "* **CatBoost:**  Specifically designed to handle categorical features effectively.  It incorporates a method called ordered boosting to reduce bias and employs symmetric trees to speed up prediction time. \n",
    "\n",
    "**Key Differences and Considerations:**\n",
    "\n",
    "* **Categorical Feature Handling:** CatBoost excels in handling categorical features.\n",
    "* **Speed and Scalability:** LightGBM is often favored for its speed and efficiency, especially for large datasets.\n",
    "* **Regularization and Overfitting:** XGBoost is known for its strong regularization techniques.\n",
    "\n",
    "The choice among these gradient boosting algorithms often depends on specific dataset characteristics, performance requirements, and the importance of handling categorical features.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/xgboost_lgbm.png\" alt=\"\" style=\"width: 40%; height: 40%\"/>\n",
    "</p>\n",
    "\n",
    "#### 6. MLP: Multi-Layer Perceptron Classifier\n",
    "\n",
    "* **Neural Network Structure:** The MLP is a type of feedforward artificial neural network, a biologically inspired computing model loosely based on the structure of the human brain. It consists of interconnected nodes (neurons) organized in layers: an input layer that receives the data, one or more hidden layers responsible for learning complex patterns, and an output layer producing the classification result.\n",
    "* **Non-Linear Activation Functions:** MLPs use non-linear activation functions (like sigmoid, ReLU) in the hidden layers. These functions introduce non-linearity, enabling the network to learn complex relationships between features that linear models might miss.  \n",
    "* **Backpropagation for Learning:** MLPs learn from data through a process called backpropagation. During training, the network adjusts its internal weights based on the difference between its predicted output and the actual target values, minimizing errors over time.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/mlp.png\" alt=\"\" style=\"width: 40%; height: 40%\"/>\n",
    "</p>\n",
    "\n",
    "#### 7. SGD: Stochastic Gradient Descent Classifier\n",
    "\n",
    "* **Linear Classifier:** SGDClassifier implements a linear classifier that finds the optimal hyperplane to separate different classes. \n",
    "* **Stochastic Gradient Descent (SGD):** The key difference lies in its optimization algorithm:  it employs Stochastic Gradient Descent (SGD) to learn from the data. Instead of updating weights based on the error calculated from the entire dataset (as in traditional gradient descent), SGD updates weights using the error from a single data point or a small batch of data. This makes SGD computationally less demanding, especially for large datasets.\n",
    "* **Flexibility in Loss Function and Regularization:** SGD offers flexibility. It can be used with different loss functions (like hinge loss for SVM-like behavior or log loss for logistic regression) and allows incorporating various regularization techniques (L1, L2) to prevent overfitting.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/sgd.png\" alt=\"\" style=\"width: 40%; height: 40%\"/>\n",
    "</p>\n",
    "\n",
    "#### 8. NB: Multinomial Naive Bayes\n",
    "\n",
    "* **Probabilistic Classifier:** Naive Bayes is a probabilistic classifier based on Bayes' theorem with a strong \"naive\" assumption of independence among features. This means it assumes that the presence or absence of a particular feature in a class is independent of the presence or absence of other features.\n",
    "* **Multinomial Variant:** The Multinomial Naive Bayes classifier is specifically designed to handle discrete features, making it well-suited for text classification tasks. \n",
    "    * **Text Classification Example:** Imagine classifying documents into categories like sports, politics, and entertainment. The presence of words like \"athlete,\" \"election,\" or \"movie\" can be strong indicators of the respective categories.  Each feature in this case might represent the frequency of occurrence of a specific word in the document. \n",
    "\n",
    "> The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work.\n",
    "\n",
    "#### 9. LSVC: Linear Support Vector Classification\n",
    "\n",
    "`LinearSVC`, like its counterpart `CalibratedClassifierCV(LinearSVC)`, implements a linear Support Vector Machine classifier. The core functionality remains identical—finding the optimal hyperplane in a high-dimensional space to separate data points belonging to different classes effectively.\n",
    "\n",
    "The primary distinction lies in probability prediction:\n",
    "\n",
    "* `LinearSVC`: Focuses solely on separating classes using a hyperplane and does not inherently provide probability estimates for predictions.\n",
    "* `CalibratedClassifierCV(LinearSVC)`: Combines `LinearSVC` with probability calibration, allowing it to provide probability estimates for class predictions. \n",
    "\n",
    "#### 10. KNN: K-Nearest Neighbors Classifier\n",
    "\n",
    "* **Instance-Based Learning:**  K-Nearest Neighbors (KNN) is a simple and intuitive algorithm that classifies new data points based on their proximity to known data points. It falls under the category of instance-based learning or lazy learning, where the algorithm doesn't explicitly learn a model from the training data but memorizes the training instances.\n",
    "* **Distance Metric:** KNN relies on a distance metric, commonly Euclidean distance, to determine closeness between data points in the feature space. \n",
    "* **\"K\" Parameter:** When classifying a new instance, KNN identifies the 'K' nearest neighbors to the instance in the feature space. The value of 'K' is a user-defined parameter.\n",
    "* **Majority Voting:** Once the 'K' nearest neighbors are identified, their class labels are used to classify the new instance. A majority voting scheme is employed, meaning that the new instance is assigned the class label that appears most frequently among its 'K' neighbors.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/knn.png\" alt=\"\" style=\"width: 40%; height: 40%\"/>\n",
    "</p>\n",
    "\n",
    "#### 11. DT: Decision Tree Classifier\n",
    "#### 12. ET: Extra Trees Classifier\n",
    "\n",
    "* **Tree-Based Classifiers:** Both Decision Tree and Extra Trees classifiers are tree-based methods that recursively partition the input space based on feature values to make predictions. Imagine a flowchart where each node represents a decision based on a specific feature.  The branches represent possible outcomes, ultimately leading to a leaf node that indicates the predicted class label.\n",
    "\n",
    "Let's differentiate these two:\n",
    "\n",
    "**Decision Tree:** \n",
    "    * **Greedy Splitting:**  It greedily searches for the best feature and threshold to split the data at each node. This search aims to maximize information gain or reduce impurity.\n",
    "    * **Prone to Overfitting:**  Without proper pruning or limitations, decision trees can become overly complex, memorizing the training data, which often results in overfitting.\n",
    "\n",
    "**Extra Trees (Extremely Randomized Trees):**\n",
    "    * **Random Subset of Features:** Like Random Forest, Extra Trees introduces randomization by selecting a random subset of features for splitting at each node.\n",
    "    * **Random Thresholds:**  It goes a step further by also randomly selecting the splitting thresholds for each feature.\n",
    "    * **Advantages:**  This additional randomness helps to reduce variance and prevent overfitting. It often results in faster training times compared to traditional decision trees.\n",
    "\n",
    "> While prone to overfitting, decision trees' performance can be significantly improved when used in ensemble methods like Random Forests.  Similarly, the randomization introduced in Extra Trees makes it suitable as a base estimator for ensemble methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Explanation\n",
    "\n",
    "Let's explore the key metrics used for evaluating classification models, including their mathematical formulas and Python code fragments. Understanding these metrics and their calculations will help you interpret your model's performance more effectively.\n",
    "\n",
    "#### 1. F1 Score\n",
    "```python\n",
    "f1 = f1_score(y, pred, average='micro')\n",
    "```\n",
    "The **F1 Score** is the harmonic mean of precision and recall. It provides a single metric that balances the trade-off between precision and recall, making it particularly useful when you need to consider both false positives and false negatives.\n",
    "\n",
    "- **Precision**: The ratio of correctly predicted positive observations to the total predicted positives.\n",
    "- **Recall**: The ratio of correctly predicted positive observations to all observations in the actual class.\n",
    "\n",
    "**Formula**:\n",
    "$$F1 = 2 \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}$$\n",
    "\n",
    "Where:\n",
    "- $\\text{precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$\n",
    "- $\\text{recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$\n",
    "\n",
    "TP = True Positives, FP = False Positives, FN = False Negatives\n",
    "\n",
    "**Range**: 0 to 1, where 1 is the best possible score.\n",
    "\n",
    "When using `average='micro'`, the F1 score is calculated globally by counting the total true positives, false negatives, and false positives across all classes.\n",
    "\n",
    "> **Note**: The F1 Score is especially useful in scenarios with imbalanced classes, where one class is significantly more frequent than others.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Balanced Accuracy\n",
    "```python\n",
    "bacc = balanced_accuracy_score(y, pred)\n",
    "```\n",
    "**Balanced Accuracy** is the average of recall obtained on each class. This metric is particularly effective for imbalanced datasets, where some classes are underrepresented.\n",
    "\n",
    "- **Recall (Sensitivity)**: The ability of the classifier to find all the positive samples.\n",
    "\n",
    "**Formula**:\n",
    "$$\\text{Balanced Accuracy} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{\\text{TP}_i}{\\text{TP}_i + \\text{FN}_i}$$\n",
    "\n",
    "Where $n$ is the number of classes, and $\\text{TP}_i$ and $\\text{FN}_i$ are the true positives and false negatives for class $i$, respectively.\n",
    "\n",
    "**Range**: 0 to 1, where 1 indicates perfect accuracy on all classes.\n",
    "\n",
    "> **Example**: In a medical diagnosis scenario, balanced accuracy helps ensure that the model performs well across both common and rare conditions.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Accuracy\n",
    "```python\n",
    "acc = accuracy_score(y, pred)\n",
    "```\n",
    "**Accuracy** measures the proportion of correct predictions out of the total number of samples. It is a straightforward metric but can be misleading in the presence of class imbalance.\n",
    "\n",
    "**Formula**:\n",
    "$$\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}$$\n",
    "\n",
    "Where TN = True Negatives\n",
    "\n",
    "**Range**: 0 to 1, where 1 means all predictions are correct.\n",
    "\n",
    "> **Important**: In datasets with imbalanced classes, accuracy might give an inflated sense of performance if the model is biased towards the majority class.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Classification Report\n",
    "```python\n",
    "cr = classification_report(y, pred)\n",
    "```\n",
    "The **Classification Report** provides a comprehensive summary of various classification metrics for each class, including:\n",
    "\n",
    "- **Precision**: How many selected items are relevant.\n",
    "- **Recall**: How many relevant items are selected.\n",
    "- **F1-Score**: The harmonic mean of precision and recall.\n",
    "- **Support**: The number of actual occurrences of the class in the dataset.\n",
    "\n",
    "The formulas for these metrics are:\n",
    "\n",
    "- **Precision**: $$\\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$$\n",
    "- **Recall**: $$\\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$$\n",
    "- **F1-Score**: $$2 \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}$$\n",
    "\n",
    "> **Usage**: This report is invaluable for gaining detailed insights into the performance of your model on a per-class basis, helping identify which classes are well-predicted and which are not.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. Matthews Correlation Coefficient (MCC)\n",
    "```python\n",
    "mcc = matthews_corrcoef(y, pred)\n",
    "```\n",
    "The **Matthews Correlation Coefficient (MCC)** is a measure of the quality of binary classifications. It takes into account true and false positives and negatives and is regarded as a balanced measure even with imbalanced classes.\n",
    "\n",
    "**Formula**:\n",
    "$$\\text{MCC} = \\frac{\\text{TP} \\cdot \\text{TN} - \\text{FP} \\cdot \\text{FN}}{\\sqrt{(\\text{TP}+\\text{FP})(\\text{TP}+\\text{FN})(\\text{TN}+\\text{FP})(\\text{TN}+\\text{FN})}}$$\n",
    "\n",
    "**Range**: -1 to 1, where 1 indicates perfect prediction, 0 no better than random prediction, and -1 total disagreement.\n",
    "\n",
    "> **Analogy**: Think of MCC as a correlation coefficient between the observed and predicted binary classifications. It provides a more informative and truthful score in scenarios where class imbalance is a concern.\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. Confusion Matrix\n",
    "```python\n",
    "cm = confusion_matrix(y, pred)\n",
    "```\n",
    "A **Confusion Matrix** is a table used to describe the performance of a classification model. It provides a breakdown of correct and incorrect predictions by each class.\n",
    "\n",
    "For a binary classification problem, it takes the form:\n",
    "\n",
    "|               | Predicted Positive | Predicted Negative |\n",
    "|---------------|--------------------|--------------------|\n",
    "| Actual Positive | TP                 | FN                 |\n",
    "| Actual Negative | FP                 | TN                 |\n",
    "\n",
    "From this matrix, various metrics can be derived:\n",
    "\n",
    "- **Sensitivity (Recall)**: $$\\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$$\n",
    "- **Specificity**: $$\\frac{\\text{TN}}{\\text{TN} + \\text{FP}}$$\n",
    "- **Precision**: $$\\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$$\n",
    "\n",
    "> **Visualization**: The confusion matrix helps visualize the performance of your model, making it easier to identify which classes are being misclassified.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodhart's Law and Classification Metrics: Balancing Numbers with Real-World Impact\n",
    "\n",
    "> \"When a measure becomes a target, it ceases to be a good measure.\" - Goodhart's Law\n",
    "\n",
    "#### The Essence of Goodhart's Law in Machine Learning\n",
    "\n",
    "Goodhart's Law, encapsulated in the quote above, is a critical concept in machine learning that reminds us to look beyond mere numbers. This principle is particularly relevant when interpreting and applying classification metrics, as it highlights the potential pitfalls of overly focusing on optimizing a single measure.\n",
    "\n",
    "#### Unpacking Classification Metrics\n",
    "\n",
    "Classification metrics are essential tools for quantifying model performance, but they should be understood as proxies for real-world outcomes rather than ends in themselves. Let's explore some key metrics and their implications:\n",
    "\n",
    "##### Accuracy: A Deceptive Simplicity\n",
    "\n",
    "**Accuracy** measures the proportion of correct predictions across all classes. While seemingly straightforward, it can be misleading, especially in imbalanced datasets. For instance:\n",
    "\n",
    "- In a dataset where 95% of samples belong to class A and 5% to class B, a model always predicting class A would achieve 95% accuracy without providing any valuable insights.\n",
    "- This metric fails to capture the nuances of misclassification costs, which can vary significantly in real-world scenarios.\n",
    "\n",
    "##### Precision and Recall: A Balancing Act\n",
    "\n",
    "**Precision** focuses on the accuracy of positive predictions, while **Recall** measures the model's ability to find all positive instances.\n",
    "\n",
    "- $\\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}$\n",
    "\n",
    "\n",
    "- $\\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}$\n",
    "\n",
    "These metrics are particularly useful when the costs of false positives and false negatives differ. For example:\n",
    "\n",
    "- In email spam detection, high precision is crucial to avoid marking important emails as spam (false positives).\n",
    "- In medical diagnosis, high recall is vital to ensure all potential cases of a severe condition are identified, even at the cost of some false alarms.\n",
    "\n",
    "##### F1-Score: Seeking Balance\n",
    "\n",
    "The **F1-score** provides a single metric that balances precision and recall: $F1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$\n",
    "\n",
    "This metric is particularly useful when you need a balanced measure of a model's performance, especially with imbalanced datasets.\n",
    "\n",
    "\n",
    "#### Beyond Metrics: The Real-World Perspective\n",
    "\n",
    "While metrics provide valuable insights, it's crucial to consider their real-world implications:\n",
    "\n",
    "1. **Context Matters**: The choice of metric should align with the specific problem and its real-world consequences. For instance, in fraud detection, the cost of missing a fraudulent transaction (false negative) might far outweigh the inconvenience of a false alarm (false positive).\n",
    "\n",
    "2. **Holistic Evaluation**: Rather than fixating on a single metric, consider a combination of measures that provide a more comprehensive view of model performance.\n",
    "\n",
    "3. **Ethical Considerations**: Metrics don't capture ethical implications or societal impacts. For example, a facial recognition system might have high accuracy but could perpetuate biases if not carefully designed and evaluated.\n",
    "\n",
    "4. **Interpretability**: Some models might achieve high metric scores but lack interpretability, which can be crucial in fields like healthcare or finance where understanding the decision-making process is essential.\n",
    "\n",
    "#### Practical Approaches to Metric Selection\n",
    "\n",
    "1. **Engage with Domain Experts**: Collaborate with subject matter experts to understand the real-world implications of model predictions and choose metrics accordingly.\n",
    "\n",
    "2. **Consider Multiple Metrics**: Use a combination of metrics to get a more comprehensive view of model performance.\n",
    "\n",
    "3. **Custom Metrics**: Develop problem-specific metrics that better align with the actual goals of your project.\n",
    "\n",
    "4. **Evaluate on Multiple Datasets**: Test your model on various datasets to ensure its performance is consistent and generalizable.\n",
    "\n",
    "5. **Monitor Real-World Performance**: Implement systems to track how well your model performs in actual deployments, not just on test sets.\n",
    "\n",
    "\n",
    "> Understanding Goodhart's Law in the context of classification metrics reminds us that our ultimate goal is to solve real-world problems, not just optimize numbers. While metrics are invaluable tools for model evaluation and improvement, they should guide our decisions rather than dictate them. By maintaining a holistic view that considers the broader impact and context of our models, we can develop more effective and responsible machine learning solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def calculate_evaluation_metrics(y_true: pd.Series, y_pred: pd.Series) -> Tuple[float, float, float, str, float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Calculate evaluation metrics for model predictions.\n",
    "\n",
    "    Args:\n",
    "        y_true (pd.Series): The true labels.\n",
    "        y_pred (pd.Series): The predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float, float, str, float, np.ndarray]: The calculated metrics including F1 score, balanced accuracy, accuracy, classification report, Matthews correlation coefficient, and confusion matrix.\n",
    "    \"\"\"\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_true, y_pred, average='micro')\n",
    "    # Calculate balanced accuracy\n",
    "    balanced_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # Generate classification report\n",
    "    classification_report_str = classification_report(y_true, y_pred)\n",
    "    # Calculate Matthews correlation coefficient\n",
    "    matthews_corr_coeff = matthews_corrcoef(y_true, y_pred)\n",
    "    # Generate confusion matrix\n",
    "    confusion_matrix_arr = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    return f1, balanced_accuracy, accuracy, classification_report_str, matthews_corr_coeff, confusion_matrix_arr\n",
    "\n",
    "def train_and_evaluate_models(X_train: pd.DataFrame, y_train: pd.Series, X_valid: pd.DataFrame, y_valid: pd.Series, n_jobs: int = -1) -> Tuple[pd.DataFrame, List[List]]:\n",
    "    \"\"\"\n",
    "    Train multiple models and evaluate their performance.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): The training data.\n",
    "        y_train (pd.Series): The training labels.\n",
    "        X_valid (pd.DataFrame): The validation data.\n",
    "        y_valid (pd.Series): The validation labels.\n",
    "        n_jobs (int, optional): The number of jobs to run in parallel. Defaults to -1.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, List[List]]: A dataframe of the evaluation results and a list of classification reports.\n",
    "    \"\"\"\n",
    "    # Define the models to be trained\n",
    "    models = [\n",
    "        ('Calibrated-LSVC', CalibratedClassifierCV(LinearSVC(random_state=271828, class_weight='balanced', dual='auto'))),\n",
    "        ('LR', LogisticRegression(random_state=271828, n_jobs=n_jobs, class_weight='balanced')),\n",
    "        ('RF', RandomForestClassifier(random_state=271828, n_jobs=n_jobs, class_weight='balanced')),\n",
    "        ('LGBM', LGBMClassifier(random_state=271828, n_jobs=n_jobs, class_weight='balanced', verbose=-1)),\n",
    "        ('XGB', XGBClassifier(random_state=271828, n_jobs=n_jobs, class_weight='balanced', verbosity=0)),\n",
    "        ('MLP', MLPClassifier(random_state=271828)),\n",
    "        ('SGD', SGDClassifier(random_state=271828, n_jobs=n_jobs, class_weight='balanced')),\n",
    "        ('NB', MultinomialNB()),\n",
    "        ('LSVC', LinearSVC(random_state=271828, class_weight='balanced', dual='auto')),\n",
    "        ('KNN', KNeighborsClassifier(n_jobs=n_jobs)),\n",
    "        ('DT', DecisionTreeClassifier(random_state=271828, class_weight='balanced')),\n",
    "        ('ExtraTrees', ExtraTreesClassifier(random_state=271828, n_jobs=n_jobs, class_weight='balanced'))\n",
    "    ]\n",
    "    \n",
    "    evaluation_results = []\n",
    "    classification_reports = []\n",
    "    \n",
    "    # Train each model and evaluate its performance\n",
    "    for model_name, model in models:\n",
    "        start_time = time.time()  # Record the start time\n",
    "\n",
    "        try:\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "            # Make predictions on the validation set\n",
    "            predictions = model.predict(X_valid)\n",
    "        except Exception as e:\n",
    "            # Handle any exceptions that occur during training or prediction\n",
    "            print(f'Error {model_name} - {e}')\n",
    "            continue \n",
    "\n",
    "        # Calculate evaluation metrics\n",
    "        f1, balanced_accuracy, accuracy, classification_report_str, matthews_corr_coeff, confusion_matrix_arr = calculate_evaluation_metrics(y_valid, predictions)\n",
    "        # Store the classification report and confusion matrix\n",
    "        classification_reports.append([model_name, classification_report_str, confusion_matrix_arr])\n",
    "\n",
    "        elapsed_time = time.time() - start_time  # Calculate the elapsed time\n",
    "        # Append the evaluation results\n",
    "        evaluation_results.append([model_name, f1, balanced_accuracy, accuracy, matthews_corr_coeff, elapsed_time, confusion_matrix_arr, classification_report_str])\n",
    "\n",
    "        # Print the evaluation results\n",
    "        print(f'Name: {model_name} - F1: {f1:.4f} - BACC: {balanced_accuracy:.4f} - ACC: {accuracy:.4f} - MCC: {matthews_corr_coeff:.4f} - Elapsed: {elapsed_time:.2f}s')\n",
    "        print(classification_report_str)\n",
    "        print(confusion_matrix_arr)\n",
    "        print('*' * 20, '\\n')\n",
    "\n",
    "    # Create a DataFrame to store the evaluation results\n",
    "    results_df = pd.DataFrame(evaluation_results, columns=['Model', 'F1', 'BACC', 'ACC', 'MCC', 'Total Time', 'Confusion Matrix', 'Classification Report'])\n",
    "    # Convert the confusion matrix to a string for better readability in the DataFrame\n",
    "    results_df['Confusion Matrix'] = results_df['Confusion Matrix'].apply(lambda x: str(x))\n",
    "\n",
    "    return results_df, classification_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Calibrated-LSVC - F1: 0.9380 - BACC: 0.8338 - ACC: 0.9380 - MCC: 0.8456 - Elapsed: 8.50s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1491\n",
      "           1       0.84      0.87      0.86       328\n",
      "           2       0.84      0.64      0.73       181\n",
      "\n",
      "    accuracy                           0.94      2000\n",
      "   macro avg       0.88      0.83      0.85      2000\n",
      "weighted avg       0.94      0.94      0.94      2000\n",
      "\n",
      "[[1474   14    3]\n",
      " [  23  286   19]\n",
      " [  24   41  116]]\n",
      "******************** \n",
      "\n",
      "Name: LR - F1: 0.9255 - BACC: 0.8922 - ACC: 0.9255 - MCC: 0.8309 - Elapsed: 6.32s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97      1491\n",
      "           1       0.82      0.85      0.84       328\n",
      "           2       0.66      0.88      0.75       181\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.83      0.89      0.85      2000\n",
      "weighted avg       0.94      0.93      0.93      2000\n",
      "\n",
      "[[1413   39   39]\n",
      " [   5  279   44]\n",
      " [   1   21  159]]\n",
      "******************** \n",
      "\n",
      "Name: RF - F1: 0.9300 - BACC: 0.7978 - ACC: 0.9300 - MCC: 0.8268 - Elapsed: 0.75s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1491\n",
      "           1       0.78      0.89      0.83       328\n",
      "           2       0.85      0.51      0.64       181\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.87      0.80      0.82      2000\n",
      "weighted avg       0.93      0.93      0.93      2000\n",
      "\n",
      "[[1475   12    4]\n",
      " [  24  292   12]\n",
      " [  19   69   93]]\n",
      "******************** \n",
      "\n",
      "Name: LGBM - F1: 0.9565 - BACC: 0.9092 - ACC: 0.9565 - MCC: 0.8942 - Elapsed: 17.73s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1491\n",
      "           1       0.89      0.89      0.89       328\n",
      "           2       0.83      0.86      0.84       181\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.90      0.91      0.91      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n",
      "[[1467   15    9]\n",
      " [  14  291   23]\n",
      " [   4   22  155]]\n",
      "******************** \n",
      "\n",
      "Name: XGB - F1: 0.9555 - BACC: 0.8957 - ACC: 0.9555 - MCC: 0.8910 - Elapsed: 16.17s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1491\n",
      "           1       0.87      0.89      0.88       328\n",
      "           2       0.87      0.81      0.84       181\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.91      0.90      0.90      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n",
      "[[1472   14    5]\n",
      " [  18  293   17]\n",
      " [   4   31  146]]\n",
      "******************** \n",
      "\n",
      "Name: MLP - F1: 0.9405 - BACC: 0.8682 - ACC: 0.9405 - MCC: 0.8540 - Elapsed: 23.13s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1491\n",
      "           1       0.85      0.86      0.85       328\n",
      "           2       0.81      0.77      0.79       181\n",
      "\n",
      "    accuracy                           0.94      2000\n",
      "   macro avg       0.88      0.87      0.87      2000\n",
      "weighted avg       0.94      0.94      0.94      2000\n",
      "\n",
      "[[1461   22    8]\n",
      " [  22  281   25]\n",
      " [  13   29  139]]\n",
      "******************** \n",
      "\n",
      "Name: SGD - F1: 0.9460 - BACC: 0.8974 - ACC: 0.9460 - MCC: 0.8705 - Elapsed: 0.60s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1491\n",
      "           1       0.88      0.84      0.86       328\n",
      "           2       0.74      0.87      0.80       181\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.87      0.90      0.88      2000\n",
      "weighted avg       0.95      0.95      0.95      2000\n",
      "\n",
      "[[1458   15   18]\n",
      " [  14  276   38]\n",
      " [   2   21  158]]\n",
      "******************** \n",
      "\n",
      "Name: NB - F1: 0.7865 - BACC: 0.5186 - ACC: 0.7865 - MCC: 0.4326 - Elapsed: 0.05s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      1491\n",
      "           1       0.50      0.40      0.44       328\n",
      "           2       0.30      0.22      0.25       181\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.56      0.52      0.53      2000\n",
      "weighted avg       0.76      0.79      0.77      2000\n",
      "\n",
      "[[1403   31   57]\n",
      " [ 164  131   33]\n",
      " [  43   99   39]]\n",
      "******************** \n",
      "\n",
      "Name: LSVC - F1: 0.9480 - BACC: 0.8949 - ACC: 0.9480 - MCC: 0.8748 - Elapsed: 2.30s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1491\n",
      "           1       0.86      0.87      0.86       328\n",
      "           2       0.78      0.84      0.81       181\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.88      0.89      0.88      2000\n",
      "weighted avg       0.95      0.95      0.95      2000\n",
      "\n",
      "[[1460   19   12]\n",
      " [  12  284   32]\n",
      " [   2   27  152]]\n",
      "******************** \n",
      "\n",
      "Name: KNN - F1: 0.8320 - BACC: 0.6235 - ACC: 0.8320 - MCC: 0.5455 - Elapsed: 0.21s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91      1491\n",
      "           1       0.67      0.48      0.56       328\n",
      "           2       0.74      0.43      0.54       181\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.76      0.62      0.67      2000\n",
      "weighted avg       0.82      0.83      0.82      2000\n",
      "\n",
      "[[1428   45   18]\n",
      " [ 160  158   10]\n",
      " [  70   33   78]]\n",
      "******************** \n",
      "\n",
      "Name: DT - F1: 0.9105 - BACC: 0.8150 - ACC: 0.9105 - MCC: 0.7792 - Elapsed: 17.68s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      1491\n",
      "           1       0.78      0.73      0.75       328\n",
      "           2       0.72      0.75      0.73       181\n",
      "\n",
      "    accuracy                           0.91      2000\n",
      "   macro avg       0.82      0.82      0.82      2000\n",
      "weighted avg       0.91      0.91      0.91      2000\n",
      "\n",
      "[[1447   32   12]\n",
      " [  49  239   40]\n",
      " [  10   36  135]]\n",
      "******************** \n",
      "\n",
      "Name: ExtraTrees - F1: 0.9070 - BACC: 0.7229 - ACC: 0.9070 - MCC: 0.7681 - Elapsed: 0.53s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1491\n",
      "           1       0.72      0.86      0.78       328\n",
      "           2       0.79      0.32      0.46       181\n",
      "\n",
      "    accuracy                           0.91      2000\n",
      "   macro avg       0.83      0.72      0.74      2000\n",
      "weighted avg       0.91      0.91      0.90      2000\n",
      "\n",
      "[[1474   14    3]\n",
      " [  34  282   12]\n",
      " [  28   95   58]]\n",
      "******************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_results, creports = train_and_evaluate_models(X_train, y_train, X_val, y_val, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1</th>\n",
       "      <th>BACC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Total Time</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Classification Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.909151</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.894218</td>\n",
       "      <td>17.729725</td>\n",
       "      <td>[[1467   15    9]\\n [  14  291   23]\\n [   4  ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.9555</td>\n",
       "      <td>0.895726</td>\n",
       "      <td>0.9555</td>\n",
       "      <td>0.890957</td>\n",
       "      <td>16.173578</td>\n",
       "      <td>[[1472   14    5]\\n [  18  293   17]\\n [   4  ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSVC</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.894947</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.874801</td>\n",
       "      <td>2.296809</td>\n",
       "      <td>[[1460   19   12]\\n [  12  284   32]\\n [   2  ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.9460</td>\n",
       "      <td>0.897420</td>\n",
       "      <td>0.9460</td>\n",
       "      <td>0.870491</td>\n",
       "      <td>0.598567</td>\n",
       "      <td>[[1458   15   18]\\n [  14  276   38]\\n [   2  ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>0.868181</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>0.853977</td>\n",
       "      <td>23.127210</td>\n",
       "      <td>[[1461   22    8]\\n [  22  281   25]\\n [  13  ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Calibrated-LSVC</td>\n",
       "      <td>0.9380</td>\n",
       "      <td>0.833811</td>\n",
       "      <td>0.9380</td>\n",
       "      <td>0.845626</td>\n",
       "      <td>8.498214</td>\n",
       "      <td>[[1474   14    3]\\n [  23  286   19]\\n [  24  ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.9255</td>\n",
       "      <td>0.892250</td>\n",
       "      <td>0.9255</td>\n",
       "      <td>0.830926</td>\n",
       "      <td>6.317317</td>\n",
       "      <td>[[1413   39   39]\\n [   5  279   44]\\n [   1  ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.797775</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.826808</td>\n",
       "      <td>0.749228</td>\n",
       "      <td>[[1475   12    4]\\n [  24  292   12]\\n [  19  ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.9105</td>\n",
       "      <td>0.815001</td>\n",
       "      <td>0.9105</td>\n",
       "      <td>0.779225</td>\n",
       "      <td>17.676320</td>\n",
       "      <td>[[1447   32   12]\\n [  49  239   40]\\n [  10  ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>0.9070</td>\n",
       "      <td>0.722932</td>\n",
       "      <td>0.9070</td>\n",
       "      <td>0.768066</td>\n",
       "      <td>0.527333</td>\n",
       "      <td>[[1474   14    3]\\n [  34  282   12]\\n [  28  ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>0.623464</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>0.545465</td>\n",
       "      <td>0.210095</td>\n",
       "      <td>[[1428   45   18]\\n [ 160  158   10]\\n [  70  ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.7865</td>\n",
       "      <td>0.518613</td>\n",
       "      <td>0.7865</td>\n",
       "      <td>0.432564</td>\n",
       "      <td>0.046383</td>\n",
       "      <td>[[1403   31   57]\\n [ 164  131   33]\\n [  43  ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model      F1      BACC     ACC       MCC  Total Time  \\\n",
       "3              LGBM  0.9565  0.909151  0.9565  0.894218   17.729725   \n",
       "4               XGB  0.9555  0.895726  0.9555  0.890957   16.173578   \n",
       "8              LSVC  0.9480  0.894947  0.9480  0.874801    2.296809   \n",
       "6               SGD  0.9460  0.897420  0.9460  0.870491    0.598567   \n",
       "5               MLP  0.9405  0.868181  0.9405  0.853977   23.127210   \n",
       "0   Calibrated-LSVC  0.9380  0.833811  0.9380  0.845626    8.498214   \n",
       "1                LR  0.9255  0.892250  0.9255  0.830926    6.317317   \n",
       "2                RF  0.9300  0.797775  0.9300  0.826808    0.749228   \n",
       "10               DT  0.9105  0.815001  0.9105  0.779225   17.676320   \n",
       "11       ExtraTrees  0.9070  0.722932  0.9070  0.768066    0.527333   \n",
       "9               KNN  0.8320  0.623464  0.8320  0.545465    0.210095   \n",
       "7                NB  0.7865  0.518613  0.7865  0.432564    0.046383   \n",
       "\n",
       "                                     Confusion Matrix  \\\n",
       "3   [[1467   15    9]\\n [  14  291   23]\\n [   4  ...   \n",
       "4   [[1472   14    5]\\n [  18  293   17]\\n [   4  ...   \n",
       "8   [[1460   19   12]\\n [  12  284   32]\\n [   2  ...   \n",
       "6   [[1458   15   18]\\n [  14  276   38]\\n [   2  ...   \n",
       "5   [[1461   22    8]\\n [  22  281   25]\\n [  13  ...   \n",
       "0   [[1474   14    3]\\n [  23  286   19]\\n [  24  ...   \n",
       "1   [[1413   39   39]\\n [   5  279   44]\\n [   1  ...   \n",
       "2   [[1475   12    4]\\n [  24  292   12]\\n [  19  ...   \n",
       "10  [[1447   32   12]\\n [  49  239   40]\\n [  10  ...   \n",
       "11  [[1474   14    3]\\n [  34  282   12]\\n [  28  ...   \n",
       "9   [[1428   45   18]\\n [ 160  158   10]\\n [  70  ...   \n",
       "7   [[1403   31   57]\\n [ 164  131   33]\\n [  43  ...   \n",
       "\n",
       "                                Classification Report  \n",
       "3                 precision    recall  f1-score   ...  \n",
       "4                 precision    recall  f1-score   ...  \n",
       "8                 precision    recall  f1-score   ...  \n",
       "6                 precision    recall  f1-score   ...  \n",
       "5                 precision    recall  f1-score   ...  \n",
       "0                 precision    recall  f1-score   ...  \n",
       "1                 precision    recall  f1-score   ...  \n",
       "2                 precision    recall  f1-score   ...  \n",
       "10                precision    recall  f1-score   ...  \n",
       "11                precision    recall  f1-score   ...  \n",
       "9                 precision    recall  f1-score   ...  \n",
       "7                 precision    recall  f1-score   ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by='MCC', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Classifier: Stacking for Enhanced Performance\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/stacking.png\" alt=\"\" style=\"width: 40%; height: 40%\"/>\n",
    "</p>\n",
    "\n",
    "#### Understanding Ensemble Learning\n",
    "\n",
    "Ensemble learning is a powerful technique in machine learning that combines multiple classifiers to achieve superior performance compared to individual models. This approach is particularly effective for:\n",
    "\n",
    "- Tackling complex classification tasks\n",
    "- Mitigating the limitations of single classifiers\n",
    "- Improving overall prediction accuracy and robustness\n",
    "\n",
    "#### The StackingClassifier: A Sophisticated Ensemble Technique\n",
    "\n",
    "The `StackingClassifier` is an advanced ensemble method that leverages the strengths of multiple base classifiers and a meta-classifier:\n",
    "\n",
    "1. **Base Classifiers**: Multiple models trained on the original dataset\n",
    "2. **Meta-Classifier**: A higher-level model that learns to combine predictions from base classifiers\n",
    "\n",
    "> **Key Insight**: The meta-classifier doesn't just average or vote on base classifier outputs. It learns the optimal way to combine these predictions, potentially capturing complex interactions between base models.\n",
    "\n",
    "#### How Stacking Works\n",
    "\n",
    "1. Train multiple base classifiers on the original dataset\n",
    "2. Use these base classifiers to make predictions on a hold-out set or through cross-validation\n",
    "3. Use the predictions from step 2 as features to train the meta-classifier\n",
    "4. For new data, base classifiers make predictions, which are then fed into the meta-classifier for the final prediction\n",
    "\n",
    "#### Choosing Classifiers for Stacking\n",
    "\n",
    "Selecting diverse classifiers is crucial for maximizing the benefits of stacking:\n",
    "\n",
    "- **Diversity in Algorithm Types**: Combine linear (e.g., Logistic Regression) and non-linear (e.g., Decision Trees) classifiers\n",
    "- **Diversity in Strengths**: Include classifiers that excel in different aspects (e.g., handling missing data, feature importance)\n",
    "- **Complementary Weaknesses**: Choose models whose weaknesses are offset by others' strengths\n",
    "\n",
    "> **Note**: While using `scikit-learn`, the meta-classifier should support the `predict_proba()` method for probabilistic predictions. Common choices include Logistic Regression or Random Forest.\n",
    "\n",
    "#### Practical Considerations\n",
    "\n",
    "- **Computational Cost**: Stacking can be computationally expensive, especially with many base classifiers or large datasets\n",
    "- **Overfitting Risk**: Careful cross-validation is necessary to prevent overfitting, particularly in the meta-classifier stage\n",
    "- **Interpretability**: While stacking often improves performance, it can reduce model interpretability\n",
    "\n",
    "#### Implementation Note\n",
    "\n",
    "For classifiers lacking `predict_proba()` (e.g., LinearSVC), the `CalibratedClassifierCV` wrapper can be used:\n",
    "\n",
    "```python\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "calibrated_svc = CalibratedClassifierCV(LinearSVC())\n",
    "```\n",
    "\n",
    "This calibration step adds probability estimation capabilities to otherwise non-probabilistic classifiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.9560 - BACC: 0.9227 - ACC: 0.9560 - MCC: 0.8947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1491\n",
      "           1       0.89      0.88      0.88       328\n",
      "           2       0.80      0.91      0.85       181\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.89      0.92      0.91      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n",
      "[[1459   20   12]\n",
      " [  10  288   30]\n",
      " [   1   15  165]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize individual models with specific parameters\n",
    "random_forest_model = RandomForestClassifier(random_state=271828, n_jobs=-1, class_weight='balanced')\n",
    "lgbm_model = LGBMClassifier(random_state=271828, n_jobs=-1, class_weight='balanced', verbose=-1)\n",
    "lsvc_model = LinearSVC(random_state=271828, class_weight='balanced', dual='auto')\n",
    "\n",
    "# List of base estimators for stacking\n",
    "base_estimators = [\n",
    "    ('random_forest', random_forest_model),\n",
    "    ('calibrated_lsvc', lsvc_model),\n",
    "    ('lgbm', lgbm_model),\n",
    "\n",
    "]\n",
    "\n",
    "# Initialize the stacking classifier with base estimators and a final estimator\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=base_estimators,\n",
    "    final_estimator=LogisticRegression(random_state=271828, n_jobs=-1, class_weight='balanced'),\n",
    "    n_jobs=2,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Fit the stacking model on the training data\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation data\n",
    "predictions = stacking_model.predict(X_val)\n",
    "\n",
    "# Calculate evaluation metrics for the predictions\n",
    "f1_score_val, balanced_accuracy_val, accuracy_val, classification_report_val, matthews_corr_coeff_val, confusion_matrix_val = calculate_evaluation_metrics(y_val, predictions)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'F1: {f1_score_val:.4f} - BACC: {balanced_accuracy_val:.4f} - ACC: {accuracy_val:.4f} - MCC: {matthews_corr_coeff_val:.4f}')\n",
    "print(classification_report_val)\n",
    "print(confusion_matrix_val)\n",
    "\n",
    "# Took 2 minutes to run in a 48 core CPU\n",
    "# Best MCC was 0.894218\n",
    "# Best MCC is now 0.8947"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`As we've seen above, we can improve our results at the cost of increased training time by combining multiple classifiers into a single model. `\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/hyperparameter_optimization.png\" alt=\"\" style=\"width: 40%; height: 40%\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "Hyperparameter optimization is the process of selecting the best set of hyperparameters for a machine learning model. These hyperparameters control the model's behavior and directly impact its performance. Finding the optimal values can often lead to better results in terms of accuracy, precision, or other evaluation metrics.\n",
    "\n",
    "Hyperparameter optimization is represented in equation form as $ \\mathcal{x}^* = \\arg \\min_{\\mathcal{x}} f(\\mathcal{x}) $, where:\n",
    "- $ \\mathcal{x}^* $ is the optimal set of hyperparameters\n",
    "- $ \\mathcal{x} $ represents the hyperparameter space\n",
    "- $ f(\\mathcal{x}) $ is the objective function to be minimized or maximized\n",
    "\n",
    "The objective function can be defined based on various criteria, such as maximizing accuracy, minimizing loss, or optimizing a specific metric.\n",
    "\n",
    "There are several methods of hyperparameter optimization, including:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/hyperparameter_optimization2.jpg\" alt=\"\" style=\"width: 40%; height: 40%\"/>\n",
    "</p>\n",
    "\n",
    "#### 1. Grid Search\n",
    "Grid Search is an exhaustive search technique that evaluates all possible combinations of hyperparameter values within a specified range. It explores the entire parameter space but can be computationally expensive, especially for large datasets or complex models.\n",
    "\n",
    "**Key Points:**\n",
    "- **Exhaustive Search:** Evaluates every possible combination within the specified grid.\n",
    "- **Computational Cost:** Can be very high, particularly with many hyperparameters or large datasets.\n",
    "- **Use Cases:** Best for smaller hyperparameter spaces or when computational resources are not a constraint.\n",
    "\n",
    "#### 2. Random Search\n",
    "Random Search involves randomly sampling the hyperparameter space and evaluating the model's performance at each sampled point. This method is less computationally intensive than Grid Search, as it does not explore every possible combination. While there is no guarantee of finding the optimal values, in many cases, Random Search can provide reasonably good results within fewer iterations.\n",
    "\n",
    "**Key Points:**\n",
    "- **Random Sampling:** Selects random combinations of hyperparameters.\n",
    "- **Efficiency:** Often finds good solutions faster than Grid Search.\n",
    "- **Use Cases:** Suitable when the hyperparameter space is large and computational resources are limited.\n",
    "\n",
    "#### 3. Bayesian Optimization\n",
    "Bayesian Optimization is a sequential model-based optimization technique that incorporates prior knowledge about the hyperparameter space. It uses a probabilistic model (e.g., Gaussian Processes) to predict the performance of various hyperparameter settings and selects the next candidate based on a predefined acquisition function. This approach is more efficient than both Grid Search and Random Search, as it intelligently chooses points in the hyperparameter space by considering information from previous evaluations.\n",
    "\n",
    "**Key Points:**\n",
    "- **Probabilistic Model:** Uses models like Gaussian Processes to predict performance.\n",
    "- **Sequential Approach:** Selects new hyperparameters based on past evaluations.\n",
    "- **Efficiency:** Often more efficient than Grid and Random Search, especially for complex models.\n",
    "- **Use Cases:** Ideal when the search space is large and evaluations are expensive.\n",
    "\n",
    "\n",
    "> **TLDR:** Hyperparameter optimization plays a crucial role in improving a model's performance. The choice of optimization method depends on factors such as available computational resources, search space complexity, and the desired balance between exploration and exploitation. Each method has its advantages and limitations, and it's essential to select the one that best suits the specific problem at hand.\n",
    "\n",
    "To save time, we'll perform each kind of optimization on the hyperparameters of our `SGDClassifier` (our fastest top classifiers). You may want to select the best classifier in your problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1'}\n",
      "Best score:  0.8545240719127332\n",
      "Validation score:  0.947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, matthews_corrcoef\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from typing import Dict, Any\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "def perform_grid_search(model: Any, param_grid: Dict[str, Any], X_train: pd.DataFrame, y_train: pd.Series, X_val: pd.DataFrame, y_val: pd.Series) -> None:\n",
    "    \"\"\"\n",
    "    Perform grid search to find the best parameters for the model and evaluate it on the validation set.\n",
    "\n",
    "    Args:\n",
    "        model (Any): The model to be trained.\n",
    "        param_grid (Dict[str, Any]): The parameter grid for the search.\n",
    "        X_train (pd.DataFrame): The training data.\n",
    "        y_train (pd.Series): The training labels.\n",
    "        X_val (pd.DataFrame): The validation data.\n",
    "        y_val (pd.Series): The validation labels.\n",
    "    \"\"\"\n",
    "    # Define the scorer for the grid search using Matthews correlation coefficient\n",
    "    scorer_mcc = make_scorer(matthews_corrcoef)\n",
    "\n",
    "    # Create the GridSearchCV object with the model and parameter grid\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3, scoring=scorer_mcc, n_jobs=-1)\n",
    "\n",
    "    # Suppress ConvergenceWarning during grid search\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "        \n",
    "        # Perform the grid search by fitting the training data\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and corresponding MCC score found by the grid search\n",
    "    print(\"Best parameters: \", grid_search.best_params_)\n",
    "    print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "    # Evaluate the model with chosen parameters on the validation set\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        validation_score = best_model.score(X_val, y_val)\n",
    "    print(\"Validation score: \", validation_score)\n",
    "\n",
    "# Define the SGDClassifier model with specific parameters\n",
    "sgd_model = SGDClassifier(random_state=271828, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "# Define parameter grid for the search\n",
    "search_parameters = {\n",
    "    'loss': ['hinge', 'log_loss', 'squared_hinge', 'modified_huber'],  # Different loss functions\n",
    "    'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0],  # Regularization strength\n",
    "    'max_iter': [1000, 2000, 3000, 4000, 5000],  # Number of iterations\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],  # Regularization types\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "perform_grid_search(sgd_model, search_parameters, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Took 17 minutes to run in a 48 core CPU\n",
    "# It performs 4 * 5 * 5 * 3 combinations of parameters, which is 300 combinations in total.\n",
    "# Since it uses Cross Validation with 3 folds, it will train 900 models in total!!!!!\n",
    "\n",
    "# Best parameters:  {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1'}\n",
    "# Validation MCC:  0.947\n",
    "# The best valid MCC for the SGDClassifier was 0.870491"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Random Search\n",
    "\n",
    "##### Understanding the 60 Iterations Rule\n",
    "\n",
    "In hyperparameter optimization, a widely-used rule of thumb states that **60 iterations of random search can find the best 5% set of parameters 95% of the time**, regardless of the grid size.\n",
    "\n",
    "This rule can be framed as a probability problem:\n",
    "\n",
    "> What is the minimum number of trials (iterations) needed to have a 95% chance of finding at least one hyperparameter set in the top 5%?\n",
    "\n",
    "This scenario aligns with the **geometric distribution**, which models the number of trials needed to achieve the first success in repeated independent trials. However, our specific question focuses on the number of trials required to be 95% confident of at least one success, rather than the expected number of trials for the first success.\n",
    "\n",
    "##### Mathematical Analysis\n",
    "\n",
    "Let's define our variables:\n",
    "- $\\mathcal{p}$ = probability of success (finding a top 5% hyperparameter set) in each trial = 0.05\n",
    "- $\\mathcal{n}$ = number of trials (iterations)\n",
    "\n",
    "We want to calculate the probability of *not* having a success after n trials, which should be less than or equal to 0.05 (5%) to ensure 95% confidence of at least one success.\n",
    "\n",
    "1. Probability of no success in n trials: $(1 - p)^n \\le 0.05$\n",
    "2. Substituting p = 0.05: $(1 - 0.05)^n \\le 0.05$\n",
    "3. Solving for n using logarithms:\n",
    "   - $n * \\log(0.95) \\le \\log(0.05)$\n",
    "   - $n \\ge \\log(0.05) / \\log(0.95)$\n",
    "\n",
    "Calculating this, we find that $\\mathcal{n}$ ≈ 59.\n",
    "\n",
    "##### Interpretation and Implications\n",
    "\n",
    "- **59 iterations** are needed for 95% confidence of finding at least one top 5% hyperparameter set.\n",
    "- This result is rounded up to 60 in the commonly cited rule of thumb.\n",
    "- The beauty of this rule lies in its **independence from the size of the hyperparameter space**.\n",
    "\n",
    "##### Practical Considerations\n",
    "\n",
    "1. **Efficiency**: Random search can be more efficient than grid search, especially in high-dimensional spaces where many parameters may not significantly impact the model's performance.\n",
    "\n",
    "2. **Adaptability**: This method works well when you're unsure which hyperparameters are most important, as it samples from the entire space.\n",
    "\n",
    "3. **Scalability**: The number of iterations needed grows logarithmically with the desired confidence level and inversely with the target percentile.\n",
    "\n",
    "   > For example, to be 99% confident of finding a top 1% set, you would need approximately 459 iterations.\n",
    "\n",
    "4. **Limitations**: While efficient, random search doesn't leverage information from previous trials to inform future searches, unlike more advanced methods like Bayesian optimization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'penalty': 'l1', 'max_iter': 3000, 'loss': 'hinge', 'alpha': 0.0001}\n",
      "Best score:  0.8545240719127332\n",
      "Validation MCC:  0.947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def perform_random_search(model: SGDClassifier, param_dist: Dict[str, Any], X_train: pd.DataFrame, y_train: pd.Series, X_val: pd.DataFrame, y_val: pd.Series) -> None:\n",
    "    \"\"\"\n",
    "    Perform random search to find the best parameters for the model and evaluate it on the validation set.\n",
    "\n",
    "    Args:\n",
    "        model (SGDClassifier): The model to be trained.\n",
    "        param_dist (Dict[str, Any]): The parameter distribution for the search.\n",
    "        X_train (pd.DataFrame): The training data.\n",
    "        y_train (pd.Series): The training labels.\n",
    "        X_val (pd.DataFrame): The validation data.\n",
    "        y_val (pd.Series): The validation labels.\n",
    "    \"\"\"\n",
    "    # Define the scorer for the random search\n",
    "    mcc_scorer = make_scorer(matthews_corrcoef)\n",
    "\n",
    "    # Create the RandomizedSearchCV object with the SGDClassifier and parameter distribution\n",
    "    random_search = RandomizedSearchCV(model, param_dist, cv=3, scoring=mcc_scorer, \n",
    "                                       n_jobs=-1, n_iter=60, random_state=271828)\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "        # Perform the random search by fitting training data\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and corresponding MCC score found by the random search\n",
    "    print(\"Best parameters: \", random_search.best_params_)\n",
    "    print(\"Best score: \", random_search.best_score_)\n",
    "\n",
    "    # Evaluate the model with chosen parameters on the validation set\n",
    "    best_model = random_search.best_estimator_\n",
    "    validation_mcc = best_model.score(X_val, y_val)\n",
    "    print(\"Validation MCC: \", validation_mcc)\n",
    "\n",
    "# Define the SGDClassifier model\n",
    "sgd_model = SGDClassifier(random_state=271828, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "# Define parameter distribution for the search\n",
    "search_parameters = {\n",
    "    'loss': ['hinge', 'log_loss', 'squared_hinge', 'modified_huber'],\n",
    "    'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0],\n",
    "    'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "}\n",
    "\n",
    "# Perform random search\n",
    "perform_random_search(sgd_model, search_parameters, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# This will typically run faster than GridSearchCV due to the reduced number of parameter combinations.\n",
    "# Time to run: 3.5 minutes in a 48 core CPU\n",
    "\n",
    "# Best parameters:  {'penalty': 'l1', 'max_iter': 3000, 'loss': 'hinge', 'alpha': 0.0001}\n",
    "# Validation MCC:  0.947\n",
    "# The best valid MCC for the SGDClassifier was 0.870491\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Optimization for Hyperparameter Tuning\n",
    "\n",
    "Bayesian optimization is a sophisticated approach to hyperparameter tuning, particularly valuable when dealing with complex models and computationally expensive evaluations. This method intelligently navigates the hyperparameter space by balancing exploration of unknown regions with exploitation of promising areas.\n",
    "\n",
    "The fundamental principle of Bayesian optimization lies in its ability to learn from previous evaluations and make informed decisions about which hyperparameters to try next. This approach significantly reduces the number of evaluations needed to find optimal or near-optimal hyperparameters.\n",
    "\n",
    "> **Key Insight**: Bayesian model-based methods can discover superior hyperparameters more efficiently by reasoning about the most promising configurations based on past trials.\n",
    "\n",
    "##### Visual Understanding\n",
    "\n",
    "To grasp the essence of Bayesian optimization, consider the following visual representations:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/bayesian1.webp\" alt=\"\" style=\"width: 40%; height: 40%\"/>\n",
    "</p>\n",
    "\n",
    "This image illustrates the initial state of the surrogate model (black line with gray uncertainty) after only two evaluations. At this stage, the surrogate model poorly approximates the true objective function (red line).\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/bayesian2.webp\" alt=\"\" style=\"width: 40%; height: 40%\"/>\n",
    "</p>\n",
    "\n",
    "After eight evaluations, the surrogate model closely matches the true function. This improved approximation allows the algorithm to select hyperparameters that are likely to yield excellent results on the actual evaluation function.\n",
    "\n",
    "For a nice conceptual understanding of Bayesian optimization, [check this link](https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f)\n",
    "\n",
    "##### The Bayesian Approach\n",
    "\n",
    "Bayesian methods mirror human learning processes:\n",
    "1. Form an initial view (prior)\n",
    "2. Update the model based on new experiences (posterior)\n",
    "\n",
    "In the context of hyperparameter optimization, this framework is applied to discover optimal model settings iteratively.\n",
    "\n",
    "##### Key Components of Bayesian Optimization\n",
    "\n",
    "1. **Objective Function**\n",
    "   - Evaluates model performance for a given set of hyperparameters\n",
    "   - Typically uses metrics like accuracy, loss, or cross-validation scores\n",
    "   - Serves as the ground truth for comparing different configurations\n",
    "\n",
    "2. **Surrogate Model**\n",
    "   - Probabilistic approximation of the objective function\n",
    "   - Often uses Gaussian Processes (GPs) for their ability to provide both predictions and uncertainty estimates\n",
    "   - Predicts performance of untested hyperparameter sets based on observed results\n",
    "   - Significantly reduces computational costs by minimizing actual evaluations of the (costly) objective function\n",
    "\n",
    "3. **Acquisition Function**\n",
    "   - Guides the selection of the next hyperparameter set to evaluate\n",
    "   - Balances exploration (investigating new areas) and exploitation (focusing on known good regions)\n",
    "   - Common types include:\n",
    "     - Expected Improvement (EI)\n",
    "     - Probability of Improvement (PI)\n",
    "     - Upper Confidence Bound (UCB)\n",
    "\n",
    "##### The Optimization Process\n",
    "\n",
    "1. **Initialization**: Randomly select and evaluate a few initial hyperparameter sets.\n",
    "\n",
    "2. **Surrogate Model Creation**: Fit a Gaussian Process to the initial data points.\n",
    "\n",
    "3. **Acquisition Function Calculation**: Compute the acquisition function values across the hyperparameter space.\n",
    "\n",
    "4. **Next Point Selection**: Choose the hyperparameter set with the highest acquisition function value.\n",
    "\n",
    "5. **Evaluation**: Assess the chosen hyperparameters using the objective function.\n",
    "\n",
    "6. **Model Update**: Refit the Gaussian Process with the new data point.\n",
    "\n",
    "7. **Iteration**: Repeat steps 3-6 until a stopping criterion is met (e.g., performance threshold or iteration limit).\n",
    "\n",
    "##### Advantages and Considerations\n",
    "\n",
    "- **Efficiency**: Particularly beneficial for expensive-to-evaluate models, minimizing the number of evaluations needed.\n",
    "- **Adaptability**: Learns from previous evaluations to make informed decisions about future trials.\n",
    "- **Uncertainty Handling**: Incorporates uncertainty in its decision-making process, leading to a more robust exploration of the hyperparameter space.\n",
    "\n",
    "> **Note**: While highly effective, Bayesian optimization does not guarantee finding the global optimum, especially in complex or noisy objective functions.\n",
    "\n",
    "##### Illustrative Analogies\n",
    "\n",
    "- **Surrogate Model as a Treasure Map**: Initially, you have a rough sketch of an island. As you explore and mark landmarks (data points), your map becomes more detailed and accurate, guiding your search more effectively.\n",
    "\n",
    "- **Acquisition Function as Oil Drilling**: Deciding whether to drill deeper in a promising spot (exploitation) or start a new drill elsewhere (exploration) based on current knowledge and potential rewards.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:744: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/jacob/miniforge3/envs/imd1107/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001, 'modified_huber', 3000, 'l2'] before, using random point [1.0, 'log_loss', 2000, 'l1']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  OrderedDict([('alpha', 0.0001), ('loss', 'hinge'), ('max_iter', 5000), ('penalty', 'l1')])\n",
      "Best score:  0.8545240719127332\n",
      "Validation MCC:  0.947\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "def perform_bayesian_optimization(model: SGDClassifier, param_space: Dict[str, Any], X_train: pd.DataFrame, y_train: pd.Series, X_val: pd.DataFrame, y_val: pd.Series) -> None:\n",
    "    \"\"\"\n",
    "    Perform Bayesian optimization to find the best parameters for the model and evaluate it on the validation set.\n",
    "\n",
    "    Args:\n",
    "        model (SGDClassifier): The model to be trained.\n",
    "        param_space (Dict[str, Any]): The parameter space for the search.\n",
    "        X_train (pd.DataFrame): The training data.\n",
    "        y_train (pd.Series): The training labels.\n",
    "        X_val (pd.DataFrame): The validation data.\n",
    "        y_val (pd.Series): The validation labels.\n",
    "    \"\"\"\n",
    "    # Define the scorer for the Bayesian optimization\n",
    "    mcc_scorer = make_scorer(matthews_corrcoef)\n",
    "\n",
    "    # Create the BayesSearchCV object with the SGDClassifier and parameter space\n",
    "    bayesian_search = BayesSearchCV(model, param_space, cv=3, scoring=mcc_scorer, \n",
    "                                    n_jobs=-1, n_iter=30, random_state=271828, n_points=10)\n",
    "\n",
    "    # Perform the Bayesian optimization by fitting training data\n",
    "    bayesian_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and corresponding MCC score found by the Bayesian search\n",
    "    print(\"Best parameters: \", bayesian_search.best_params_)\n",
    "    print(\"Best score: \", bayesian_search.best_score_)\n",
    "\n",
    "    # Evaluate the model with chosen parameters on the validation set\n",
    "    best_model = bayesian_search.best_estimator_\n",
    "    validation_mcc = best_model.score(X_val, y_val)\n",
    "    print(\"Validation MCC: \", validation_mcc)\n",
    "\n",
    "# Define the SGDClassifier model\n",
    "sgd_model = SGDClassifier(random_state=271828, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "# Define parameter space for the search\n",
    "search_parameters = {\n",
    "    'loss': ['hinge', 'log_loss', 'squared_hinge', 'modified_huber'],\n",
    "    'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0],\n",
    "    'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "}\n",
    "\n",
    "# Perform Bayesian optimization\n",
    "perform_bayesian_optimization(sgd_model, search_parameters, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# This cell took 1 minute do run\n",
    "# Best parameters:  OrderedDict({'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 5000, 'penalty': 'l1'})\n",
    "# Validation MCC:  0.947 \n",
    "# The best valid MCC for the SGDClassifier was 0.870491\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 - Predicting the Time it Takes to Issue an \"Acórdão\"\n",
    "Your turn to build a model! In this problem, you'll use the data from the previous problem to predict the time it takes for an appeal to be judged. This is a regression problem, and you'll use the same features as in the previous problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our data.\n",
    "import pandas as pd\n",
    "\n",
    "df_texts = pd.read_parquet('data/brcad5/texts_sample.parquet.gz')\n",
    "df_meta = pd.read_parquet('data/brcad5/metadata_sample.parquet.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_number</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>defendant_normalized</th>\n",
       "      <th>date_first_instance_ruling</th>\n",
       "      <th>date_appeal_panel_ruling</th>\n",
       "      <th>case_topic_code</th>\n",
       "      <th>case_topic_1st_level</th>\n",
       "      <th>case_topic_2nd_level</th>\n",
       "      <th>case_topic_3rd_level</th>\n",
       "      <th>court_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0510491-75.2017.4.05.8103</td>\n",
       "      <td>2017-10-11 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2018-01-16 11:16:19</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>6095</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Aposentadoria por Invalidez</td>\n",
       "      <td>19-CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0509917-52.2017.4.05.8103</td>\n",
       "      <td>2017-09-26 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2018-01-15 18:07:55</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>6101</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Auxílio-Doença Previdenciário</td>\n",
       "      <td>31-CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0501051-55.2017.4.05.8103</td>\n",
       "      <td>2017-02-03 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2017-11-21 11:44:40</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>6103</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Salário-Maternidade (Art. 71/73)</td>\n",
       "      <td>31-CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0511681-76.2017.4.05.8102</td>\n",
       "      <td>2017-09-27 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2017-12-29 02:18:24</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>6104</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Pensão por Morte (Art. 74/9)</td>\n",
       "      <td>30-CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0500777-79.2017.4.05.8107</td>\n",
       "      <td>2017-02-23 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2017-11-27 17:58:46</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>6103</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Salário-Maternidade (Art. 71/73)</td>\n",
       "      <td>25-CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152600</th>\n",
       "      <td>0511177-90.2019.4.05.8202</td>\n",
       "      <td>2019-11-08 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2019-12-16 13:09:08</td>\n",
       "      <td>2020-03-31 11:47:59</td>\n",
       "      <td>6176</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Pedidos Genéricos Relativos aos Benefícios em ...</td>\n",
       "      <td>Parcelas de benefício não pagas</td>\n",
       "      <td>15-PB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152605</th>\n",
       "      <td>0508370-06.2019.4.05.8200</td>\n",
       "      <td>2019-06-13 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2019-10-03 18:01:23</td>\n",
       "      <td>2020-03-31 15:22:15</td>\n",
       "      <td>6096</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Aposentadoria por Idade (Art. 48/51)</td>\n",
       "      <td>7-PB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152610</th>\n",
       "      <td>0508717-73.2018.4.05.8200</td>\n",
       "      <td>2018-06-20 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2019-08-29 16:53:58</td>\n",
       "      <td>2020-03-31 15:22:15</td>\n",
       "      <td>6114</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Benefício Assistencial (Art. 203,V CF/88)</td>\n",
       "      <td>13-PB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152628</th>\n",
       "      <td>0507511-81.2019.4.05.8202</td>\n",
       "      <td>2019-08-22 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2019-11-05 17:10:31</td>\n",
       "      <td>2020-04-01 11:24:06</td>\n",
       "      <td>6176</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Pedidos Genéricos Relativos aos Benefícios em ...</td>\n",
       "      <td>Parcelas de benefício não pagas</td>\n",
       "      <td>15-PB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152635</th>\n",
       "      <td>0507364-55.2019.4.05.8202</td>\n",
       "      <td>2019-08-21 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2019-10-30 16:18:03</td>\n",
       "      <td>2020-04-01 11:24:06</td>\n",
       "      <td>6176</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Pedidos Genéricos Relativos aos Benefícios em ...</td>\n",
       "      <td>Parcelas de benefício não pagas</td>\n",
       "      <td>15-PB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      case_number          filing_date defendant_normalized  \\\n",
       "11      0510491-75.2017.4.05.8103  2017-10-11 00:00:00                 INSS   \n",
       "16      0509917-52.2017.4.05.8103  2017-09-26 00:00:00                 INSS   \n",
       "19      0501051-55.2017.4.05.8103  2017-02-03 00:00:00                 INSS   \n",
       "23      0511681-76.2017.4.05.8102  2017-09-27 00:00:00                 INSS   \n",
       "33      0500777-79.2017.4.05.8107  2017-02-23 00:00:00                 INSS   \n",
       "...                           ...                  ...                  ...   \n",
       "152600  0511177-90.2019.4.05.8202  2019-11-08 00:00:00                 INSS   \n",
       "152605  0508370-06.2019.4.05.8200  2019-06-13 00:00:00                 INSS   \n",
       "152610  0508717-73.2018.4.05.8200  2018-06-20 00:00:00                 INSS   \n",
       "152628  0507511-81.2019.4.05.8202  2019-08-22 00:00:00                 INSS   \n",
       "152635  0507364-55.2019.4.05.8202  2019-08-21 00:00:00                 INSS   \n",
       "\n",
       "       date_first_instance_ruling date_appeal_panel_ruling  case_topic_code  \\\n",
       "11            2018-01-16 11:16:19      2018-03-26 17:07:16             6095   \n",
       "16            2018-01-15 18:07:55      2018-03-26 17:07:16             6101   \n",
       "19            2017-11-21 11:44:40      2018-03-26 17:07:16             6103   \n",
       "23            2017-12-29 02:18:24      2018-03-26 17:07:16             6104   \n",
       "33            2017-11-27 17:58:46      2018-03-26 17:07:16             6103   \n",
       "...                           ...                      ...              ...   \n",
       "152600        2019-12-16 13:09:08      2020-03-31 11:47:59             6176   \n",
       "152605        2019-10-03 18:01:23      2020-03-31 15:22:15             6096   \n",
       "152610        2019-08-29 16:53:58      2020-03-31 15:22:15             6114   \n",
       "152628        2019-11-05 17:10:31      2020-04-01 11:24:06             6176   \n",
       "152635        2019-10-30 16:18:03      2020-04-01 11:24:06             6176   \n",
       "\n",
       "          case_topic_1st_level  \\\n",
       "11      Direito Previdenciário   \n",
       "16      Direito Previdenciário   \n",
       "19      Direito Previdenciário   \n",
       "23      Direito Previdenciário   \n",
       "33      Direito Previdenciário   \n",
       "...                        ...   \n",
       "152600  Direito Previdenciário   \n",
       "152605  Direito Previdenciário   \n",
       "152610  Direito Previdenciário   \n",
       "152628  Direito Previdenciário   \n",
       "152635  Direito Previdenciário   \n",
       "\n",
       "                                     case_topic_2nd_level  \\\n",
       "11                                  Benefícios em Espécie   \n",
       "16                                  Benefícios em Espécie   \n",
       "19                                  Benefícios em Espécie   \n",
       "23                                  Benefícios em Espécie   \n",
       "33                                  Benefícios em Espécie   \n",
       "...                                                   ...   \n",
       "152600  Pedidos Genéricos Relativos aos Benefícios em ...   \n",
       "152605                              Benefícios em Espécie   \n",
       "152610                              Benefícios em Espécie   \n",
       "152628  Pedidos Genéricos Relativos aos Benefícios em ...   \n",
       "152635  Pedidos Genéricos Relativos aos Benefícios em ...   \n",
       "\n",
       "                             case_topic_3rd_level court_id  \n",
       "11                    Aposentadoria por Invalidez    19-CE  \n",
       "16                  Auxílio-Doença Previdenciário    31-CE  \n",
       "19               Salário-Maternidade (Art. 71/73)    31-CE  \n",
       "23                   Pensão por Morte (Art. 74/9)    30-CE  \n",
       "33               Salário-Maternidade (Art. 71/73)    25-CE  \n",
       "...                                           ...      ...  \n",
       "152600            Parcelas de benefício não pagas    15-PB  \n",
       "152605       Aposentadoria por Idade (Art. 48/51)     7-PB  \n",
       "152610  Benefício Assistencial (Art. 203,V CF/88)    13-PB  \n",
       "152628            Parcelas de benefício não pagas    15-PB  \n",
       "152635            Parcelas de benefício não pagas    15-PB  \n",
       "\n",
       "[20000 rows x 10 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 40000 entries, 2 to 305281\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   case_number  40000 non-null  object\n",
      " 1   text         40000 non-null  object\n",
      " 2   outcome      40000 non-null  object\n",
      " 3   ruling_type  40000 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_texts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_number</th>\n",
       "      <th>text</th>\n",
       "      <th>outcome</th>\n",
       "      <th>date_appeal_panel_ruling</th>\n",
       "      <th>outcome_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5318</th>\n",
       "      <td>0529055-14.2017.4.05.8100</td>\n",
       "      <td>RELATÓRIO Trata-se de recurso interposto pela ...</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>2018-03-26 17:02:45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19114</th>\n",
       "      <td>0504805-96.2017.4.05.8105</td>\n",
       "      <td>DIREITO PREVIDENCIÁRIO. AUXÍLIO-DOENÇA. LAUDO ...</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13460</th>\n",
       "      <td>0511681-76.2017.4.05.8102</td>\n",
       "      <td>RECURSO INOMINADO. DIREITO PREVIDENCIÁRIO. PEN...</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>0502738-58.2017.4.05.8106</td>\n",
       "      <td>ADMINISTRATIVO. GRATIFICAÇÃO DE DESEMPENHO. GD...</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>0509527-91.2017.4.05.8100</td>\n",
       "      <td>EMENTA: APLICAÇÃO DO INPC À CORREÇÃO MONETÁRIA...</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>0500987-74.2019.4.05.8200</td>\n",
       "      <td>VOTO-EMENTA ADMINISTRATIVO. CONVERSÃO DE LICEN...</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>2020-03-31 15:22:15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12876</th>\n",
       "      <td>0508370-06.2019.4.05.8200</td>\n",
       "      <td>VOTO – EMENTA PREVIDENCIÁRIO. APOSENTADORIA PO...</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>2020-03-31 15:22:15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0507364-55.2019.4.05.8202</td>\n",
       "      <td>VOTO - EMENTA PREVIDENCIÁRIO. EXTENSÃO DO PERÍ...</td>\n",
       "      <td>PROVIMENTO PARCIAL</td>\n",
       "      <td>2020-04-01 11:24:06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19799</th>\n",
       "      <td>0508286-96.2019.4.05.8202</td>\n",
       "      <td>VOTO - EMENTA PREVIDENCIÁRIO. EXTENSÃO DO PERÍ...</td>\n",
       "      <td>PROVIMENTO PARCIAL</td>\n",
       "      <td>2020-04-01 11:24:06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239</th>\n",
       "      <td>0507511-81.2019.4.05.8202</td>\n",
       "      <td>VOTO - EMENTA PREVIDENCIÁRIO. EXTENSÃO DO PERÍ...</td>\n",
       "      <td>PROVIMENTO PARCIAL</td>\n",
       "      <td>2020-04-01 11:24:06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     case_number  \\\n",
       "5318   0529055-14.2017.4.05.8100   \n",
       "19114  0504805-96.2017.4.05.8105   \n",
       "13460  0511681-76.2017.4.05.8102   \n",
       "2359   0502738-58.2017.4.05.8106   \n",
       "1706   0509527-91.2017.4.05.8100   \n",
       "...                          ...   \n",
       "2880   0500987-74.2019.4.05.8200   \n",
       "12876  0508370-06.2019.4.05.8200   \n",
       "183    0507364-55.2019.4.05.8202   \n",
       "19799  0508286-96.2019.4.05.8202   \n",
       "6239   0507511-81.2019.4.05.8202   \n",
       "\n",
       "                                                    text             outcome  \\\n",
       "5318   RELATÓRIO Trata-se de recurso interposto pela ...      NÃO PROVIMENTO   \n",
       "19114  DIREITO PREVIDENCIÁRIO. AUXÍLIO-DOENÇA. LAUDO ...      NÃO PROVIMENTO   \n",
       "13460  RECURSO INOMINADO. DIREITO PREVIDENCIÁRIO. PEN...          PROVIMENTO   \n",
       "2359   ADMINISTRATIVO. GRATIFICAÇÃO DE DESEMPENHO. GD...      NÃO PROVIMENTO   \n",
       "1706   EMENTA: APLICAÇÃO DO INPC À CORREÇÃO MONETÁRIA...          PROVIMENTO   \n",
       "...                                                  ...                 ...   \n",
       "2880   VOTO-EMENTA ADMINISTRATIVO. CONVERSÃO DE LICEN...          PROVIMENTO   \n",
       "12876  VOTO – EMENTA PREVIDENCIÁRIO. APOSENTADORIA PO...      NÃO PROVIMENTO   \n",
       "183    VOTO - EMENTA PREVIDENCIÁRIO. EXTENSÃO DO PERÍ...  PROVIMENTO PARCIAL   \n",
       "19799  VOTO - EMENTA PREVIDENCIÁRIO. EXTENSÃO DO PERÍ...  PROVIMENTO PARCIAL   \n",
       "6239   VOTO - EMENTA PREVIDENCIÁRIO. EXTENSÃO DO PERÍ...  PROVIMENTO PARCIAL   \n",
       "\n",
       "      date_appeal_panel_ruling  outcome_int  \n",
       "5318       2018-03-26 17:02:45            0  \n",
       "19114      2018-03-26 17:07:16            0  \n",
       "13460      2018-03-26 17:07:16            1  \n",
       "2359       2018-03-26 17:07:16            0  \n",
       "1706       2018-03-26 17:07:16            1  \n",
       "...                        ...          ...  \n",
       "2880       2020-03-31 15:22:15            1  \n",
       "12876      2020-03-31 15:22:15            0  \n",
       "183        2020-04-01 11:24:06            2  \n",
       "19799      2020-04-01 11:24:06            2  \n",
       "6239       2020-04-01 11:24:06            2  \n",
       "\n",
       "[20000 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20000 entries, 11 to 152635\n",
      "Data columns (total 10 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   case_number                 20000 non-null  object        \n",
      " 1   filing_date                 20000 non-null  object        \n",
      " 2   defendant_normalized        20000 non-null  object        \n",
      " 3   date_first_instance_ruling  20000 non-null  datetime64[ns]\n",
      " 4   date_appeal_panel_ruling    20000 non-null  datetime64[us]\n",
      " 5   case_topic_code             20000 non-null  int64         \n",
      " 6   case_topic_1st_level        20000 non-null  object        \n",
      " 7   case_topic_2nd_level        20000 non-null  object        \n",
      " 8   case_topic_3rd_level        19993 non-null  object        \n",
      " 9   court_id                    20000 non-null  object        \n",
      "dtypes: datetime64[ns](1), datetime64[us](1), int64(1), object(7)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_meta.date_first_instance_ruling = pd.to_datetime(df_meta.date_first_instance_ruling, yearfirst=True)\n",
    "df_meta.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20000.000000\n",
       "mean       153.045100\n",
       "std        267.485493\n",
       "min          8.000000\n",
       "25%         55.000000\n",
       "50%         80.000000\n",
       "75%        127.000000\n",
       "max       3599.000000\n",
       "Name: time_to_trial_appeal, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta['time_to_trial_appeal'] = df_meta['date_appeal_panel_ruling'] - df_meta['date_first_instance_ruling']\n",
    "df_meta['time_to_trial_appeal'] = df_meta['time_to_trial_appeal'].dt.days\n",
    "df_meta['time_to_trial_appeal'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_number</th>\n",
       "      <th>text</th>\n",
       "      <th>outcome</th>\n",
       "      <th>ruling_type</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>defendant_normalized</th>\n",
       "      <th>date_first_instance_ruling</th>\n",
       "      <th>date_appeal_panel_ruling</th>\n",
       "      <th>case_topic_code</th>\n",
       "      <th>case_topic_1st_level</th>\n",
       "      <th>case_topic_2nd_level</th>\n",
       "      <th>case_topic_3rd_level</th>\n",
       "      <th>court_id</th>\n",
       "      <th>time_to_trial_appeal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0515165-56.2018.4.05.8202</td>\n",
       "      <td>SENTENÇA I - RELATÓRIO Dispensada a feitura do...</td>\n",
       "      <td>IMPROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2018-10-19 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2019-04-25 15:55:52</td>\n",
       "      <td>2019-08-20 10:11:35</td>\n",
       "      <td>6114</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Benefício Assistencial (Art. 203,V CF/88)</td>\n",
       "      <td>15-PB</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0506287-42.2018.4.05.8300</td>\n",
       "      <td>SENTENÇA I - RELATÓRIO Dispensado, nos termos ...</td>\n",
       "      <td>PARCIALMENTE PROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2018-04-20 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2019-05-02 23:48:08</td>\n",
       "      <td>2019-07-03 18:08:09</td>\n",
       "      <td>6099</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Aposentadoria por Tempo de Serviço (Art. 52/4)</td>\n",
       "      <td>14-PE</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0505610-87.2019.4.05.8102</td>\n",
       "      <td>SENTENÇA I – RELATÓRIO Por força do disposto n...</td>\n",
       "      <td>PROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2019-05-06 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2019-07-28 09:57:06</td>\n",
       "      <td>2019-09-26 14:16:00</td>\n",
       "      <td>6101</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Auxílio-Doença Previdenciário</td>\n",
       "      <td>30-CE</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0501720-83.2018.4.05.8100</td>\n",
       "      <td>SENTENÇA Dispensado o relatório, nos termos do...</td>\n",
       "      <td>IMPROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2018-01-24 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2018-08-27 12:39:45</td>\n",
       "      <td>2018-10-31 15:36:41</td>\n",
       "      <td>6114</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Benefício Assistencial (Art. 203,V CF/88)</td>\n",
       "      <td>13-CE</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0501533-63.2018.4.05.8104</td>\n",
       "      <td>TERMO DE AUDIÊNCIA Aos 18 de setembro de 2018,...</td>\n",
       "      <td>PROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2018-05-02 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2018-09-18 14:33:01</td>\n",
       "      <td>2018-11-14 13:50:04</td>\n",
       "      <td>6103</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Salário-Maternidade (Art. 71/73)</td>\n",
       "      <td>22-CE</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0500473-94.2019.4.05.8306</td>\n",
       "      <td>SENTENÇA (Tipo C – Sem Resolução do Mérito) I ...</td>\n",
       "      <td>EXTINTO SEM MÉRITO</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2019-03-14 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2019-04-15 09:12:31</td>\n",
       "      <td>2019-07-22 15:38:11</td>\n",
       "      <td>6114</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Benefício Assistencial (Art. 203,V CF/88)</td>\n",
       "      <td>25-PE</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0505814-16.2014.4.05.8100</td>\n",
       "      <td>SENTENÇA Por força do disposto no art. 38 da L...</td>\n",
       "      <td>IMPROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2014-03-21 00:00:00</td>\n",
       "      <td>CEF</td>\n",
       "      <td>2014-03-28 10:32:04</td>\n",
       "      <td>2018-07-06 11:33:24</td>\n",
       "      <td>7691</td>\n",
       "      <td>Direito Civil</td>\n",
       "      <td>Obrigações</td>\n",
       "      <td>Inadimplemento</td>\n",
       "      <td>14-CE</td>\n",
       "      <td>1561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0500153-84.2018.4.05.8304</td>\n",
       "      <td>SENTENÇA I. Relatório Ante o disposto no art. ...</td>\n",
       "      <td>IMPROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2018-01-24 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2018-03-23 08:35:39</td>\n",
       "      <td>2018-05-23 14:42:26</td>\n",
       "      <td>6177</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Pedidos Genéricos Relativos aos Benefícios em ...</td>\n",
       "      <td>Concessão</td>\n",
       "      <td>20-PE</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0511210-80.2019.4.05.8202</td>\n",
       "      <td>SENTENÇA I – RELATÓRIO Trata-se de ação de ind...</td>\n",
       "      <td>IMPROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2019-11-08 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2019-12-16 13:09:08</td>\n",
       "      <td>2020-03-16 14:46:57</td>\n",
       "      <td>6176</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Pedidos Genéricos Relativos aos Benefícios em ...</td>\n",
       "      <td>Parcelas de benefício não pagas</td>\n",
       "      <td>15-PB</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0503936-39.2017.4.05.8201</td>\n",
       "      <td>SENTENÇA Dispensado o relatório por força do d...</td>\n",
       "      <td>PROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2017-05-18 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2017-09-27 15:04:01</td>\n",
       "      <td>2018-07-16 11:49:04</td>\n",
       "      <td>6101</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Auxílio-Doença Previdenciário</td>\n",
       "      <td>9-PB</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     case_number  \\\n",
       "0      0515165-56.2018.4.05.8202   \n",
       "1      0506287-42.2018.4.05.8300   \n",
       "2      0505610-87.2019.4.05.8102   \n",
       "3      0501720-83.2018.4.05.8100   \n",
       "4      0501533-63.2018.4.05.8104   \n",
       "...                          ...   \n",
       "19995  0500473-94.2019.4.05.8306   \n",
       "19996  0505814-16.2014.4.05.8100   \n",
       "19997  0500153-84.2018.4.05.8304   \n",
       "19998  0511210-80.2019.4.05.8202   \n",
       "19999  0503936-39.2017.4.05.8201   \n",
       "\n",
       "                                                    text  \\\n",
       "0      SENTENÇA I - RELATÓRIO Dispensada a feitura do...   \n",
       "1      SENTENÇA I - RELATÓRIO Dispensado, nos termos ...   \n",
       "2      SENTENÇA I – RELATÓRIO Por força do disposto n...   \n",
       "3      SENTENÇA Dispensado o relatório, nos termos do...   \n",
       "4      TERMO DE AUDIÊNCIA Aos 18 de setembro de 2018,...   \n",
       "...                                                  ...   \n",
       "19995  SENTENÇA (Tipo C – Sem Resolução do Mérito) I ...   \n",
       "19996  SENTENÇA Por força do disposto no art. 38 da L...   \n",
       "19997  SENTENÇA I. Relatório Ante o disposto no art. ...   \n",
       "19998  SENTENÇA I – RELATÓRIO Trata-se de ação de ind...   \n",
       "19999  SENTENÇA Dispensado o relatório por força do d...   \n",
       "\n",
       "                       outcome ruling_type          filing_date  \\\n",
       "0                 IMPROCEDENTE    SENTENÇA  2018-10-19 00:00:00   \n",
       "1      PARCIALMENTE PROCEDENTE    SENTENÇA  2018-04-20 00:00:00   \n",
       "2                   PROCEDENTE    SENTENÇA  2019-05-06 00:00:00   \n",
       "3                 IMPROCEDENTE    SENTENÇA  2018-01-24 00:00:00   \n",
       "4                   PROCEDENTE    SENTENÇA  2018-05-02 00:00:00   \n",
       "...                        ...         ...                  ...   \n",
       "19995       EXTINTO SEM MÉRITO    SENTENÇA  2019-03-14 00:00:00   \n",
       "19996             IMPROCEDENTE    SENTENÇA  2014-03-21 00:00:00   \n",
       "19997             IMPROCEDENTE    SENTENÇA  2018-01-24 00:00:00   \n",
       "19998             IMPROCEDENTE    SENTENÇA  2019-11-08 00:00:00   \n",
       "19999               PROCEDENTE    SENTENÇA  2017-05-18 00:00:00   \n",
       "\n",
       "      defendant_normalized date_first_instance_ruling  \\\n",
       "0                     INSS        2019-04-25 15:55:52   \n",
       "1                     INSS        2019-05-02 23:48:08   \n",
       "2                     INSS        2019-07-28 09:57:06   \n",
       "3                     INSS        2018-08-27 12:39:45   \n",
       "4                     INSS        2018-09-18 14:33:01   \n",
       "...                    ...                        ...   \n",
       "19995                 INSS        2019-04-15 09:12:31   \n",
       "19996                  CEF        2014-03-28 10:32:04   \n",
       "19997                 INSS        2018-03-23 08:35:39   \n",
       "19998                 INSS        2019-12-16 13:09:08   \n",
       "19999                 INSS        2017-09-27 15:04:01   \n",
       "\n",
       "      date_appeal_panel_ruling  case_topic_code    case_topic_1st_level  \\\n",
       "0          2019-08-20 10:11:35             6114  Direito Previdenciário   \n",
       "1          2019-07-03 18:08:09             6099  Direito Previdenciário   \n",
       "2          2019-09-26 14:16:00             6101  Direito Previdenciário   \n",
       "3          2018-10-31 15:36:41             6114  Direito Previdenciário   \n",
       "4          2018-11-14 13:50:04             6103  Direito Previdenciário   \n",
       "...                        ...              ...                     ...   \n",
       "19995      2019-07-22 15:38:11             6114  Direito Previdenciário   \n",
       "19996      2018-07-06 11:33:24             7691           Direito Civil   \n",
       "19997      2018-05-23 14:42:26             6177  Direito Previdenciário   \n",
       "19998      2020-03-16 14:46:57             6176  Direito Previdenciário   \n",
       "19999      2018-07-16 11:49:04             6101  Direito Previdenciário   \n",
       "\n",
       "                                    case_topic_2nd_level  \\\n",
       "0                                  Benefícios em Espécie   \n",
       "1                                  Benefícios em Espécie   \n",
       "2                                  Benefícios em Espécie   \n",
       "3                                  Benefícios em Espécie   \n",
       "4                                  Benefícios em Espécie   \n",
       "...                                                  ...   \n",
       "19995                              Benefícios em Espécie   \n",
       "19996                                         Obrigações   \n",
       "19997  Pedidos Genéricos Relativos aos Benefícios em ...   \n",
       "19998  Pedidos Genéricos Relativos aos Benefícios em ...   \n",
       "19999                              Benefícios em Espécie   \n",
       "\n",
       "                                 case_topic_3rd_level court_id  \\\n",
       "0           Benefício Assistencial (Art. 203,V CF/88)    15-PB   \n",
       "1      Aposentadoria por Tempo de Serviço (Art. 52/4)    14-PE   \n",
       "2                       Auxílio-Doença Previdenciário    30-CE   \n",
       "3           Benefício Assistencial (Art. 203,V CF/88)    13-CE   \n",
       "4                    Salário-Maternidade (Art. 71/73)    22-CE   \n",
       "...                                               ...      ...   \n",
       "19995       Benefício Assistencial (Art. 203,V CF/88)    25-PE   \n",
       "19996                                  Inadimplemento    14-CE   \n",
       "19997                                       Concessão    20-PE   \n",
       "19998                 Parcelas de benefício não pagas    15-PB   \n",
       "19999                   Auxílio-Doença Previdenciário     9-PB   \n",
       "\n",
       "       time_to_trial_appeal  \n",
       "0                       116  \n",
       "1                        61  \n",
       "2                        60  \n",
       "3                        65  \n",
       "4                        56  \n",
       "...                     ...  \n",
       "19995                    98  \n",
       "19996                  1561  \n",
       "19997                    61  \n",
       "19998                    91  \n",
       "19999                   291  \n",
       "\n",
       "[20000 rows x 14 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_texts.query('ruling_type == \"SENTENÇA\"').merge(df_meta, on='case_number', how='left')\n",
    "df.drop_duplicates(subset='case_number', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_number</th>\n",
       "      <th>text</th>\n",
       "      <th>outcome</th>\n",
       "      <th>ruling_type</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>defendant_normalized</th>\n",
       "      <th>date_first_instance_ruling</th>\n",
       "      <th>date_appeal_panel_ruling</th>\n",
       "      <th>case_topic_code</th>\n",
       "      <th>case_topic_1st_level</th>\n",
       "      <th>case_topic_2nd_level</th>\n",
       "      <th>case_topic_3rd_level</th>\n",
       "      <th>court_id</th>\n",
       "      <th>time_to_trial_appeal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0529055-14.2017.4.05.8100</td>\n",
       "      <td>SENTENÇA Dispensado o relatório (art. 1o da Le...</td>\n",
       "      <td>IMPROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2017-12-22 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2018-01-30 12:09:11</td>\n",
       "      <td>2018-03-26 17:02:45</td>\n",
       "      <td>6138</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>RMI - Renda Mensal Inicial, Reajustes e Revisõ...</td>\n",
       "      <td>Reajustes e Revisões Específicos</td>\n",
       "      <td>14-CE</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0505725-70.2017.4.05.8105</td>\n",
       "      <td>JUSTIÇA FEDERAL SEÇÃO JUDICIÁRIA DO ESTADO DO ...</td>\n",
       "      <td>IMPROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2017-11-21 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2018-02-06 15:50:11</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>6101</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Auxílio-Doença Previdenciário</td>\n",
       "      <td>23-CE</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0501051-55.2017.4.05.8103</td>\n",
       "      <td>SENTENÇA I. RELATÓRIO Trata-se de demanda prev...</td>\n",
       "      <td>IMPROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2017-02-03 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2017-11-21 11:44:40</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>6103</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Salário-Maternidade (Art. 71/73)</td>\n",
       "      <td>31-CE</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0512841-39.2017.4.05.8102</td>\n",
       "      <td>PODER JUDICIÁRIO JUSTIÇA FEDERAL DE PRIMEIRA I...</td>\n",
       "      <td>PROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2017-10-25 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2017-11-09 10:58:36</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>10288</td>\n",
       "      <td>Direito Administrativo e outras matérias do Di...</td>\n",
       "      <td>Servidor Público Civil</td>\n",
       "      <td>Sistema Remuneratório e Benefícios</td>\n",
       "      <td>17-CE</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0509917-52.2017.4.05.8103</td>\n",
       "      <td>SENTENÇA I. RELATÓRIO Trata-sede ação de rito ...</td>\n",
       "      <td>IMPROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2017-09-26 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2018-01-15 18:07:55</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>6101</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Auxílio-Doença Previdenciário</td>\n",
       "      <td>31-CE</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0508370-06.2019.4.05.8200</td>\n",
       "      <td>SENTENÇA – TIPO A Vistos etc. Trata-se de ação...</td>\n",
       "      <td>PROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2019-06-13 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2019-10-03 18:01:23</td>\n",
       "      <td>2020-03-31 15:22:15</td>\n",
       "      <td>6096</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Aposentadoria por Idade (Art. 48/51)</td>\n",
       "      <td>7-PB</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0508717-73.2018.4.05.8200</td>\n",
       "      <td>SENTENÇA Dispensado o relatório nos termos do ...</td>\n",
       "      <td>IMPROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2018-06-20 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2019-08-29 16:53:58</td>\n",
       "      <td>2020-03-31 15:22:15</td>\n",
       "      <td>6114</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Benefício Assistencial (Art. 203,V CF/88)</td>\n",
       "      <td>13-PB</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0507511-81.2019.4.05.8202</td>\n",
       "      <td>SENTENÇA I – RELATÓRIO Trata-se de ação de ind...</td>\n",
       "      <td>IMPROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2019-08-22 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2019-11-05 17:10:31</td>\n",
       "      <td>2020-04-01 11:24:06</td>\n",
       "      <td>6176</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Pedidos Genéricos Relativos aos Benefícios em ...</td>\n",
       "      <td>Parcelas de benefício não pagas</td>\n",
       "      <td>15-PB</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0507364-55.2019.4.05.8202</td>\n",
       "      <td>SENTENÇA I – RELATÓRIO Trata-se de ação de ind...</td>\n",
       "      <td>IMPROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2019-08-21 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2019-10-30 16:18:03</td>\n",
       "      <td>2020-04-01 11:24:06</td>\n",
       "      <td>6176</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Pedidos Genéricos Relativos aos Benefícios em ...</td>\n",
       "      <td>Parcelas de benefício não pagas</td>\n",
       "      <td>15-PB</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0508286-96.2019.4.05.8202</td>\n",
       "      <td>SENTENÇA I – RELATÓRIO Trata-se de ação de ind...</td>\n",
       "      <td>IMPROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2019-09-05 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2019-11-03 17:39:57</td>\n",
       "      <td>2020-04-01 11:24:06</td>\n",
       "      <td>6176</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Pedidos Genéricos Relativos aos Benefícios em ...</td>\n",
       "      <td>Parcelas de benefício não pagas</td>\n",
       "      <td>15-PB</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     case_number  \\\n",
       "0      0529055-14.2017.4.05.8100   \n",
       "1      0505725-70.2017.4.05.8105   \n",
       "2      0501051-55.2017.4.05.8103   \n",
       "3      0512841-39.2017.4.05.8102   \n",
       "4      0509917-52.2017.4.05.8103   \n",
       "...                          ...   \n",
       "19995  0508370-06.2019.4.05.8200   \n",
       "19996  0508717-73.2018.4.05.8200   \n",
       "19997  0507511-81.2019.4.05.8202   \n",
       "19998  0507364-55.2019.4.05.8202   \n",
       "19999  0508286-96.2019.4.05.8202   \n",
       "\n",
       "                                                    text       outcome  \\\n",
       "0      SENTENÇA Dispensado o relatório (art. 1o da Le...  IMPROCEDENTE   \n",
       "1      JUSTIÇA FEDERAL SEÇÃO JUDICIÁRIA DO ESTADO DO ...  IMPROCEDENTE   \n",
       "2      SENTENÇA I. RELATÓRIO Trata-se de demanda prev...  IMPROCEDENTE   \n",
       "3      PODER JUDICIÁRIO JUSTIÇA FEDERAL DE PRIMEIRA I...    PROCEDENTE   \n",
       "4      SENTENÇA I. RELATÓRIO Trata-sede ação de rito ...  IMPROCEDENTE   \n",
       "...                                                  ...           ...   \n",
       "19995  SENTENÇA – TIPO A Vistos etc. Trata-se de ação...    PROCEDENTE   \n",
       "19996  SENTENÇA Dispensado o relatório nos termos do ...  IMPROCEDENTE   \n",
       "19997  SENTENÇA I – RELATÓRIO Trata-se de ação de ind...  IMPROCEDENTE   \n",
       "19998  SENTENÇA I – RELATÓRIO Trata-se de ação de ind...  IMPROCEDENTE   \n",
       "19999  SENTENÇA I – RELATÓRIO Trata-se de ação de ind...  IMPROCEDENTE   \n",
       "\n",
       "      ruling_type          filing_date defendant_normalized  \\\n",
       "0        SENTENÇA  2017-12-22 00:00:00                 INSS   \n",
       "1        SENTENÇA  2017-11-21 00:00:00                 INSS   \n",
       "2        SENTENÇA  2017-02-03 00:00:00                 INSS   \n",
       "3        SENTENÇA  2017-10-25 00:00:00                 INSS   \n",
       "4        SENTENÇA  2017-09-26 00:00:00                 INSS   \n",
       "...           ...                  ...                  ...   \n",
       "19995    SENTENÇA  2019-06-13 00:00:00                 INSS   \n",
       "19996    SENTENÇA  2018-06-20 00:00:00                 INSS   \n",
       "19997    SENTENÇA  2019-08-22 00:00:00                 INSS   \n",
       "19998    SENTENÇA  2019-08-21 00:00:00                 INSS   \n",
       "19999    SENTENÇA  2019-09-05 00:00:00                 INSS   \n",
       "\n",
       "      date_first_instance_ruling date_appeal_panel_ruling  case_topic_code  \\\n",
       "0            2018-01-30 12:09:11      2018-03-26 17:02:45             6138   \n",
       "1            2018-02-06 15:50:11      2018-03-26 17:07:16             6101   \n",
       "2            2017-11-21 11:44:40      2018-03-26 17:07:16             6103   \n",
       "3            2017-11-09 10:58:36      2018-03-26 17:07:16            10288   \n",
       "4            2018-01-15 18:07:55      2018-03-26 17:07:16             6101   \n",
       "...                          ...                      ...              ...   \n",
       "19995        2019-10-03 18:01:23      2020-03-31 15:22:15             6096   \n",
       "19996        2019-08-29 16:53:58      2020-03-31 15:22:15             6114   \n",
       "19997        2019-11-05 17:10:31      2020-04-01 11:24:06             6176   \n",
       "19998        2019-10-30 16:18:03      2020-04-01 11:24:06             6176   \n",
       "19999        2019-11-03 17:39:57      2020-04-01 11:24:06             6176   \n",
       "\n",
       "                                    case_topic_1st_level  \\\n",
       "0                                 Direito Previdenciário   \n",
       "1                                 Direito Previdenciário   \n",
       "2                                 Direito Previdenciário   \n",
       "3      Direito Administrativo e outras matérias do Di...   \n",
       "4                                 Direito Previdenciário   \n",
       "...                                                  ...   \n",
       "19995                             Direito Previdenciário   \n",
       "19996                             Direito Previdenciário   \n",
       "19997                             Direito Previdenciário   \n",
       "19998                             Direito Previdenciário   \n",
       "19999                             Direito Previdenciário   \n",
       "\n",
       "                                    case_topic_2nd_level  \\\n",
       "0      RMI - Renda Mensal Inicial, Reajustes e Revisõ...   \n",
       "1                                  Benefícios em Espécie   \n",
       "2                                  Benefícios em Espécie   \n",
       "3                                 Servidor Público Civil   \n",
       "4                                  Benefícios em Espécie   \n",
       "...                                                  ...   \n",
       "19995                              Benefícios em Espécie   \n",
       "19996                              Benefícios em Espécie   \n",
       "19997  Pedidos Genéricos Relativos aos Benefícios em ...   \n",
       "19998  Pedidos Genéricos Relativos aos Benefícios em ...   \n",
       "19999  Pedidos Genéricos Relativos aos Benefícios em ...   \n",
       "\n",
       "                            case_topic_3rd_level court_id  \\\n",
       "0               Reajustes e Revisões Específicos    14-CE   \n",
       "1                  Auxílio-Doença Previdenciário    23-CE   \n",
       "2               Salário-Maternidade (Art. 71/73)    31-CE   \n",
       "3             Sistema Remuneratório e Benefícios    17-CE   \n",
       "4                  Auxílio-Doença Previdenciário    31-CE   \n",
       "...                                          ...      ...   \n",
       "19995       Aposentadoria por Idade (Art. 48/51)     7-PB   \n",
       "19996  Benefício Assistencial (Art. 203,V CF/88)    13-PB   \n",
       "19997            Parcelas de benefício não pagas    15-PB   \n",
       "19998            Parcelas de benefício não pagas    15-PB   \n",
       "19999            Parcelas de benefício não pagas    15-PB   \n",
       "\n",
       "       time_to_trial_appeal  \n",
       "0                        55  \n",
       "1                        48  \n",
       "2                       125  \n",
       "3                       137  \n",
       "4                        69  \n",
       "...                     ...  \n",
       "19995                   179  \n",
       "19996                   214  \n",
       "19997                   147  \n",
       "19998                   153  \n",
       "19999                   149  \n",
       "\n",
       "[20000 rows x 14 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(by='date_appeal_panel_ruling', ascending=True).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 14), (2000, 14), (2000, 14))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the length of the training set (80% of the total data)\n",
    "train_len = int(0.8 * len(df))\n",
    "\n",
    "# Determine the length of the validation set (10% of the total data)\n",
    "val_len = int(0.1 * len(df))\n",
    "\n",
    "# Create the training set by selecting the first 'train_len' rows from the dataframe\n",
    "df_train = df.iloc[:train_len].copy()\n",
    "\n",
    "# Create the validation set by selecting the next 'val_len' rows after the training set\n",
    "df_val = df.iloc[train_len:train_len + val_len].copy()\n",
    "\n",
    "# Create the test set by selecting the remaining rows after the training and validation sets\n",
    "df_test = df.iloc[train_len + val_len:].copy()\n",
    "\n",
    "# Print the shapes of the training, validation, and test sets to verify the splits\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in [df_train, df_val, df_test]:\n",
    "    dataframe['clean_text'] = dataframe.text.apply(remove_accented_characters)\n",
    "    dataframe['clean_text'] = dataframe.clean_text.apply(remove_numbers_punctuation_from_text)\n",
    "    dataframe['clean_text'] = dataframe.clean_text.apply(remove_excessive_spaces)\n",
    "    dataframe['clean_text'] = dataframe.clean_text.apply(remove_short_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_number</th>\n",
       "      <th>text</th>\n",
       "      <th>outcome</th>\n",
       "      <th>ruling_type</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>defendant_normalized</th>\n",
       "      <th>date_first_instance_ruling</th>\n",
       "      <th>date_appeal_panel_ruling</th>\n",
       "      <th>case_topic_code</th>\n",
       "      <th>case_topic_1st_level</th>\n",
       "      <th>case_topic_2nd_level</th>\n",
       "      <th>case_topic_3rd_level</th>\n",
       "      <th>court_id</th>\n",
       "      <th>time_to_trial_appeal</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0529055-14.2017.4.05.8100</td>\n",
       "      <td>SENTENÇA Dispensado o relatório (art. 1o da Le...</td>\n",
       "      <td>IMPROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2017-12-22 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2018-01-30 12:09:11</td>\n",
       "      <td>2018-03-26 17:02:45</td>\n",
       "      <td>6138</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>RMI - Renda Mensal Inicial, Reajustes e Revisõ...</td>\n",
       "      <td>Reajustes e Revisões Específicos</td>\n",
       "      <td>14-CE</td>\n",
       "      <td>55</td>\n",
       "      <td>SENTENCA Dispensado relatorio art Lei art Lei ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0505725-70.2017.4.05.8105</td>\n",
       "      <td>JUSTIÇA FEDERAL SEÇÃO JUDICIÁRIA DO ESTADO DO ...</td>\n",
       "      <td>IMPROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2017-11-21 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2018-02-06 15:50:11</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>6101</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Auxílio-Doença Previdenciário</td>\n",
       "      <td>23-CE</td>\n",
       "      <td>48</td>\n",
       "      <td>JUSTICA FEDERAL SECAO JUDICIARIA ESTADO CEARA ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0501051-55.2017.4.05.8103</td>\n",
       "      <td>SENTENÇA I. RELATÓRIO Trata-se de demanda prev...</td>\n",
       "      <td>IMPROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2017-02-03 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2017-11-21 11:44:40</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>6103</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Salário-Maternidade (Art. 71/73)</td>\n",
       "      <td>31-CE</td>\n",
       "      <td>125</td>\n",
       "      <td>SENTENCA RELATORIO Trata demanda previdenciari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0512841-39.2017.4.05.8102</td>\n",
       "      <td>PODER JUDICIÁRIO JUSTIÇA FEDERAL DE PRIMEIRA I...</td>\n",
       "      <td>PROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2017-10-25 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2017-11-09 10:58:36</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>10288</td>\n",
       "      <td>Direito Administrativo e outras matérias do Di...</td>\n",
       "      <td>Servidor Público Civil</td>\n",
       "      <td>Sistema Remuneratório e Benefícios</td>\n",
       "      <td>17-CE</td>\n",
       "      <td>137</td>\n",
       "      <td>PODER JUDICIARIO JUSTICA FEDERAL PRIMEIRA INST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0509917-52.2017.4.05.8103</td>\n",
       "      <td>SENTENÇA I. RELATÓRIO Trata-sede ação de rito ...</td>\n",
       "      <td>IMPROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2017-09-26 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2018-01-15 18:07:55</td>\n",
       "      <td>2018-03-26 17:07:16</td>\n",
       "      <td>6101</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Auxílio-Doença Previdenciário</td>\n",
       "      <td>31-CE</td>\n",
       "      <td>69</td>\n",
       "      <td>SENTENCA RELATORIO Trata sede acao rito especi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>0516038-07.2019.4.05.8013</td>\n",
       "      <td>Processo no 05160380720194058013T Autor: CARLS...</td>\n",
       "      <td>PROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2019-05-23 00:00:00</td>\n",
       "      <td>IFES</td>\n",
       "      <td>2019-07-29 11:47:02</td>\n",
       "      <td>2019-09-30 17:20:24</td>\n",
       "      <td>10220</td>\n",
       "      <td>Direito Administrativo e outras matérias do Di...</td>\n",
       "      <td>Servidor Público Civil</td>\n",
       "      <td>Regime Estatutário</td>\n",
       "      <td>14-AL</td>\n",
       "      <td>63</td>\n",
       "      <td>Processo Autor CARLSON LAMENHA APOLINARIO Reu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>0500940-73.2019.4.05.8015</td>\n",
       "      <td>SENTENÇA Trata-se de ação proposta em face da ...</td>\n",
       "      <td>IMPROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2019-01-29 00:00:00</td>\n",
       "      <td>CEF</td>\n",
       "      <td>2019-06-14 11:24:25</td>\n",
       "      <td>2019-09-30 17:20:24</td>\n",
       "      <td>10433</td>\n",
       "      <td>Direito Civil</td>\n",
       "      <td>Responsabilidade Civil</td>\n",
       "      <td>Indenização por Dano Moral</td>\n",
       "      <td>10-AL</td>\n",
       "      <td>108</td>\n",
       "      <td>SENTENCA Trata acao proposta face Caixa Econom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>0509291-41.2019.4.05.8013</td>\n",
       "      <td>SENTENÇA Trata-se de ação proposta contra o IN...</td>\n",
       "      <td>PROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2019-03-29 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2019-06-13 12:08:18</td>\n",
       "      <td>2019-09-30 17:20:24</td>\n",
       "      <td>6118</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Aposentadoria por Tempo de Contribuição (Art. ...</td>\n",
       "      <td>9-AL</td>\n",
       "      <td>109</td>\n",
       "      <td>SENTENCA Trata acao proposta contra INSS que p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>0519807-23.2019.4.05.8013</td>\n",
       "      <td>SENTENÇA Trata-se de ação de rito sumaríssimo,...</td>\n",
       "      <td>PROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2019-06-25 00:00:00</td>\n",
       "      <td>INSS</td>\n",
       "      <td>2019-07-16 11:13:16</td>\n",
       "      <td>2019-09-30 17:20:24</td>\n",
       "      <td>6100</td>\n",
       "      <td>Direito Previdenciário</td>\n",
       "      <td>Benefícios em Espécie</td>\n",
       "      <td>Aposentadoria Especial (Art. 57/8)</td>\n",
       "      <td>9-AL</td>\n",
       "      <td>76</td>\n",
       "      <td>SENTENCA Trata acao rito sumarissimo com pedid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>0512444-82.2019.4.05.8013</td>\n",
       "      <td>SENTENÇA Trata-se de demanda ajuizada em face ...</td>\n",
       "      <td>IMPROCEDENTE</td>\n",
       "      <td>SENTENÇA</td>\n",
       "      <td>2019-04-25 00:00:00</td>\n",
       "      <td>CEF</td>\n",
       "      <td>2019-06-20 23:54:41</td>\n",
       "      <td>2019-09-30 17:20:24</td>\n",
       "      <td>6005</td>\n",
       "      <td>Direito Tributário</td>\n",
       "      <td>Crédito Tributário</td>\n",
       "      <td>Juros/Correção Monetária</td>\n",
       "      <td>9-AL</td>\n",
       "      <td>101</td>\n",
       "      <td>SENTENCA Trata demanda ajuizada face Caixa Eco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     case_number  \\\n",
       "0      0529055-14.2017.4.05.8100   \n",
       "1      0505725-70.2017.4.05.8105   \n",
       "2      0501051-55.2017.4.05.8103   \n",
       "3      0512841-39.2017.4.05.8102   \n",
       "4      0509917-52.2017.4.05.8103   \n",
       "...                          ...   \n",
       "15995  0516038-07.2019.4.05.8013   \n",
       "15996  0500940-73.2019.4.05.8015   \n",
       "15997  0509291-41.2019.4.05.8013   \n",
       "15998  0519807-23.2019.4.05.8013   \n",
       "15999  0512444-82.2019.4.05.8013   \n",
       "\n",
       "                                                    text       outcome  \\\n",
       "0      SENTENÇA Dispensado o relatório (art. 1o da Le...  IMPROCEDENTE   \n",
       "1      JUSTIÇA FEDERAL SEÇÃO JUDICIÁRIA DO ESTADO DO ...  IMPROCEDENTE   \n",
       "2      SENTENÇA I. RELATÓRIO Trata-se de demanda prev...  IMPROCEDENTE   \n",
       "3      PODER JUDICIÁRIO JUSTIÇA FEDERAL DE PRIMEIRA I...    PROCEDENTE   \n",
       "4      SENTENÇA I. RELATÓRIO Trata-sede ação de rito ...  IMPROCEDENTE   \n",
       "...                                                  ...           ...   \n",
       "15995  Processo no 05160380720194058013T Autor: CARLS...    PROCEDENTE   \n",
       "15996  SENTENÇA Trata-se de ação proposta em face da ...  IMPROCEDENTE   \n",
       "15997  SENTENÇA Trata-se de ação proposta contra o IN...    PROCEDENTE   \n",
       "15998  SENTENÇA Trata-se de ação de rito sumaríssimo,...    PROCEDENTE   \n",
       "15999  SENTENÇA Trata-se de demanda ajuizada em face ...  IMPROCEDENTE   \n",
       "\n",
       "      ruling_type          filing_date defendant_normalized  \\\n",
       "0        SENTENÇA  2017-12-22 00:00:00                 INSS   \n",
       "1        SENTENÇA  2017-11-21 00:00:00                 INSS   \n",
       "2        SENTENÇA  2017-02-03 00:00:00                 INSS   \n",
       "3        SENTENÇA  2017-10-25 00:00:00                 INSS   \n",
       "4        SENTENÇA  2017-09-26 00:00:00                 INSS   \n",
       "...           ...                  ...                  ...   \n",
       "15995    SENTENÇA  2019-05-23 00:00:00                 IFES   \n",
       "15996    SENTENÇA  2019-01-29 00:00:00                  CEF   \n",
       "15997    SENTENÇA  2019-03-29 00:00:00                 INSS   \n",
       "15998    SENTENÇA  2019-06-25 00:00:00                 INSS   \n",
       "15999    SENTENÇA  2019-04-25 00:00:00                  CEF   \n",
       "\n",
       "      date_first_instance_ruling date_appeal_panel_ruling  case_topic_code  \\\n",
       "0            2018-01-30 12:09:11      2018-03-26 17:02:45             6138   \n",
       "1            2018-02-06 15:50:11      2018-03-26 17:07:16             6101   \n",
       "2            2017-11-21 11:44:40      2018-03-26 17:07:16             6103   \n",
       "3            2017-11-09 10:58:36      2018-03-26 17:07:16            10288   \n",
       "4            2018-01-15 18:07:55      2018-03-26 17:07:16             6101   \n",
       "...                          ...                      ...              ...   \n",
       "15995        2019-07-29 11:47:02      2019-09-30 17:20:24            10220   \n",
       "15996        2019-06-14 11:24:25      2019-09-30 17:20:24            10433   \n",
       "15997        2019-06-13 12:08:18      2019-09-30 17:20:24             6118   \n",
       "15998        2019-07-16 11:13:16      2019-09-30 17:20:24             6100   \n",
       "15999        2019-06-20 23:54:41      2019-09-30 17:20:24             6005   \n",
       "\n",
       "                                    case_topic_1st_level  \\\n",
       "0                                 Direito Previdenciário   \n",
       "1                                 Direito Previdenciário   \n",
       "2                                 Direito Previdenciário   \n",
       "3      Direito Administrativo e outras matérias do Di...   \n",
       "4                                 Direito Previdenciário   \n",
       "...                                                  ...   \n",
       "15995  Direito Administrativo e outras matérias do Di...   \n",
       "15996                                      Direito Civil   \n",
       "15997                             Direito Previdenciário   \n",
       "15998                             Direito Previdenciário   \n",
       "15999                                 Direito Tributário   \n",
       "\n",
       "                                    case_topic_2nd_level  \\\n",
       "0      RMI - Renda Mensal Inicial, Reajustes e Revisõ...   \n",
       "1                                  Benefícios em Espécie   \n",
       "2                                  Benefícios em Espécie   \n",
       "3                                 Servidor Público Civil   \n",
       "4                                  Benefícios em Espécie   \n",
       "...                                                  ...   \n",
       "15995                             Servidor Público Civil   \n",
       "15996                             Responsabilidade Civil   \n",
       "15997                              Benefícios em Espécie   \n",
       "15998                              Benefícios em Espécie   \n",
       "15999                                 Crédito Tributário   \n",
       "\n",
       "                                    case_topic_3rd_level court_id  \\\n",
       "0                       Reajustes e Revisões Específicos    14-CE   \n",
       "1                          Auxílio-Doença Previdenciário    23-CE   \n",
       "2                       Salário-Maternidade (Art. 71/73)    31-CE   \n",
       "3                     Sistema Remuneratório e Benefícios    17-CE   \n",
       "4                          Auxílio-Doença Previdenciário    31-CE   \n",
       "...                                                  ...      ...   \n",
       "15995                                 Regime Estatutário    14-AL   \n",
       "15996                         Indenização por Dano Moral    10-AL   \n",
       "15997  Aposentadoria por Tempo de Contribuição (Art. ...     9-AL   \n",
       "15998                 Aposentadoria Especial (Art. 57/8)     9-AL   \n",
       "15999                           Juros/Correção Monetária     9-AL   \n",
       "\n",
       "       time_to_trial_appeal                                         clean_text  \n",
       "0                        55  SENTENCA Dispensado relatorio art Lei art Lei ...  \n",
       "1                        48  JUSTICA FEDERAL SECAO JUDICIARIA ESTADO CEARA ...  \n",
       "2                       125  SENTENCA RELATORIO Trata demanda previdenciari...  \n",
       "3                       137  PODER JUDICIARIO JUSTICA FEDERAL PRIMEIRA INST...  \n",
       "4                        69  SENTENCA RELATORIO Trata sede acao rito especi...  \n",
       "...                     ...                                                ...  \n",
       "15995                    63  Processo Autor CARLSON LAMENHA APOLINARIO Reu ...  \n",
       "15996                   108  SENTENCA Trata acao proposta face Caixa Econom...  \n",
       "15997                   109  SENTENCA Trata acao proposta contra INSS que p...  \n",
       "15998                    76  SENTENCA Trata acao rito sumarissimo com pedid...  \n",
       "15999                   101  SENTENCA Trata demanda ajuizada face Caixa Eco...  \n",
       "\n",
       "[16000 rows x 15 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.clean_text\n",
    "X_val = df_val.clean_text\n",
    "X_test = df_test.clean_text\n",
    "\n",
    "y_train = df_train.time_to_trial_appeal\n",
    "y_val = df_val.time_to_trial_appeal\n",
    "y_test = df_test.time_to_trial_appeal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, it's up to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "1. What are the three key steps in text processing mentioned in the NLP pipeline?\n",
    "\n",
    "2. What is the \"60 iterations rule\" in the context of random search for hyperparameter optimization?\n",
    "\n",
    "3. What are the three main components of Bayesian Optimization for hyperparameter tuning?\n",
    "\n",
    "4. How does the notebook split the data for training, validation and testing?\n",
    "\n",
    "5. What is the purpose of the StackingClassifier in the context of this notebook?\n",
    "\n",
    "6. What evaluation metrics are used to assess the performance of the classifiers?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Answers are commented inside this cell.`\n",
    "\n",
    "<!-- 1. The three key steps in text processing mentioned in the NLP pipeline are: Normalization (standardizing text), Tokenization (breaking text into smaller units), and Numericalization (converting tokens to numerical representations).\n",
    "\n",
    "2. The \"60 iterations rule\" states that 60 iterations of random search can find the best 5% set of parameters 95% of the time, regardless of the grid size. This rule provides an efficient approach to hyperparameter optimization.\n",
    "\n",
    "3. The three main components of Bayesian Optimization for hyperparameter tuning are: Objective Function (evaluates model performance), Surrogate Model (probabilistic approximation of the objective function), and Acquisition Function (guides selection of next hyperparameter set to evaluate).\n",
    "\n",
    "4. The notebook splits the data chronologically: the first 80% of the data (sorted by date) is used for training, the next 10% for validation, and the final 10% for testing.\n",
    "\n",
    "5. The StackingClassifier is used to combine multiple base classifiers with a meta-classifier, aiming to achieve superior performance compared to individual models by leveraging their collective strengths.\n",
    "\n",
    "6. The evaluation metrics used include F1 score, balanced accuracy, accuracy, Matthews Correlation Coefficient (MCC), and confusion matrix. The notebook particularly emphasizes MCC as a key metric.\n",
    " -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "class_applied_ml_tre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
